> # ğŸš§ Attention, peinture fraÃ®che !
>
> Cette page a Ã©tÃ© traduite par une seule personne et n'a pas Ã©tÃ© relue et
> vÃ©rifiÃ©e par quelqu'un d'autre ! Les informations peuvent par exemple Ãªtre
> erronÃ©es, Ãªtre formulÃ©es maladroitement, ou contenir d'autres types de fautes.

<!--
# Handling Connections Concurrently
The problem with our code so far is that `listener.incoming()` is a blocking iterator.
The executor can't run other futures while `listener` waits on incoming connections,
and we can't handle a new connection until we're done with the previous one.
-->

# GÃ©rer les connexions en concurrence

Le problÃ¨me avec notre code prÃ©cÃ©dent est que `ecouteur.incoming()` est un
itÃ©rateur bloquant. L'exÃ©cuteur ne peut pas exÃ©cuter d'autres futures pendant
que `ecouteur` attends les connexions entrantes, et nous ne pouvons pas gÃ©rer
une nouvelle connexion jusqu'Ã  ce que nous ayons terminÃ© avec la prÃ©cÃ©dente.

<!--
In order to fix this, we'll transform `listener.incoming()` from a blocking Iterator
to a non-blocking Stream. Streams are similar to Iterators, but can be consumed asynchronously.
For more information, see the [chapter on Streams](../05_streams/01_chapter.md).
-->

Pour corriger cela, nous allons transformer l'itÃ©rateur bloquant
`ecouteur.incoming()` en `Stream` non bloquant. Les `Stream`s ressemblent aux
itÃ©rateurs, mais peuvent Ãªtre consommÃ©s de maniÃ¨re asynchrone. Pour plus
d'informations, vous pouvez consulter [le chapitre sur les
`Stream`s](../05_streams/01_chapter.md).

<!--
Let's replace our blocking `std::net::TcpListener` with the non-blocking `async_std::net::TcpListener`,
and update our connection handler to accept an `async_std::net::TcpStream`:
```rust,ignore
{{#include ../../examples-sources/09_04_concurrent_tcp_server/src/main.rs:handle_connection}}
```
-->

RemplaÃ§ons notre `std::net::TcpListener` bloquant par le
`async_std::net::TcpListener` non bloquant, et mettons Ã  jour notre gestion de
connexion pour accepter un `async_std::net::TcpStream`Â :

```rust,ignore
{{#include ../../examples/09_04_concurrent_tcp_server/src/main.rs:handle_connection}}
```

<!--
The asynchronous version of `TcpListener` implements the `Stream` trait for `listener.incoming()`,
a change which provides two benefits.
The first is that `listener.incoming()` no longer blocks the executor.
The executor can now yield to other pending futures 
while there are no incoming TCP connections to be processed.
-->

La version asynchrone de `TcpListener` implÃ©mente le trait `Stream` sur
`ecouteur.incoming()`, ce qui apporte deux avantages.
Le premier est que `ecouteur.incoming()` ne bloque plus l'exÃ©cuteur.
L'exÃ©cuteur peut maintenant transfÃ©rer l'exÃ©cution Ã  d'autres futures en
attente lorsqu'il n'y a plus de connexions TCP entrantes Ã  traiter.

<!--
The second benefit is that elements from the Stream can optionally be processed concurrently,
using a Stream's `for_each_concurrent` method.
Here, we'll take advantage of this method to handle each incoming request concurrently.
We'll need to import the `Stream` trait from the `futures` crate, so our Cargo.toml now looks like this:
```diff
+[dependencies]
+futures = "0.3"

 [dependencies.async-std]
 version = "1.6"
 features = ["attributes"]
```
-->

Le second bienfait est que les Ã©lÃ©ments du `Stream` peuvent optionnellement
Ãªtre traitÃ©s en concurrence, en utilisant la mÃ©thode `for_each_concurrent` des
`Stream`s.
Ici, nous allons profiter de cette mÃ©thode pour traiter chaque requÃªte entrante
de maniÃ¨re concurrente.
Nous avons besoin d'importer le trait `Stream` de la crate `futures`, donc
notre Cargo.toml ressemble maintenant Ã  ceciÂ :

```diff
+[dependencies]
+futures = "0.3"

 [dependencies.async-std]
 version = "1.6"
 features = ["attributes"]
```

<!--
Now, we can handle each connection concurrently by passing `handle_connection` in through a closure function.
The closure function takes ownership of each `TcpStream`, and is run as soon as a new `TcpStream` becomes available.
As long as `handle_connection` does not block, a slow request will no longer prevent other requests from completing.
```rust,ignore
{{#include ../../examples-sources/09_04_concurrent_tcp_server/src/main.rs:main_func}}
```
# Serving Requests in Parallel
Our example so far has largely presented concurrency (using async code)
as an alternative to parallelism (using threads).
However, async code and threads are not mutually exclusive.
In our example, `for_each_concurrent` processes each connection concurrently, but on the same thread.
The `async-std` crate allows us to spawn tasks onto separate threads as well.
Because `handle_connection` is both `Send` and non-blocking, it's safe to use with `async_std::task::spawn`.
Here's what that would look like:
```rust
{{#include ../../examples-sources/09_05_final_tcp_server/src/main.rs:main_func}}
```
Now we are using both concurrency and parallelism to handle multiple requests at the same time!
See the [section on multithreaded executors](../08_ecosystem/00_chapter.md#single-threading-vs-multithreading)
for more information.
-->

Maintenant, nous pouvons traiter chaque connexion en concurrence en passant
`gestion_connexion` dans une fermeture. La fermeture prend possession de chaque
`TcpStream`, et est exÃ©cutÃ© dÃ¨s qu'un nouveau `TcpStream` est disponible. Tant
que `gestion_connexion` ne bloque pas, une rÃ©ponse lente ne va plus empÃªcher
les autres requÃªtes de se complÃ©ter.

```rust,ignore
{{#include ../../examples/09_04_concurrent_tcp_server/src/main.rs:main_func}}
```

# Servir les requÃªtes en parallÃ¨le

Notre exemple jusqu'Ã  prÃ©sent a largement prÃ©sentÃ© la concurrence (en utilisant
du code asynchrone) comme Ã©tant une alternative au parallÃ©lisme (en utilisant
des processus).
Cependant, le code asynchrone et les processus ne s'excluent pas mutuellement.
Dans notre exemple, `for_each_concurrent` traite chaque connexion en
concurrence, mais sur le mÃªme processus.
La crate `async-std` nous permet Ã©galement de crÃ©er des tÃ¢ches sur des
processus sÃ©parÃ©s.
Comme `gestion_connexion` est Ã  la fois `Send` et non bloquant, il est sÃ»r Ã 
utiliser avec `async_std::task::spawn`.
Voici Ã  quoi cela devrait ressemblerÂ :

```rust
{{#include ../../examples/09_05_final_tcp_server/src/main.rs:main_func}}
```

Maintenant nous utilisons Ã  la fois la concurrence et le parallÃ©lisme pour
traiter plusieurs requÃªtes en mÃªme tempsÂ ! Lisez la [section sur les exÃ©cuteurs
multi-processus](../08_ecosystem/00_chapter.md) pour en savoir plus.
