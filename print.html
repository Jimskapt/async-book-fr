<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>La programmation asynchrone avec Rust</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="01_getting_started/01_chapter.html"><strong aria-hidden="true">1.</strong> 🚧 Pour démarrer</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="01_getting_started/02_why_async.html"><strong aria-hidden="true">1.1.</strong> 🚧 Pourquoi l'asynchrone ?</a></li><li class="chapter-item expanded "><a href="01_getting_started/03_state_of_async_rust.html"><strong aria-hidden="true">1.2.</strong> 🚧 L'état de l'art de l'asynchrone en Rust</a></li><li class="chapter-item expanded "><a href="01_getting_started/04_async_await_primer.html"><strong aria-hidden="true">1.3.</strong> 🚧 Introduction à async et await</a></li></ol></li><li class="chapter-item expanded "><a href="02_execution/01_chapter.html"><strong aria-hidden="true">2.</strong> 🚧 Sous le capot : exécuter les Futures et les tâches</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="02_execution/02_future.html"><strong aria-hidden="true">2.1.</strong> 💬 The Future Trait</a></li><li class="chapter-item expanded "><a href="02_execution/03_wakeups.html"><strong aria-hidden="true">2.2.</strong> 💬 Task Wakeups with Waker</a></li><li class="chapter-item expanded "><a href="02_execution/04_executor.html"><strong aria-hidden="true">2.3.</strong> 💬 Applied: Build an Executor</a></li><li class="chapter-item expanded "><a href="02_execution/05_io.html"><strong aria-hidden="true">2.4.</strong> 💬 Executors and System IO</a></li></ol></li><li class="chapter-item expanded "><a href="03_async_await/01_chapter.html"><strong aria-hidden="true">3.</strong> 🚧 async et await</a></li><li class="chapter-item expanded "><a href="04_pinning/01_chapter.html"><strong aria-hidden="true">4.</strong> 🚧 L'épinglage</a></li><li class="chapter-item expanded "><a href="05_streams/01_chapter.html"><strong aria-hidden="true">5.</strong> 🚧 Le trait Stream</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="05_streams/02_iteration_and_concurrency.html"><strong aria-hidden="true">5.1.</strong> 🚧 L'itération et la concurrence</a></li></ol></li><li class="chapter-item expanded "><a href="06_multiple_futures/01_chapter.html"><strong aria-hidden="true">6.</strong> 🚧 Exécuter plusieurs futures en même temps</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="06_multiple_futures/02_join.html"><strong aria-hidden="true">6.1.</strong> 🚧 join!</a></li><li class="chapter-item expanded "><a href="06_multiple_futures/03_select.html"><strong aria-hidden="true">6.2.</strong> 🚧 select!</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.3.</strong> 🥚 TODO: Spawning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.4.</strong> 🥚 TODO: Cancellation and Timeouts</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.5.</strong> 🥚 TODO: FuturesUnordered</div></li></ol></li><li class="chapter-item expanded "><a href="07_workarounds/01_chapter.html"><strong aria-hidden="true">7.</strong> 🚧 Solutions de contournement à connaître et à utiliser</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="07_workarounds/02_err_in_async_blocks.html"><strong aria-hidden="true">7.1.</strong> 🚧 ? dans les blocs async</a></li><li class="chapter-item expanded "><a href="07_workarounds/03_send_approximation.html"><strong aria-hidden="true">7.2.</strong> 🚧 L'approximation de Send</a></li><li class="chapter-item expanded "><a href="07_workarounds/04_recursion.html"><strong aria-hidden="true">7.3.</strong> 🚧 La récursivité</a></li><li class="chapter-item expanded "><a href="07_workarounds/05_async_in_traits.html"><strong aria-hidden="true">7.4.</strong> 🚧 async dans les traits</a></li></ol></li><li class="chapter-item expanded "><a href="08_ecosystem/00_chapter.html"><strong aria-hidden="true">8.</strong> 🚧 L'écosystème asynchrone</a></li><li class="chapter-item expanded "><a href="09_example/00_intro.html"><strong aria-hidden="true">9.</strong> 🚧 Projet final : Serveur HTTP</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="09_example/01_running_async_code.html"><strong aria-hidden="true">9.1.</strong> 🚧 Exécuter du code asynchrone</a></li><li class="chapter-item expanded "><a href="09_example/02_handling_connections_concurrently.html"><strong aria-hidden="true">9.2.</strong> 🚧 Gérer les connexions en concurrence</a></li><li class="chapter-item expanded "><a href="09_example/03_tests.html"><strong aria-hidden="true">9.3.</strong> 🚧 Test du serveur</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.</strong> TODO: I/O</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">10.1.</strong> TODO: AsyncRead and AsyncWrite</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> TODO: Asynchronous Design Patterns: Solutions and Suggestions</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">11.1.</strong> TODO: Modeling Servers and the Request/Response Pattern</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.2.</strong> TODO: Managing Shared State</div></li></ol></li><li class="chapter-item expanded "><a href="12_appendix/01_translations.html"><strong aria-hidden="true">12.</strong> Annexe : traductions du livre</a></li><li class="chapter-item expanded affix "><a href="translation-terms.html">Traduction des termes</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">La programmation asynchrone avec Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Jimskapt/async-book-fr/" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <blockquote>
<h1 id="-attention-peinture-fraîche-"><a class="header" href="#-attention-peinture-fraîche-">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/1">Pull Request</a>.</p>
</blockquote>
<!--
# Getting Started
-->
<h1 id="pour-démarrer"><a class="header" href="#pour-démarrer">Pour démarrer</a></h1>
<!--
Welcome to Asynchronous Programming in Rust! If you're looking to start writing
asynchronous Rust code, you've come to the right place. Whether you're building
a web server, a database, or an operating system, this book will show you
how to use Rust's asynchronous programming tools to get the most out of your
hardware.
-->
<p>Bienvenue dans la programmation asynchrone avec Rust ! Si vous voulez
commencer à écrire du code asynchrone avec Rust, vous êtes au bon endroit. Que
vous soyez en train de construire un serveur web, une base de données, ou un
système d'exploitation, ce livre va vous montrer comment utiliser les outils
de programmation asynchrone de Rust pour exploiter au mieux votre matériel.</p>
<!--
## What This Book Covers
-->
<h2 id="ce-que-ce-livre-va-traiter"><a class="header" href="#ce-que-ce-livre-va-traiter">Ce que ce livre va traiter</a></h2>
<!--
This book aims to be a comprehensive, up-to-date guide to using Rust's async
language features and libraries, appropriate for beginners and old hands alike.
-->
<p>Ce livre vise à être un guide étendu et à jour sur l'utilisation des
bibliothèques et fonctionnalités asynchrones du langage Rust, aussi bien pour
les débutants que pour les habitués.</p>
<!--
- The early chapters provide an introduction to async programming in general,
and to Rust's particular take on it.

- The middle chapters discuss key utilities and control-flow tools you can use
when writing async code, and describe best-practices for structuring libraries
and applications to maximize performance and reusability.

- The last section of the book covers the broader async ecosystem, and provides
a number of examples of how to accomplish common tasks.
-->
<ul>
<li>
<p>Les chapitres du début initient à la programmation asynchrone en général, et
comment Rust l'a interprété.</p>
</li>
<li>
<p>Les chapitres intermédiaires présentent les principaux utilitaires et outils
de contrôle que vous pouvez utiliser lorsque vous écrivez du code asynchrone,
et explique les bonnes pratiques pour structurer les bibliothèques et les
applications afin d'optimiser les performances et la réutilisation.</p>
</li>
<li>
<p>La dernière section du livre aborde plus largement l'écosystème asynchrone,
et propose un certain nombre d'exemples pour répondre à des besoins courants.</p>
</li>
</ul>
<!--
With that out of the way, let's explore the exciting world of Asynchronous
Programming in Rust!
-->
<p>Maintenant que vous savez cela, commençons à explorer le monde excitant de la
programmation asynchrone avec Rust !</p>
<p>Ce livre est la traduction française de la version Anglaise du livre
<a href="https://rust-lang.github.io/async-book/index.html">Asynchronous Programming in Rust</a>.
Si vous souhaitez contribuer à cette traduction, vous trouverez <a href="https://github.com/Jimskapt/async-book-fr">le dépôt de
son code sur GitHub</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--1"><a class="header" href="#-attention-peinture-fraîche--1">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/2">Pull Request</a>.</p>
</blockquote>
<!--
# Why Async?
-->
<h1 id="pourquoi-lasynchrone-"><a class="header" href="#pourquoi-lasynchrone-">Pourquoi l'asynchrone ?</a></h1>
<!--
We all love how Rust empowers us to write fast, safe software.
But how does asynchronous programming fit into this vision?
-->
<p>Nous apprécions tous la façon dont Rust nous permet d'écrire rapidement des
programmes sûrs. Mais comment la programmation asynchrone s'inscrit-elle dans
cette démarche ?</p>
<!--
Asynchronous programming, or async for short, is a _concurrent programming model_
supported by an increasing number of programming languages.
It lets you run a large number of concurrent
tasks on a small number of OS threads, while preserving much of the
look and feel of ordinary synchronous programming, through the
`async/await` syntax.
-->
<p>La programmation asynchrone, abrégé async, est un <em>modèle de programmation
concurrent</em> pris en charge par un nombre croissant de langages de
programmation. Il vous permet d'exécuter un grand nombre de tâches concurrentes
sur un petit nombre de processus du Système d'Exploitation, tout en conservant
l'apparence et la convivialité de la programmation synchrone habituelle, grâce
à la syntaxe <code>async/await</code>.</p>
<!--
## Async vs other concurrency models
-->
<h2 id="lasynchrone-et-les-autres-modèles-de-concurrence"><a class="header" href="#lasynchrone-et-les-autres-modèles-de-concurrence">L'asynchrone et les autres modèles de concurrence</a></h2>
<!--
Concurrent programming is less mature and "standardized" than
regular, sequential programming. As a result, we express concurrency
differently depending on which concurrent programming model
the language is supporting.
A brief overview of the most popular concurrency models can help
you understand how asynchronous programming fits within the broader
field of concurrent programming:
-->
<p>La programmation concurrente est moins mûre et moins &quot;formalisée&quot; que la
programmation séquentielle classique. Par conséquent, nous formulons la
concurrence différemment selon le modèle de programmation pris en charge par le
langage.
Un bref panorama des modèles de concurrence les plus populaires peut vous aider
à comprendre où se situe la programmation asynchrone dans le domaine plus large
de la programmation asynchrone :</p>
<!--
- **OS threads** don't require any changes to the programming model,
  which makes it very easy to express concurrency. However, synchronizing
  between threads can be difficult, and the performance overhead is large.
  Thread pools can mitigate some of these costs, but not enough to support
  massive IO-bound workloads.
- **Event-driven programming**, in conjunction with _callbacks_, can be very
  performant, but tends to result in a verbose, "non-linear" control flow.
  Data flow and error propagation is often hard to follow.
- **Coroutines**, like threads, don't require changes to the programming model,
  which makes them easy to use. Like async, they can also support a large
  number of tasks. However, they abstract away low-level details that
  are important for systems programming and custom runtime implementors.
- **The actor model** divides all concurrent computation into units called
  actors, which communicate through fallible message passing, much like
  in distributed systems. The actor model can be efficiently implemented, but it leaves
  many practical issues unanswered, such as flow control and retry logic.
-->
<ul>
<li>Les <strong>processus du système d'exploitation</strong> ne nécessitent aucun changement
dans le modèle de programmation, ce qui facilite l'expression de la
concurrence. Cependant, la synchronisation entre les processus peut être
difficile, et la conséquence sur les performances est importante. Les groupes
de processus peuvent réduire certains coûts, mais pas suffisamment pour faire
face à la charge de travail d'une grosse masse d'entrées/sorties.</li>
<li>La <strong>programmation orientée évènements</strong>, conjuguée avec les <em>fonctions de
rappel</em>, peut s'avérer très performante, mais a tendance à produire un
contrôle de flux &quot;non-linéaire&quot; et verbeux. Les flux de données et les
propagations d'erreurs sont souvent difficiles à suivre.</li>
<li>Les <strong>coroutines</strong>, comme les processus, ne nécessitent pas de changements
sur le modèle de programmation, ce qui facilite leur utilisation. Comme
l'asynchrone, elles peuvent supporter de nombreuses tâches. Cependant, elles
font abstraction des détails de bas niveau, qui sont importants pour la
programmation système et les implémentations personnalisées d'environnements
d'exécution.</li>
<li>Le <strong>modèle acteur</strong> divise tous les calculs concurrents en différentes
parties que l'on appelle acteurs, qui communiquent par le biais de passage de
messages faillibles, comme dans les systèmes distribués. Le modèle d'acteur
peut être implémenté efficacement, mais il ne répondra pas à tous les
problèmes, comme le contrôle de flux et la logique de relance.</li>
</ul>
<!--
In summary, asynchronous programming allows highly performant implementations
that are suitable for low-level languages like Rust, while providing
most of the ergonomic benefits of threads and coroutines.
-->
<p>En résumé, la programmation asynchrone permet des implémentations très
performantes qui sont nécessaires pour des langages bas-niveau comme Rust, tout
en offrant les avantages ergonomiques aux processus et aux coroutines.</p>
<!--
## Async in Rust vs other languages
-->
<h2 id="lasynchrone-en-rust-et-dans-les-autres-langages"><a class="header" href="#lasynchrone-en-rust-et-dans-les-autres-langages">L'asynchrone en Rust et dans les autres langages</a></h2>
<!--
Although asynchronous programming is supported in many languages, some
details vary across implementations. Rust's implementation of async
differs from most languages in a few ways:
-->
<p>Bien que la programmation asynchrone soit prise en charge dans de nombreux
langages, certains détails changent selon les implémentations. L'implémentation
en Rust de async se distingue des autres langages de plusieurs manières :</p>
<!--
- **Futures are inert** in Rust and make progress only when polled. Dropping a
  future stops it from making further progress.
- **Async is zero-cost** in Rust, which means that you only pay for what you use.
  Specifically, you can use async without heap allocations and dynamic dispatch,
  which is great for performance!
  This also lets you use async in constrained environments, such as embedded systems.
- **No built-in runtime** is provided by Rust. Instead, runtimes are provided by
  community maintained crates.
- **Both single- and multithreaded** runtimes are available in Rust, which have
  different strengths and weaknesses.
-->
<ul>
<li>Les <strong>futures sont inertes</strong> en Rust et progressent uniquement lorsqu'elles
sont sollicitées. Libérer une future va arrêter sa progression.</li>
<li><strong>L'asynchrone n'a pas de coût</strong> en Rust, ce qui signifie que vous ne payez que
ce que vous utilisez. Plus précisément, vous pouvez utiliser async sans
allouer sur le tas et sans répartition dynamique, ce qui est très intéressant
pour les performances !
Cela vous permet également d'utiliser async dans des environnements
restreints, comme par exemple sur des systèmes embarqués.</li>
<li><strong>Il n'y a pas d'environnement d'exécution intégré</strong> par défaut dans Rust. Par
contre, des environnements d'exécution sont disponibles dans des crates maintenues
par la communauté.</li>
<li><strong>Des environnements d'exécution mono-processus et multi-processus</strong> existent
en Rust, qui ont chacun leurs avantages et inconvénients.</li>
</ul>
<!--
## Async vs threads in Rust
-->
<h2 id="lasynchrone-et-les-processus-en-rust"><a class="header" href="#lasynchrone-et-les-processus-en-rust">L'asynchrone et les processus en Rust</a></h2>
<!--
The primary alternative to async in Rust is using OS threads, either
directly through [`std::thread`](https://doc.rust-lang.org/std/thread/)
or indirectly through a thread pool.
Migrating from threads to async or vice versa
typically requires major refactoring work, both in terms of implementation and
(if you are building a library) any exposed public interfaces. As such,
picking the model that suits your needs early can save a lot of development time.
-->
<p>La première alternative à l'asynchrone en Rust est d'utiliser les processus du
Système d'Exploitation, soit directement via
<a href="https://doc.rust-lang.org/std/thread/"><code>std::thread</code></a>, soit indirectement via
un groupe de processus.
La migration des processus vers de l'asynchrone et vice-versa nécessite
généralement un gros chantier de remaniement, que ce soit pour leur implémentation
ou pour leurs interfaces publique (si vous écrivez une bibliothèque) . Par
conséquent, vous pouvez vous épargner beaucoup de temps de développement si
vous choisissez très tôt le modèle qui convient bien à vos besoins.</p>
<!--
**OS threads** are suitable for a small number of tasks, since threads come with
CPU and memory overhead. Spawning and switching between threads
is quite expensive as even idle threads consume system resources.
A thread pool library can help mitigate some of these costs, but not all.
However, threads let you reuse existing synchronous code without significant
code changes—no particular programming model is required.
In some operating systems, you can also change the priority of a thread,
which is useful for drivers and other latency sensitive applications.
-->
<p>Les <strong>processus de Système d'Exploitation</strong> sont préférables pour un petit
nombre de tâches, puisque les processus s'accompagnent d'une surcharge du
processeur et de la mémoire. Créer et basculer entre les processus est assez
gourmand, car même les processus inutilisés consomment des ressources système.
Une bibliothèque implémentant des groupe de tâches peut aider à atténuer certains
coûts, mais pas tous. Cependant, les processus vous permet de réutiliser du code
synchrone existant sans avoir besoin de changement significatif du code — il n'y
a pas besoin d'avoir de modèle de programmation en particulier.
Avec certains systèmes d'exploitation, vous pouvez aussi changer la priorité
d'un processus, ce qui peut être pratique pour les pilotes et les autres
utilisations sensibles à la latence.</p>
<!--
**Async** provides significantly reduced CPU and memory
overhead, especially for workloads with a
large amount of IO-bound tasks, such as servers and databases.
All else equal, you can have orders of magnitude more tasks than OS threads,
because an async runtime uses a small amount of (expensive) threads to handle
a large amount of (cheap) tasks.
However, async Rust results in larger binary blobs due to the state
machines generated from async functions and since each executable
bundles an async runtime.
-->
<p><strong>L'asynchrone</strong> permet de réduire significativement la surcharge du processeur
et de la mémoire, en particulier pour les charges de travail avec un grand
nombre de tâches liées à des entrées/sorties, comme les serveurs et les bases
de données. Pour comparaison à la même échelle, vous pouvez avoir un nombre bien
plus élevé de tâches qu'avec les processus du Système d'Exploitation, car comme
un environnement d'exécution asynchrone utilise une petite partie des (coûteux)
processus pour gérer une grande quantité de tâches (peu coûteuses).
Cependant, le Rust asynchrone produit des binaires plus lourds à cause des
machines à états générés à partir des fonctions asynchrones et que par conséquent
chaque exécutable embarque un environnement d'exécution asynchrone.</p>
<!--
On a last note, asynchronous programming is not _better_ than threads,
but different.
If you don't need async for performance reasons, threads can often be
the simpler alternative.
-->
<p>Une dernière remarque, la programmation asynchrone n'est pas <em>meilleure</em> que
les processus, c'est différent.
Si vous n'avez pas besoin de l'asynchrone pour des raisons de performance, les
processus sont souvent une alternative plus simple.</p>
<!--
### Example: Concurrent downloading
-->
<h3 id="exemple--un-téléchargement-concurrent"><a class="header" href="#exemple--un-téléchargement-concurrent">Exemple : un téléchargement concurrent</a></h3>
<!--
In this example our goal is to download two web pages concurrently.
In a typical threaded application we need to spawn threads
to achieve concurrency:
-->
<p>Dans cet exemple, notre objectif est de télécharger deux pages web en
concurrence. Dans une application traditionnelle avec des processus nous avons
besoin de créer des processus pour appliquer la concurrence :</p>
<!--
```rust,ignore
fn get_two_sites() {
    // Spawn two threads to do work.
    let thread_one = thread::spawn(|| download("https://www.foo.com"));
    let thread_two = thread::spawn(|| download("https://www.bar.com"));

    // Wait for both threads to complete.
    thread_one.join().expect("thread one panicked");
    thread_two.join().expect("thread two panicked");
}
```
-->
<pre><code class="language-rust ignore">fn recuperer_deux_sites() {
    // Crée deux tâches pour faire le travail.
    let premiere_tache = std::thread::spawn(|| telecharger(&quot;https://www.foo.com&quot;));
    let seconde_tache = std::thread::spawn(|| telecharger(&quot;https://www.bar.com&quot;));

    // Attente que les deux tâches se terminent.
    premiere_tache.join().expect(&quot;la première tâche a paniqué&quot;);
    seconde_tache.join().expect(&quot;la deuxième tâche a paniqué&quot;);
}
</code></pre>
<!--
However, downloading a web page is a small task; creating a thread
for such a small amount of work is quite wasteful. For a larger application, it
can easily become a bottleneck. In async Rust, we can run these tasks
concurrently without extra threads:
-->
<p>Cependant, le téléchargement d'une page web est une petite tâche, donc créer un
processus pour une si petite quantité de travail est un peu du gaspillage. Pour
une application plus importante, cela peut rapidement devenir un goulot
d'étranglement. Grâce au Rust asynchrone, nous pouvons exécuter ces tâches en
concurrence sans avoir besoin de processus supplémentaires :</p>
<!--
```rust,ignore
async fn get_two_sites_async() {
    // Create two different "futures" which, when run to completion,
    // will asynchronously download the webpages.
    let future_one = download_async("https://www.foo.com");
    let future_two = download_async("https://www.bar.com");

    // Run both futures to completion at the same time.
    join!(future_one, future_two);
}
```
-->
<pre><code class="language-rust ignore">async fn recuperer_deux_sites_asynchrone() {
    // Crée deux différentes &quot;futures&quot; qui, lorsqu'elles sont menée à terme,
    // va télécharger les pages web de manière asynchrone.
    let premier_future = telecharger_asynchrone(&quot;https://www.foo.com&quot;);
    let second_future = telecharger_asynchrone(&quot;https://www.bar.com&quot;);

    // Exécute les deux futures en même temps jusqu'à leur fin.
    futures::join!(premier_future, second_future);
}
</code></pre>
<!--
Here, no extra threads are created. Additionally, all function calls are statically
dispatched, and there are no heap allocations!
However, we need to write the code to be asynchronous in the first place,
which this book will help you achieve.
-->
<p>Notez bien que ici, il n'y a pas de processus supplémentaires qui sont créés.
De plus, tous les appels à des fonctions sont distribués statiquement, et il
n'y a pas d'allocation sur le tas !
Cependant, nous avons d'abord besoin d'écrire le code pour être asynchrone, ce
que ce livre va vous aider à accomplir.</p>
<!--
## Custom concurrency models in Rust
-->
<h2 id="les-modèles-personnalisés-de-concurrence-en-rust"><a class="header" href="#les-modèles-personnalisés-de-concurrence-en-rust">Les modèles personnalisés de concurrence en Rust</a></h2>
<!--
On a last note, Rust doesn't force you to choose between threads and async.
You can use both models within the same application, which can be
useful when you have mixed threaded and async dependencies.
In fact, you can even use a different concurrency model altogether,
such as event-driven programming, as long as you find a library that
implements it.
-->
<p>Une dernière remarque, Rust ne vous forçait pas à choisir entre les
processus et l'asynchrone. Vous pouvez utiliser ces deux modèles au sein d'une
même application, ce qui peut être utile lorsque vous mélangez les dépendances
de processus et d'asynchrone.
En fait, vous pouvez même utiliser un modèle de concurrence complètement
différent en même temps, du moment que vous trouvez une bibliothèque qui
l'implémente.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--2"><a class="header" href="#-attention-peinture-fraîche--2">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/3">Pull Request</a>.</p>
</blockquote>
<!--
# The State of Asynchronous Rust
-->
<h1 id="létat-de-lart-de-lasynchrone-en-rust"><a class="header" href="#létat-de-lart-de-lasynchrone-en-rust">L'état de l'art de l'asynchrone en Rust</a></h1>
<!--
Parts of async Rust are supported with the same stability guarantees as
synchronous Rust. Other parts are still maturing and will change
over time. With async Rust, you can expect:
-->
<p>Certaines parties du Rust asynchrone sont pris en charge avec les mêmes
garanties de stabilité que le Rust synchrone. Les autres parties sont en cours
de perfectionnement et évolueront dans le temps. Voici ce que vous pouvez
attendre du Rust asynchrone :</p>
<!--
- Outstanding runtime performance for typical concurrent workloads.
- More frequent interaction with advanced language features, such as lifetimes
  and pinning.
- Some compatibility constraints, both between sync and async code, and between
  different async runtimes.
- Higher maintenance burden, due to the ongoing evolution of async runtimes
  and language support.
-->
<ul>
<li>D'excellentes performances à l'exécution des charges de travail en concurrence
classiques.</li>
<li>Une interaction plus régulière avec les fonctionnalités avancées du langage,
comme les durées de vie et l'épinglage.</li>
<li>Des contraintes de compatibilité, à la fois entre le code synchrone et
asynchrone, et entre les différents environnements d'exécution.</li>
<li>Une plus grande exigence de maintenance, à cause de l'évolution continue des
environnements d'exécution asynchrones et du langage.</li>
</ul>
<!--
In short, async Rust is more difficult to use and can result in a higher
maintenance burden than synchronous Rust,
but gives you best-in-class performance in return.
All areas of async Rust are constantly improving,
so the impact of these issues will wear off over time.
-->
<p>En résumé, le Rust asynchrone est plus difficile à utiliser et peut demander
plus de maintenance que le Rust synchrone, mais il vous procure en retour les
meilleures performances dans le domaine. Tous les éléments du Rust asynchrone
dont en constante amélioration, donc les effets de ces contre-parties
s'estomperont avec le temps.</p>
<!--
## Language and library support
-->
<h2 id="la-prise-en-charge-des-bibliothèques-et-du-langage"><a class="header" href="#la-prise-en-charge-des-bibliothèques-et-du-langage">La prise en charge des bibliothèques et du langage</a></h2>
<!--
While asynchronous programming is supported by Rust itself,
most async applications depend on functionality provided
by community crates.
As such, you need to rely on a mixture of
language features and library support:
-->
<p>Bien que la programmation asynchrone soit fournie par le coeur de Rust, la
plupart des applications asynchrones dépendent des fonctionnalités offertes
par les crates de la communauté.
Par conséquent, vous devez avoir recours à un mélange de fonctionnalités
offertes par le langage et les bibliothèques :</p>
<!--
- The most fundamental traits, types and functions, such as the
  [`Future`](https://doc.rust-lang.org/std/future/trait.Future.html) trait
  are provided by the standard library.
- The `async/await` syntax is supported directly by the Rust compiler.
- Many utility types, macros and functions are provided by the
  [`futures`](https://docs.rs/futures/) crate. They can be used in any async
  Rust application.
- Execution of async code, IO and task spawning are provided by "async
  runtimes", such as Tokio and async-std. Most async applications, and some
  async crates, depend on a specific runtime. See
  ["The Async Ecosystem"](../08_ecosystem/00_chapter.md) section for more
  details.
-->
<ul>
<li>Les traits, types et fonctions les plus fondamentaux, comme le trait
<a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>Future</code></a>, sont
fournis par la bibliothèque standard.</li>
<li>La syntaxe <code>async/await</code> est prise en charge directement par le compilateur
Rust.</li>
<li>De nombreux types, macros et fonctions utilitaires sont fournis par la crate
<a href="https://docs.rs/futures/"><code>futures</code></a>. Ils peuvent être utilisés dans de
nombreuses applications asynchrones en Rust.</li>
<li>L'exécution du code asynchrone, les entrées/sorties, et la création de tâches
sont prises en charge par les &quot;environnements d'exécution asynchrone&quot;, comme
Tokio et async-std. La plupart des applications asynchrones, et certaines
crates asynchrones, dépendent d'un environnement d'exécution précis. Vous
pouvez consulter la section
<a href="01_getting_started/../08_ecosystem/00_chapter.html">&quot;L'écosystème asynchrone&quot;</a> pour en savoir
plus.</li>
</ul>
<!--
Some language features you may be used to from synchronous Rust are not yet
available in async Rust. Notably, Rust does not let you declare async
functions in traits. Instead, you need to use workarounds to achieve the same
result, which can be more verbose.
-->
<p>Certaines fonctionnalités du langage auquel vous êtes habitué en Rust synchrone
peuvent ne pas encore être disponible en Rust asynchrone. Par exemple, Rust ne
vous permet pas encore de déclarer des fonctions asynchrones dans des traits.
Par conséquent, vous avez besoin de mettre en place des solutions de
substitution pour arriver au même résultat, ce qui peut rendre les choses un
peu plus verbeuses.</p>
<!--
## Compiling and debugging
-->
<h2 id="la-compilation-et-le-débogage"><a class="header" href="#la-compilation-et-le-débogage">La compilation et le débogage</a></h2>
<!--
For the most part, compiler- and runtime errors in async Rust work
the same way as they have always done in Rust. There are a few
noteworthy differences:
-->
<p>Dans la plupart des cas, les erreurs du compilateur et d'exécution du Rust
asynchrone fonctionnent de la même manière qu'elles l'ont toujours fait en
Rust. Voici quelques différences intéressantes :</p>
<!--
### Compilation errors
-->
<h3 id="les-erreurs-de-compilation"><a class="header" href="#les-erreurs-de-compilation">Les erreurs de compilation</a></h3>
<!--
Compilation errors in async Rust conform to the same high standards as
synchronous Rust, but since async Rust often depends on more complex language
features, such as lifetimes and pinning, you may encounter these types of
errors more frequently.
-->
<p>Les erreurs de compilateur en Rust asynchrone suivent les mêmes règles strictes
que le Rust synchrone, mais comme le Rust asynchrone dépend souvent de
fonctionnalités du langage plus élaborées, comme les durées de vie
et l'épinglage, vous pourriez rencontrer plus régulièrement ces types
d'erreurs.</p>
<!--
### Runtime errors
-->
<h3 id="les-erreurs-à-lexécution"><a class="header" href="#les-erreurs-à-lexécution">Les erreurs à l'exécution</a></h3>
<!--
Whenever the compiler encounters an async function, it generates a state
machine under the hood. Stack traces in async Rust typically contain details
from these state machines, as well as function calls from
the runtime. As such, interpreting stack traces can be a bit more involved than
it would be in synchronous Rust.
-->
<p>A chaque fois que le compilateur va rencontrer une fonction asynchrone, il va
générer une machine à états en arrière-plan. Les traces de la pile en Rust
asynchrone contiennent généralement des informations sur ces machines à états,
ainsi que les appels de fonctions de l'environnement d'exécution. Par
conséquent, l'interprétation des traces de la pile peut être un peu plus ardue
qu'elle le serait en Rust synchrone.</p>
<!--
### New failure modes
-->
<h3 id="les-nouveaux-types-derreurs"><a class="header" href="#les-nouveaux-types-derreurs">Les nouveaux types d'erreurs</a></h3>
<!--
A few novel failure modes are possible in async Rust, for instance
if you call a blocking function from an async context or if you implement
the `Future` trait incorrectly. Such errors can silently pass both the
compiler and sometimes even unit tests. Having a firm understanding
of the underlying concepts, which this book aims to give you, can help you
avoid these pitfalls.
-->
<p>Quelques nouveaux types d'erreurs sont possibles avec Rust asynchrone, par
exemple si vous appelez une fonction bloquante à partir d'un contexte
asynchrone ou si vous n'implémentez pas correctement le trait <code>Future</code>. Ces
erreurs peuvent ne pas être signalées par le compilateur et parfois même ne
peuvent pas être couvertes par vos tests unitaires. Le but de ce livre est
de vous apprendre les principes fondamentaux pour vous aider à éviter ces
pièges.</p>
<!--
## Compatibility considerations
-->
<h2 id="remarques-à-propos-de-la-compatibilité"><a class="header" href="#remarques-à-propos-de-la-compatibilité">Remarques à propos de la compatibilité</a></h2>
<!--
Asynchronous and synchronous code cannot always be combined freely.
For instance, you can't directly call an async function from a sync function.
Sync and async code also tend to promote different design patterns, which can
make it difficult to compose code intended for the different environments.
-->
<p>Le code asynchrone et synchrone ne peuvent pas toujours être combinés
librement. Par exemple, vous ne pouvez pas appeler directement une fonction
asynchrone à partir d'une fonction synchrone. Le code synchrone et asynchrone
ont aussi tendance à favoriser des motifs de conception différents, ce qui
peut rendre difficile de combiner du code destiné aux différents
environnements.</p>
<!--
Even async code cannot always be combined freely. Some crates depend on a
specific async runtime to function. If so, it is usually specified in the
crate's dependency list.
-->
<p>Et même le code asynchrone ne peut pas être combiné librement. Certaines crates
dépendent d'un environnement d'exécution asynchrone pour fonctionner. Si c'est
le cas, c'est souvent précisé dans la liste des dépendances de la crate.</p>
<!--
These compatibility issues can limit your options, so make sure to
research which async runtime and what crates you may need early.
Once you have settled in with a runtime, you won't have to worry
much about compatibility.
-->
<p>Ces problèmes de compatibilité peuvent réduire vos options, donc il vaut mieux
faire assez tôt vos recherches sur les environnements d'exécution asynchrone et
de leurs crates associées. Une fois que vous vous êtes installé dans un
environnement d'exécution, vous n'aurez plus à vous soucier de la
compatibilité.</p>
<!--
## Performance characteristics
-->
<h2 id="les-performances"><a class="header" href="#les-performances">Les performances</a></h2>
<!--
The performance of async Rust depends on the implementation of the
async runtime you're using.
Even though the runtimes that power async Rust applications are relatively new,
they perform exceptionally well for most practical workloads.
-->
<p>Les performances du Rust asynchrone dépend de l'implémentation de
l'environnement d'exécution asynchrone que vous choisissez.
Même si les environnements d'exécution qui propulsent les applications
asynchrones en Rust sont relativement récents, ils sont remarquablement
performants pour la plupart des charges de travail.</p>
<!--
That said, most of the async ecosystem assumes a _multi-threaded_ runtime.
This makes it difficult to enjoy the theoretical performance benefits
of single-threaded async applications, namely cheaper synchronization.
Another overlooked use-case is _latency sensitive tasks_, which are
important for drivers, GUI applications and so on. Such tasks depend
on runtime and/or OS support in order to be scheduled appropriately.
You can expect better library support for these use cases in the future.
-->
<p>Ceci étant dit, la plupart des écosystèmes asynchrones prévoient un
environnement d'exécution <em>multi-processus</em>. Cela rend plus difficile
d'apprécier les bienfaits sur les performances théoriques des applications
asynchrone sur un seul processus, appelée aussi synchronisation allégée.
Un autre domaine d'application sous-côté est celui des <em>tâches sensibles à la
latence</em>, qui sont importantes pour les pilotes, les applications avec
interface graphique, parmi d'autres. Ces tâches dépendent de l'environnement
d'exécution et/ou de la prise en charge du système d'exploitation pour être
orchestrées correctement. Vous pouvez donc espérer une meilleure prise en
charge à l'avenir des bibliothèques de ces cas d'usages.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--3"><a class="header" href="#-attention-peinture-fraîche--3">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/4">Pull Request</a>.</p>
</blockquote>
<!--
# `async`/`.await` Primer
-->
<h1 id="introduction-à-async-et-await"><a class="header" href="#introduction-à-async-et-await">Introduction à <code>async</code> et <code>await</code></a></h1>
<!--
`async`/`.await` is Rust's built-in tool for writing asynchronous functions
that look like synchronous code. `async` transforms a block of code into a
state machine that implements a trait called `Future`. Whereas calling a
blocking function in a synchronous method would block the whole thread,
blocked `Future`s will yield control of the thread, allowing other
`Future`s to run.
-->
<p>Le <code>async</code> et <code>await</code> sont les outils intégrés dans Rust pour écrire des
fonctions asynchrones qui ressemblent à du code synchrone. <code>async</code> transforme
un bloc de code en une machine à états qui implémente le trait <code>Future</code>. Alors
que l'appel à une fonction bloquante dans une méthode synchrone va bloquer tout
le processus, les <code>Future</code>s bloquées céderont le contrôle du processus,
permettant aux autres <code>Future</code>s de s'exécuter.</p>
<!--
Let's add some dependencies to the `Cargo.toml` file:
-->
<p>Ajoutons quelques dépendances au fichier <code>Cargo.toml</code> :</p>
<!--
```toml
[dependencies]
futures = "0.3"
```
-->
<pre><code class="language-toml">[dependencies]
futures = &quot;0.3&quot;
</code></pre>
<!--
To create an asynchronous function, you can use the `async fn` syntax:
-->
<p>Pour créer une fonction asynchrone, vous pouvez utiliser la syntaxe
<code>async fn</code> :</p>
<!--
```rust,edition2018
async fn do_something() { /* ... */ }
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn faire_quelquechose() { /* ... */ }
<span class="boring">}
</span></code></pre></pre>
<!--
The value returned by `async fn` is a `Future`. For anything to happen,
the `Future` needs to be run on an executor.
-->
<p>La valeur retournée par <code>async fn</code> est une <code>Future</code>. Pour que quelque chose se
produise, la <code>Future</code> a besoin d'être exécutée avec un exécuteur.</p>
<!--
```rust,edition2018
// `block_on` blocks the current thread until the provided future has run to
// completion. Other executors provide more complex behavior, like scheduling
// multiple futures onto the same thread.
use futures::executor::block_on;

async fn hello_world() {
    println!("hello, world!");
}

fn main() {
    let future = hello_world(); // Nothing is printed
    block_on(future); // `future` is run and "hello, world!" is printed
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">// `block_on` bloque le processus en cours jusqu'à ce que la future qu'on lui
// donne ait terminé son exécution. Les autres exécuteurs ont un comportement
// plus complexe, comme par exemple ordonnancer plusieurs futures sur le même
// processus.
use futures::executor::block_on;

async fn salutations() {
    println!(&quot;salutations !&quot;);
}

fn main() {
    let future = salutations(); // rien n'est pas affiché
    block_on(future); // `future` est exécuté et &quot;salutations !&quot; est affiché
}
</code></pre></pre>
<!--
Inside an `async fn`, you can use `.await` to wait for the completion of
another type that implements the `Future` trait, such as the output of
another `async fn`. Unlike `block_on`, `.await` doesn't block the current
thread, but instead asynchronously waits for the future to complete, allowing
other tasks to run if the future is currently unable to make progress.
-->
<p>Dans une <code>async fn</code>, vous pouvez utiliser <code>.await</code> pour attendre la fin d'un
autre type qui implémente le trait <code>Future</code>, comme le résultat d'une autre
<code>async fn</code>. Contrairement à <code>block_on</code>, <code>.await</code> ne bloque pas le processus en
cours, mais attends plutôt de manière asynchrone que la future se termine, pour
permettre aux autres tâches de s'exécuter si cette future n'est pas en mesure de
progresser actuellement.</p>
<!--
For example, imagine that we have three `async fn`: `learn_song`, `sing_song`,
and `dance`:
-->
<p>Par exemple, imaginons que nous ayons trois <code>async fn</code> : <code>apprendre_chanson</code>,
<code>chanter_chanson</code>, et <code>danser</code> :</p>
<!--
```rust,ignore
async fn learn_song() -> Song { /* ... */ }
async fn sing_song(song: Song) { /* ... */ }
async fn dance() { /* ... */ }
```
-->
<pre><code class="language-rust ignore">async fn apprendre_chanson() -&gt; Chanson { /* ... */ }
async fn chanter_chanson(chanson: Chanson) { /* ... */ }
async fn danser() { /* ... */ }
</code></pre>
<!--
One way to do learn, sing, and dance would be to block on each of these
individually:
-->
<p>Une façon d'apprendre, chanter, et danser serait de bloquer sur chacun :</p>
<!--
```rust,ignore
fn main() {
    let song = block_on(learn_song());
    block_on(sing_song(song));
    block_on(dance());
}
```
-->
<pre><code class="language-rust ignore">fn main() {
    let chanson = block_on(apprendre_chanson());
    block_on(chanter_chanson(chanson));
    block_on(danser());
}
</code></pre>
<!--
However, we're not giving the best performance possible this way—we're
only ever doing one thing at once! Clearly we have to learn the song before
we can sing it, but it's possible to dance at the same time as learning and
singing the song. To do this, we can create two separate `async fn` which
can be run concurrently:
-->
<p>Cependant, nous ne profitons pas de performances optimales de cette manière —
nous ne faisons qu'une seule chose à fois ! Il faut que nous apprenions la
chanson avant de pouvoir la chanter, mais il reste possible de danser en même
temps qu'on apprends et qu'on chante la chanson. Pour pouvoir faire cela, nous
pouvons créer deux <code>async fn</code> qui peuvent être exécutés en concurrence :</p>
<!--
```rust,ignore
async fn learn_and_sing() {
    // Wait until the song has been learned before singing it.
    // We use `.await` here rather than `block_on` to prevent blocking the
    // thread, which makes it possible to `dance` at the same time.
    let song = learn_song().await;
    sing_song(song).await;
}

async fn async_main() {
    let f1 = learn_and_sing();
    let f2 = dance();

    // `join!` is like `.await` but can wait for multiple futures concurrently.
    // If we're temporarily blocked in the `learn_and_sing` future, the `dance`
    // future will take over the current thread. If `dance` becomes blocked,
    // `learn_and_sing` can take back over. If both futures are blocked, then
    // `async_main` is blocked and will yield to the executor.
    futures::join!(f1, f2);
}

fn main() {
    block_on(async_main());
}
```
-->
<pre><code class="language-rust ignore">async fn apprendre_et_chanter() {
    // Attends (await) que la chanson soit apprise avant de la chanter.
    // Nous utilisons ici `.await` plutôt que `block_on` pour éviter de bloquer
    // le processus, ce qui rend possible de `danser` en même temps.
    let chanson = apprendre_chanson().await;
    chanter_chanson(chanson).await;
}

async fn async_main() {
    let f1 = apprendre_et_chanter();
    let f2 = danser();

    // `join!` se comporte comme `.await`, mais permet d'attendre plusieurs
    // futures en concurrence. Si nous avions bloqué temporairement dans la
    // future `apprendre_et_chanter`, la future `danser` aurais pris le relais
    // dans le processus d'exécution en cours. Si `danser` se bloque aussi,
    // `apprendre_et_chanter` pourra continuer dans le processus en cours. Si
    // les deux futures sont bloquées, et bien `async_main` est bloqué et va en
    // informer son exécuteur.
    futures::join!(f1, f2);
}

fn main() {
    block_on(async_main());
}
</code></pre>
<!--
In this example, learning the song must happen before singing the song, but
both learning and singing can happen at the same time as dancing. If we used
`block_on(learn_song())` rather than `learn_song().await` in `learn_and_sing`,
the thread wouldn't be able to do anything else while `learn_song` was running.
This would make it impossible to dance at the same time. By `.await`-ing
the `learn_song` future, we allow other tasks to take over the current thread
if `learn_song` is blocked. This makes it possible to run multiple futures
to completion concurrently on the same thread.
-->
<p>Dans cet exemple, la chanson doit être apprise avant de chanter la chanson,
mais l'apprentissage et le chant peuvent se dérouler en même temps qu'on
danse. Si nous avions utilisé <code>block_on(apprendre_chanson())</code> plutôt que
<code>apprendre_chanson().await</code> dans <code>apprendre_et_chanter</code>, le processus n'aurait
rien pu faire tant que <code>apprendre_chanson</code> s'exécutait. Cela aurait rendu
impossible de pouvoir danser en même temps. En attendant la future
<code>apprendre_chanson</code>, grâce à <code>await</code>, nous permettons aux autres tâches de
prendre le relais dans le processus en cours d'exécution lorsque
<code>apprendre_chanson</code> est bloqué. Cela permet d'exécuter plusieurs futures
jusqu'à leur fin de manière concurrente au sein du même processus.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--4"><a class="header" href="#-attention-peinture-fraîche--4">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/5">Pull Request</a>.</p>
</blockquote>
<!--
# Under the Hood: Executing `Future`s and Tasks
-->
<h1 id="sous-le-capot--exécuter-les-futures-et-les-tâches"><a class="header" href="#sous-le-capot--exécuter-les-futures-et-les-tâches">Sous le capot : exécuter les <code>Future</code>s et les tâches</a></h1>
<!--
In this section, we'll cover the underlying structure of how `Future`s and
asynchronous tasks are scheduled. If you're only interested in learning
how to write higher-level code that uses existing `Future` types and aren't
interested in the details of how `Future` types work, you can skip ahead to
the `async`/`await` chapter. However, several of the topics discussed in this
chapter are useful for understanding how `async`/`await` code works,
understanding the runtime and performance properties of `async`/`await` code,
and building new asynchronous primitives. If you decide to skip this section
now, you may want to bookmark it to revisit in the future.
-->
<p>Dans cette section, nous allons étudier la structure sous-jacente de
l'ordonnancement des <code>Future</code>s et des tâches asynchrones. Si vous vous intéressez
uniquement à l'apprentissage de l'écriture de code de haut niveau qui utilise
les types <code>Future</code> existants et que vous n'êtes pas intéressés par détails du
fonctionnement des types <code>Future</code>, vous pouvez passer au chapitre suivant.
Cependant, certains sujets abordés dans ce chapitre sont utiles pour comprendre
comment le code de <code>async</code> et <code>await</code> fonctionne, comprendre l'environnement
d'exécution et les caractéristiques de performance du code <code>async</code> et <code>await</code>,
ainsi que la création de nouvelles primitives asynchrones.
Si vous décidez de sauter cette section, vous devriez le marquer pour revenir le
consulter à nouveau.</p>
<!--
Now, with that out of the way, let's talk about the `Future` trait.
-->
<p>Maintenance que vous savez cela, commençons par parler du trait <code>Future</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-future-trait"><a class="header" href="#the-future-trait">The <code>Future</code> Trait</a></h1>
<p>Cette page n'a pas encore été traduite.</p>
<p><a href="https://rust-lang.github.io/async-book/02_execution/02_future.html">Consulter cette page en Anglais</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="task-wakeups-with-waker"><a class="header" href="#task-wakeups-with-waker">Task Wakeups with <code>Waker</code></a></h1>
<p>Cette page n'a pas encore été traduite.</p>
<p><a href="https://rust-lang.github.io/async-book/02_execution/03_wakeups.html">Consulter cette page en Anglais</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="applied-build-an-executor"><a class="header" href="#applied-build-an-executor">Applied: Build an Executor</a></h1>
<p>Cette page n'a pas encore été traduite.</p>
<p><a href="https://rust-lang.github.io/async-book/02_execution/04_executor.html">Consulter cette page en Anglais</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="executors-and-system-io"><a class="header" href="#executors-and-system-io">Executors and System IO</a></h1>
<p>Cette page n'a pas encore été traduite.</p>
<p><a href="https://rust-lang.github.io/async-book/02_execution/05_io.html">Consulter cette page en Anglais</a></p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--5"><a class="header" href="#-attention-peinture-fraîche--5">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/6">Pull Request</a>.</p>
</blockquote>
<!--
# `async`/`.await`
-->
<h1 id="async-et-await"><a class="header" href="#async-et-await"><code>async</code> et <code>await</code></a></h1>
<!--
In [the first chapter], we took a brief look at `async`/`.await`.
This chapter will discuss `async`/`.await` in
greater detail, explaining how it works and how `async` code differs from
traditional Rust programs.
-->
<p>Dans <a href="03_async_await/../01_getting_started/04_async_await_primer.html">le premier chapitre</a>, nous avons présenté <code>async</code> et
<code>await</code>. Ce nouveau chapitre va aborder plus en détails <code>async</code> et <code>await</code>, en
expliquant comment il fonctionne et comment le code <code>async</code> se distingue des
programmes Rust traditionnels.</p>
<!--
`async`/`.await` are special pieces of Rust syntax that make it possible to
yield control of the current thread rather than blocking, allowing other
code to make progress while waiting on an operation to complete.
-->
<p><code>async</code> et <code>await</code> sont des mot-clés spécifiques de la syntaxe Rust qui permet
de transférer le contrôle du processus en cours plutôt que de le bloquer,
ce qui permet à un autre code de progresser pendant que nous attendons que
cette opération se termine.</p>
<!--
There are two main ways to use `async`: `async fn` and `async` blocks.
Each returns a value that implements the `Future` trait:
-->
<p>Il y a deux principaux moyens d'utiliser <code>async</code> : <code>async fn</code> et les blocs
<code>async</code>. Chacun retourne une valeur qui implémente le trait <code>Future</code> :</p>
<!--
```rust,edition2018,ignore

// `foo()` returns a type that implements `Future<Output = u8>`.
// `foo().await` will result in a value of type `u8`.
async fn foo() -> u8 { 5 }

fn bar() -> impl Future<Output = u8> {
    // This `async` block results in a type that implements
    // `Future<Output = u8>`.
    async {
        let x: u8 = foo().await;
        x + 5
    }
}
```
-->
<pre><code class="language-rust edition2018 ignore">
// `alpha()` retourne un type qui implémente `Future&lt;Output = u8&gt;`.
// `alpha().await` va retourner une valeur de type `u8`.
async fn alpha() -&gt; u8 { 5 }

fn beta() -&gt; impl Future&lt;Output = u8&gt; {
    // Ce bloc `async` va retourner un type qui implémente
    // `Future&lt;Output = u8&gt;`.
    async {
        let x: u8 = alpha().await;
        x + 5
    }
}
</code></pre>
<!--
As we saw in the first chapter, `async` bodies and other futures are lazy:
they do nothing until they are run. The most common way to run a `Future`
is to `.await` it. When `.await` is called on a `Future`, it will attempt
to run it to completion. If the `Future` is blocked, it will yield control
of the current thread. When more progress can be made, the `Future` will be picked
up by the executor and will resume running, allowing the `.await` to resolve.
-->
<p>Comme nous l'avons vu dans le premier chapitre, les corps des <code>async</code> et des
autres futures sont passifs : ils ne font rien jusqu'à ce qu'ils soient
exécutés. La façon la plus courante d'exécuter une <code>Future</code> est d'utiliser
<code>await</code> sur elle. Lorsque <code>await</code> est utilisé sur une <code>Future</code>, il va tenter de
l'exécuter jusqu'à sa fin. Si la <code>Future</code> est bloquée, il va transférer le
contrôle du processus en cours. Lorsqu'une progression pourra être effectuée à
nouveau, la <code>Future</code> va être récupérée par l'exécuteur et va continuer son
exécution, ce qui permettra à terme au <code>await</code> de se résoudre.</p>
<!--
## `async` Lifetimes
-->
<h2 id="les-durées-de-vie-async"><a class="header" href="#les-durées-de-vie-async">Les durées de vie <code>async</code></a></h2>
<!--
Unlike traditional functions, `async fn`s which take references or other
non-`'static` arguments return a `Future` which is bounded by the lifetime of
the arguments:
-->
<p>Contrairement aux fonctions traditionnelles, les <code>async fn</code> qui utilisent des
références ou d'autres arguments non <code>static</code> vont retourner une <code>Future</code> qui
est contrainte par la durée de vie des arguments :</p>
<!--
```rust,edition2018,ignore
// This function:
async fn foo(x: &u8) -> u8 { *x }

// Is equivalent to this function:
fn foo_expanded<'a>(x: &'a u8) -> impl Future<Output = u8> + 'a {
    async move { *x }
}
```
-->
<pre><code class="language-rust edition2018 ignore">// Cette fonction :
async fn alpha(x: &amp;u8) -&gt; u8 { *x }

// ... est équivalente à cette fonction :
fn alpha_enrichi&lt;'a&gt;(x: &amp;'a u8) -&gt; impl Future&lt;Output = u8&gt; + 'a {
    async move { *x }
}
</code></pre>
<!--
This means that the future returned from an `async fn` must be `.await`ed
while its non-`'static` arguments are still valid. In the common
case of `.await`ing the future immediately after calling the function
(as in `foo(&x).await`) this is not an issue. However, if storing the future
or sending it over to another task or thread, this may be an issue.
-->
<p>Cela signifie que l'on doit utiliser <code>await</code> sur la future retournée d'une
<code>async fn</code> uniquement pendant que ses arguments non <code>static</code> sont toujours en
vigueur. Dans le cas courant où on utilise <code>await</code> sur la future immédiatement
après avoir appelé la fonction (comme avec <code>alpha(&amp;x).await</code>), ce n'est pas un
problème. Cependant, si on stocke la future ou si on l'envoie à une autre tâche
ou processus, cela peut devenir un problème.</p>
<!--
One common workaround for turning an `async fn` with references-as-arguments
into a `'static` future is to bundle the arguments with the call to the
`async fn` inside an `async` block:
-->
<p>Un contournement courant pour utiliser une <code>async fn</code> avec des références en
argument afin qu'elle retourne une future <code>'static</code> est d'envelopper à
l'intérieur d'un bloc <code>async</code> les arguments utilisés pour l'appel à la
<code>async fn</code> :</p>
<!--
```rust,edition2018,ignore
fn bad() -> impl Future<Output = u8> {
    let x = 5;
    borrow_x(&x) // ERROR: `x` does not live long enough
}

fn good() -> impl Future<Output = u8> {
    async {
        let x = 5;
        borrow_x(&x).await
    }
}
```
-->
<pre><code class="language-rust edition2018 ignore">fn incorrect() -&gt; impl Future&lt;Output = u8&gt; {
    let x = 5;
    emprunter_x(&amp;x) // ERREUR : `x` ne vit pas suffisamment longtemps
}

fn correct() -&gt; impl Future&lt;Output = u8&gt; {
    async {
        let x = 5;
        emprunter_x(&amp;x).await
    }
}
</code></pre>
<!--
By moving the argument into the `async` block, we extend its lifetime to match
that of the `Future` returned from the call to `good`.
-->
<p>En déplaçant l'argument dans le bloc <code>async</code>, nous avons étendu sa durée de vie
à celle de cette <code>Future</code> qui est retournée suite à l'appel à <code>correct</code>.</p>
<!--
## `async move`
-->
<h2 id="async-move"><a class="header" href="#async-move"><code>async move</code></a></h2>
<!--
`async` blocks and closures allow the `move` keyword, much like normal
closures. An `async move` block will take ownership of the variables it
references, allowing it to outlive the current scope, but giving up the ability
to share those variables with other code:
-->
<p>Les blocs et fermetures <code>async</code>autorisent l'utilisation du mot-clé <code>move</code>,
comme les fermetures synchrones. Un bloc <code>async move</code> va prendre possession
des variables qu'il utilise, leur permettant de survivre à l'extérieur de la
portée actuelle, mais par conséquent qui empêche de partager ces variables avec
un autre code :</p>
<!--
```rust,edition2018,ignore
/// `async` block:
///
/// Multiple different `async` blocks can access the same local variable
/// so long as they're executed within the variable's scope
async fn blocks() {
    let my_string = "foo".to_string();

    let future_one = async {
        // ...
        println!("{my_string}");
    };

    let future_two = async {
        // ...
        println!("{my_string}");
    };

    // Run both futures to completion, printing "foo" twice:
    let ((), ()) = futures::join!(future_one, future_two);
}

/// `async move` block:
///
/// Only one `async move` block can access the same captured variable, since
/// captures are moved into the `Future` generated by the `async move` block.
/// However, this allows the `Future` to outlive the original scope of the
/// variable:
fn move_block() -> impl Future<Output = ()> {
    let my_string = "foo".to_string();
    async move {
        // ...
        println!("{my_string}");
    }
}
```
-->
<pre><code class="language-rust edition2018 ignore">/// blocs `async` :
///
/// Plusieurs blocs `async` différents peuvent accéder à la même variable
/// locale tant qu'elles sont exécutées dans la portée de la variable
async fn blocs() {
    let ma_chaine = &quot;alpha&quot;.to_string();

    let premiere_future = async {
        // ...
        println!(&quot;{ma_chaine}&quot;);
    };

    let seconde_future = async {
        // ...
        println!(&quot;{ma_chaine}&quot;);
    };

    // Exécute les deux futures jusqu'à leur fin, ce qui affichera
    // deux fois &quot;alpha&quot; :
    let ((), ()) = futures::join!(premiere_future, seconde_future);
}

/// blocs `async move` :
///
/// Un seul bloc `async move` peut avoir accès à la même variable capturée,
/// puisque qu'elles sont déplacées dans la `Future` générée par le bloc
/// `async move`.
/// Cependant, cela permet d'étendre la portée de la `Future` en dehors de
/// celle de la variable :
fn bloc_avec_move() -&gt; impl Future&lt;Output = ()&gt; {
    let ma_chaine = &quot;alpha&quot;.to_string();
    async move {
        // ...
        println!(&quot;{ma_chaine}&quot;);
    }
}
</code></pre>
<!--
## `.await`ing on a Multithreaded Executor
-->
<h2 id="utiliser-await-avec-un-exécuteur-multi-processus"><a class="header" href="#utiliser-await-avec-un-exécuteur-multi-processus">Utiliser <code>await</code> avec un exécuteur multi-processus</a></h2>
<!--
Note that, when using a multithreaded `Future` executor, a `Future` may move
between threads, so any variables used in `async` bodies must be able to travel
between threads, as any `.await` can potentially result in a switch to a new
thread.
-->
<p>Remarquez que lorsque vous utilisez un exécuteur de <code>Future</code> multi-processus,
une <code>Future</code> peut être déplacée entre les processus, donc toutes les variables
utilisées dans les corps des <code>async</code> doivent pouvoir aussi être déplacés entre
des processus, car n'importe quel <code>await</code> peut potentiellement basculer sur un
autre processus.</p>
<!--
This means that it is not safe to use `Rc`, `&RefCell` or any other types
that don't implement the `Send` trait, including references to types that don't
implement the `Sync` trait.
-->
<p>Cela signifie que ce n'est sûr d'utiliser <code>Rc</code>, <code>&amp;RefCell</code> ou tout autre type
qui n'implémente pas le trait <code>Send</code>, y compris les références à des types qui
n'implémente pas le trait <code>Sync</code>.</p>
<!--
(Caveat: it is possible to use these types as long as they aren't in scope
during a call to `.await`.)
-->
<p>(Remarque : il reste possible d'utiliser ces types du moment qu'ils ne sont pas
dans la portée d'un appel à <code>await</code>)</p>
<!--
Similarly, it isn't a good idea to hold a traditional non-futures-aware lock
across an `.await`, as it can cause the threadpool to lock up: one task could
take out a lock, `.await` and yield to the executor, allowing another task to
attempt to take the lock and cause a deadlock. To avoid this, use the `Mutex`
in `futures::lock` rather than the one from `std::sync`.
-->
<p>Pour la même raison, ce n'est pas une bonne idée de maintenir un verrou
traditionnel, qui ne se préoccupe pas des futures, dans un <code>await</code>, car cela
peut provoquer le blocage du groupe de processus : une tâche peut poser le
verrou, attendre grâce à <code>await</code> et transférer le contrôle à l'exécuteur, qui
va permettre à une autre tâche de vouloir poser le verrou et cela va causer un
interblocage. Pour éviter cela, utilisez le <code>Mutex</code> dans <code>futures::lock</code> plutôt
que celui dans <code>std::sync</code>.</p>
<!--
[the first chapter]: ../01_getting_started/04_async_await_primer.md
-->
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--6"><a class="header" href="#-attention-peinture-fraîche--6">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/7">Pull Request</a>.</p>
</blockquote>
<!--
# Pinning
-->
<h1 id="lépinglage"><a class="header" href="#lépinglage">L'épinglage</a></h1>
<!--
To poll futures, they must be pinned using a special type called
`Pin<T>`. If you read the explanation of [the `Future` trait] in the
previous section ["Executing `Future`s and Tasks"], you'll recognize
`Pin` from the `self: Pin<&mut Self>` in the `Future::poll` method's definition.
But what does it mean, and why do we need it?
-->
<p>Pour piloter les futures, ils doivent être épinglés en utilisant un type
spécial qui s'appelle <code>Pin&lt;T&gt;</code>. Si vous lisez l'explication <a href="https://rust-lang.github.io/async-book/02_execution/02_future.html">du trait
<code>Future</code></a> dans la <a href="04_pinning/../02_execution/01_chapter.html">section précédente</a>, vous devriez constater la présence du <code>Pin</code> dans le
<code>self: Pin&lt;&amp;mut Self&gt;</code> dans la définition de la méthode <code>Future::poll</code>. Mais
qu'est-ce que cela signifie, et pourquoi nous en avons besoin ?</p>
<!--
## Why Pinning
-->
<h2 id="pourquoi-épingler-"><a class="header" href="#pourquoi-épingler-">Pourquoi épingler ?</a></h2>
<!--
`Pin` works in tandem with the `Unpin` marker. Pinning makes it possible
to guarantee that an object implementing `!Unpin` won't ever be moved. To understand
why this is necessary, we need to remember how `async`/`.await` works. Consider
the following code:
-->
<p><code>Pin</code> fonctionne en binôme avec le marqueur <code>Unpin</code>. L'épinglage permet de
garantir qu'un objet qui implémente <code>!Unpin</code> ne sera jamais déplacé. Pour
comprendre pourquoi c'est nécessaire, nous devons nous rappeler comment <code>async</code>
et <code>await</code> fonctionnent. Imaginons le code suivant :</p>
<!--
```rust,edition2018,ignore
let fut_one = /* ... */;
let fut_two = /* ... */;
async move {
    fut_one.await;
    fut_two.await;
}
```
-->
<pre><code class="language-rust edition2018 ignore">let premiere_future = /* ... */;
let seconde_future = /* ... */;
async move {
    premiere_future.await;
    seconde_future.await;
}
</code></pre>
<!--
Under the hood, this creates an anonymous type that implements `Future`,
providing a `poll` method that looks something like this:
-->
<p>Sous le capot, cela crée un type anonyme qui implémente <code>Future</code>, ce qui va
fournir une méthode <code>poll</code> qui ressemble à ceci :</p>
<!--
```rust,ignore
// The `Future` type generated by our `async { ... }` block
struct AsyncFuture {
    fut_one: FutOne,
    fut_two: FutTwo,
    state: State,
}

// List of states our `async` block can be in
enum State {
    AwaitingFutOne,
    AwaitingFutTwo,
    Done,
}

impl Future for AsyncFuture {
    type Output = ();

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<()> {
        loop {
            match self.state {
                State::AwaitingFutOne => match self.fut_one.poll(..) {
                    Poll::Ready(()) => self.state = State::AwaitingFutTwo,
                    Poll::Pending => return Poll::Pending,
                }
                State::AwaitingFutTwo => match self.fut_two.poll(..) {
                    Poll::Ready(()) => self.state = State::Done,
                    Poll::Pending => return Poll::Pending,
                }
                State::Done => return Poll::Ready(()),
            }
        }
    }
}
```
-->
<pre><code class="language-rust ignore">// Le type `Future` généré pour notre bloc `async { ... }`
struct FutureAsynchrone {
    premiere_future: FutOne,
    seconde_future: FutTwo,
    etat: Etat,
}

// Liste des états dans lesquels notre bloc `async` peut être
enum Etat {
    AttentePremiereFuture,
    AttenteSecondeFuture,
    Termine,
}

impl Future for FutureAsynchrone {
    type Output = ();

    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;()&gt; {
        loop {
            match self.etat {
                Etat::AttentePremiereFuture =&gt; match self.premiere_future.poll(..) {
                    Poll::Ready(()) =&gt; self.etat = Etat::AttenteSecondeFuture,
                    Poll::Pending =&gt; return Poll::Pending,
                }
                Etat::AttenteSecondeFuture =&gt; match self.seconde_future.poll(..) {
                    Poll::Ready(()) =&gt; self.etat = Etat::Termine,
                    Poll::Pending =&gt; return Poll::Pending,
                }
                Etat::Termine =&gt; return Poll::Ready(()),
            }
        }
    }
}
</code></pre>
<!--

When `poll` is first called, it will poll `fut_one`. If `fut_one` can't
complete, `AsyncFuture::poll` will return. Future calls to `poll` will pick
up where the previous one left off. This process continues until the future
is able to successfully complete.
-->
<p>Lorsque <code>poll</code> est appelé la première fois, il va appeler <code>premiere_future</code>. Si
<code>premiere_future</code> ne peut pas être complété, <code>FutureAsynchrone::poll</code> va retourner
sa valeur. Les appels futurs à <code>poll</code> vont reprendre où le précédent s'est
arrêté. Ce fonctionnement va continuer jusqu'à ce que la future se termine au
complet.</p>
<!--
However, what happens if we have an `async` block that uses references?
For example:
-->
<p>Cependant, que se passe-t-il si nous avons un bloc <code>async</code> qui utilise des
références ? Par exemple :</p>
<!--
```rust,edition2018,ignore
async {
    let mut x = [0; 128];
    let read_into_buf_fut = read_into_buf(&mut x);
    read_into_buf_fut.await;
    println!("{:?}", x);
}
```
-->
<pre><code class="language-rust edition2018 ignore">async {
    let mut x = [0; 128];
    let lire_dans_un_tampon = lire_dans_un_tampon(&amp;mut x);
    lire_dans_un_tampon.await;
    println!(&quot;{:?}&quot;, x);
}
</code></pre>
<!--
What struct does this compile down to?
-->
<p>Quelle structure va donner la compilation ?</p>
<!--
```rust,ignore
struct ReadIntoBuf<'a> {
    buf: &'a mut [u8], // points to `x` below
}

struct AsyncFuture {
    x: [u8; 128],
    read_into_buf_fut: ReadIntoBuf<'what_lifetime?>,
}
```
-->
<pre><code class="language-rust ignore">struct LireDansTampon&lt;'a&gt; {
    tampon: &amp;'a mut [u8], // cela pointe sur le `x` ci-desous
}

struct FutureAsynchrone {
    x: [u8; 128],
    future_lire_dans_un_tampon: LireDansTampon&lt;'quelle_duree_de_vie?&gt;,
}
</code></pre>
<!--
Here, the `ReadIntoBuf` future holds a reference into the other field of our
structure, `x`. However, if `AsyncFuture` is moved, the location of `x` will
move as well, invalidating the pointer stored in `read_into_buf_fut.buf`.
-->
<p>Ici, la future <code>LireDansTampon</code> contient une référence vers l'autre champ de
notre structure, <code>x</code>. Cependant, si <code>FutureAsynchrone</code> est déplacée,
l'emplacement de <code>x</code> va aussi être déplacé, ce qui va corrompre le pointeur
stocké dans <code>future_lire_dans_un_tampon.tampon</code>.</p>
<!--
Pinning futures to a particular spot in memory prevents this problem, making
it safe to create references to values inside an `async` block.
-->
<p>L'épinglage des futures à un endroit précis de la mémoire évite ce problème, ce
qui va sécuriser la création de références vers des valeurs dans des blocs
<code>async</code>.</p>
<!--
## Pinning in Detail
-->
<h2 id="lépinglage-en-détail"><a class="header" href="#lépinglage-en-détail">L'épinglage en détail</a></h2>
<!--
Let's try to understand pinning by using an slightly simpler example. The problem we encounter
above is a problem that ultimately boils down to how we handle references in self-referential
types in Rust.
-->
<p>Essayons de comprendre l'épinglage en utilisant un exemple légèrement plus
simple. Le problème que nous allons rencontrer ci-dessous peut se résumer à
notre manière de gérer les types auto-référentiels en Rust.</p>
<!--
For now our example will look like this:
-->
<p>Pour l'instant, notre exemple ressemble à ceci :</p>
<!--
```rust, ignore
#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
}

impl Test {
    fn new(txt: &str) -> Self {
        Test {
            a: String::from(txt),
            b: std::ptr::null(),
        }
    }

    fn init(&mut self) {
        let self_ref: *const String = &self.a;
        self.b = self_ref;
    }

    fn a(&self) -> &str {
        &self.a
    }

    fn b(&self) -> &String {
        assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
        unsafe { &*(self.b) }
    }
}
```
-->
<pre><code class="language-rust  ignore">#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
}

impl Test {
    fn new(texte: &amp;str) -&gt; Self {
        Test {
            a: String::from(texte),
            b: std::ptr::null(),
        }
    }

    fn initialiser(&amp;mut self) {
        let self_ref: *const String = &amp;self.a;
        self.b = self_ref;
    }

    fn a(&amp;self) -&gt; &amp;str {
        &amp;self.a
    }

    fn b(&amp;self) -&gt; &amp;String {
        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
        unsafe { &amp;*(self.b) }
    }
}
</code></pre>
<!--
`Test` provides methods to get a reference to the value of the fields `a` and `b`. Since `b` is a
reference to `a` we store it as a pointer since the borrowing rules of Rust doesn't allow us to
define this lifetime. We now have what we call a self-referential struct.
-->
<p><code>Test</code> propose des méthodes pour obtenir une référence vers la valeur des
champs <code>a</code> et <code>b</code>. Comme <code>b</code> est une référence vers <code>a</code>, nous le stockons comme
un pointeur puisque les règles d'emprunt de Rust ne nous autorisent pas à
définir cette durée de vie. Nous avons désormais ce que l'on appelle une
structure auto-référentielle.</p>
<!--
Our example works fine if we don't move any of our data around as you can observe by running
this example:
-->
<p>Notre exemple fonctionne bien si nous ne déplaçons aucune de nos données, comme
vous pouvez le constater en exécutant cet exemple :</p>
<!--
```rust
fn main() {
    let mut test1 = Test::new("test1");
    test1.init();
    let mut test2 = Test::new("test2");
    test2.init();

    println!("a: {}, b: {}", test1.a(), test1.b());
    println!("a: {}, b: {}", test2.a(), test2.b());

}
# #[derive(Debug)]
# struct Test {
#     a: String,
#     b: *const String,
# }
#
# impl Test {
#     fn new(txt: &str) -> Self {
#         Test {
#             a: String::from(txt),
#             b: std::ptr::null(),
#         }
#     }
#
#     // We need an `init` method to actually set our self-reference
#     fn init(&mut self) {
#         let self_ref: *const String = &self.a;
#         self.b = self_ref;
#     }
#
#     fn a(&self) -> &str {
#         &self.a
#     }
#
#     fn b(&self) -> &String {
#         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
#         unsafe { &*(self.b) }
#     }
# }
```
-->
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.initialiser();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.initialiser();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(texte: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(texte),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    // We need an `init` method to actually set our self-reference
</span><span class="boring">    fn initialiser(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<!--
We get what we'd expect:
-->
<p>Nous obtenons ce que nous attendions :</p>
<!--
```rust, ignore
a: test1, b: test1
a: test2, b: test2
```
-->
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test2, b: test2
</code></pre>
<!--
Let's see what happens if we swap `test1` with `test2` and thereby move the data:
-->
<p>Voyons maintenant ce qui se passe si nous permutions <code>test1</code> avec <code>test2</code> et
ainsi nous déplaçons les données :</p>
<!--
```rust
fn main() {
    let mut test1 = Test::new("test1");
    test1.init();
    let mut test2 = Test::new("test2");
    test2.init();

    println!("a: {}, b: {}", test1.a(), test1.b());
    std::mem::swap(&mut test1, &mut test2);
    println!("a: {}, b: {}", test2.a(), test2.b());

}
# #[derive(Debug)]
# struct Test {
#     a: String,
#     b: *const String,
# }
#
# impl Test {
#     fn new(txt: &str) -> Self {
#         Test {
#             a: String::from(txt),
#             b: std::ptr::null(),
#         }
#     }
#
#     fn init(&mut self) {
#         let self_ref: *const String = &self.a;
#         self.b = self_ref;
#     }
#
#     fn a(&self) -> &str {
#         &self.a
#     }
#
#     fn b(&self) -> &String {
#         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
#         unsafe { &*(self.b) }
#     }
# }
```
-->
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.initialiser();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.initialiser();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    std::mem::swap(&amp;mut test1, &amp;mut test2);
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(texte: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(texte),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn initialiser(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<!--
Naively, we could think that what we should get a debug print of `test1` two times like this:
-->
<p>Naïvement, nous pourrions penser que nous devrions obtenir l'écriture de
déboguage de <code>test1</code> deux fois comme ceci :</p>
<!--
```rust, ignore
a: test1, b: test1
a: test1, b: test1
```
-->
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test1, b: test1
</code></pre>
<!--
But instead we get:
-->
<p>Mais à la place, nous avons ceci :</p>
<!--
```rust, ignore
a: test1, b: test1
a: test1, b: test2
```
-->
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test1, b: test2
</code></pre>
<!--
The pointer to `test2.b` still points to the old location which is inside `test1`
now. The struct is not self-referential anymore, it holds a pointer to a field
in a different object. That means we can't rely on the lifetime of `test2.b` to
be tied to the lifetime of `test2` anymore.
-->
<p>Le pointeur vers <code>test2.b</code> pointe toujours vers l'ancien emplacement qui est
maintenant <code>test1</code>. La structure n'est plus auto-référentielle, elle contient
un pointeur vers un champ dans un objet différent. Cela signifie que nous ne
pouvons plus considérer que la durée de vie de <code>test2.b</code> soit toujours liée à
la durée de vie de <code>test2</code>.</p>
<!--
If you're still not convinced, this should at least convince you:
-->
<p>Si vous n'êtes pas convaincu, ceci devrait vous convaincre :</p>
<!--
```rust
fn main() {
    let mut test1 = Test::new("test1");
    test1.init();
    let mut test2 = Test::new("test2");
    test2.init();

    println!("a: {}, b: {}", test1.a(), test1.b());
    std::mem::swap(&mut test1, &mut test2);
    test1.a = "I've totally changed now!".to_string();
    println!("a: {}, b: {}", test2.a(), test2.b());

}
# #[derive(Debug)]
# struct Test {
#     a: String,
#     b: *const String,
# }
#
# impl Test {
#     fn new(txt: &str) -> Self {
#         Test {
#             a: String::from(txt),
#             b: std::ptr::null(),
#         }
#     }
#
#     fn init(&mut self) {
#         let self_ref: *const String = &self.a;
#         self.b = self_ref;
#     }
#
#     fn a(&self) -> &str {
#         &self.a
#     }
#
#     fn b(&self) -> &String {
#         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
#         unsafe { &*(self.b) }
#     }
# }
```
-->
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.initialiser();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.initialiser();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    std::mem::swap(&amp;mut test1, &amp;mut test2);
    test1.a = &quot;J'ai complètement changé, désormais !&quot;.to_string();
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(texte: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(texte),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn initialiser(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<!--
The diagram below can help visualize what's going on:
-->
<p>Le schéma ci-dessous peut vous aider à voir ce qui se passe :</p>
<!--
**Fig 1: Before and after swap**
![swap_problem](../assets/swap_problem.jpg)
-->
<p><strong>Figure 1 : avant et après l'échange</strong>
<img src="04_pinning/../assets/swap_problem.jpg" alt="probleme_echange" /></p>
<!--
It's easy to get this to show undefined behavior and fail in other spectacular ways as well.
-->
<p>C'est ainsi facile d'avoir un fonctionnement indéfini et aussi de provoquer une
autre défaillance spectaculaire.</p>
<!--
## Pinning in Practice
-->
<h2 id="lépinglage-dans-la-pratique"><a class="header" href="#lépinglage-dans-la-pratique">L'épinglage dans la pratique</a></h2>
<!--
Let's see how pinning and the `Pin` type can help us solve this problem.
-->
<p>Voyons voir comment l'épinglage et le type <code>Pin</code> peut nous aider à résoudre ce
problème.</p>
<!--
The `Pin` type wraps pointer types, guaranteeing that the values behind the
pointer won't be moved. For example, `Pin<&mut T>`, `Pin<&T>`,
`Pin<Box<T>>` all guarantee that `T` won't be moved even if `T: !Unpin`.
-->
<p>Le type <code>Pin</code> enveloppe les types de pointeurs, ce qui garantit que les valeurs
derrière ce pointeur ne seront pas déplacées. Par exemple, <code>Pin&lt;&amp;mut T&gt;</code>,
<code>Pin&lt;&amp;T&gt;</code>, <code>Pin&lt;Box&lt;T&gt;&gt;</code> garantissent tous que <code>T</code> ne sera pas déplacé même si
<code>T: !Unpin</code>.</p>
<!--
Most types don't have a problem being moved. These types implement a trait
called `Unpin`. Pointers to `Unpin` types can be freely placed into or taken
out of `Pin`. For example, `u8` is `Unpin`, so `Pin<&mut u8>` behaves just like
a normal `&mut u8`.
-->
<p>La plupart des types n'ont pas de problème lorsqu'ils sont déplacés. Ces types
implémentent le trait <code>Unpin</code>. Les pointeurs vers des types <code>Unpin</code> peuvent
être librement logés à l'intérieur d'un <code>Pin</code>, ou en être retiré. Par exemple,
<code>u8</code> implémente <code>Unpin</code>, donc <code>Pin&lt;&amp;mut u8&gt;</code> se comporte exactement comme un
<code>&amp;mut u8</code> normal.</p>
<!--
However, types that can't be moved after they're pinned have a marker called
`!Unpin`. Futures created by async/await is an example of this.
-->
<p>Cependant, les types qui ne peuvent pas être déplacés après avoir été épinglés
ont un marqueur <code>!Unpin</code>. Les futures créées par <code>async</code> et <code>await</code> en sont un
exemple.</p>
<!--
### Pinning to the Stack
-->
<h3 id="lépinglage-sur-la-pile"><a class="header" href="#lépinglage-sur-la-pile">L'épinglage sur la pile</a></h3>
<!--
Back to our example. We can solve our problem by using `Pin`. Let's take a look at what
our example would look like if we required a pinned pointer instead:
-->
<p>Retournons à notre exemple. Nous pouvons résoudre notre problème en utilisant
<code>Pin</code>. Voyons ce à quoi notre exemple ressemblerait si nous avions utilisé un
pointeur épinglé à la place :</p>
<!-- markdownlint-disable -->
<!--
```rust, ignore
use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marker: PhantomPinned,
}


impl Test {
    fn new(txt: &str) -> Self {
        Test {
            a: String::from(txt),
            b: std::ptr::null(),
            _marker: PhantomPinned, // This makes our type `!Unpin`
        }
    }

    fn init(self: Pin<&mut Self>) {
        let self_ptr: *const String = &self.a;
        let this = unsafe { self.get_unchecked_mut() };
        this.b = self_ptr;
    }

    fn a(self: Pin<&Self>) -> &str {
        &self.get_ref().a
    }

    fn b(self: Pin<&Self>) -> &String {
        assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
        unsafe { &*(self.b) }
    }
}
```
-->
<!-- markdownlint-enable -->
<pre><code class="language-rust  ignore">use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marqueur: PhantomPinned,
}

impl Test {
    fn new(texte: &amp;str) -&gt; Self {
        Test {
            a: String::from(texte),
            b: std::ptr::null(),
            _marqueur: PhantomPinned, // Cela rends notre type `!Unpin`
        }
    }

    fn initialiser(self: Pin&lt;&amp;mut Self&gt;) {
        let self_pointeur: *const String = &amp;self.a;
        let this = unsafe { self.get_unchecked_mut() };
        this.b = self_pointeur;
    }

    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
        &amp;self.get_ref().a
    }

    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
        unsafe { &amp;*(self.b) }
    }
}
</code></pre>
<!--
Pinning an object to the stack will always be `unsafe` if our type implements
`!Unpin`. You can use a crate like [`pin_utils`][pin_utils] to avoid writing
our own `unsafe` code when pinning to the stack.
-->
<p>L'épinglage d'un objet à la pile va toujours être <code>unsafe</code> si notre type
implémente <code>!Unpin</code>. Vous pouvez utiliser une crate comme
<a href="https://docs.rs/pin-utils/"><code>pin_utils</code></a> pour éviter d'avoir à écrire notre propre <code>unsafe</code> code
lorsqu'on épinglera sur la pile.</p>
<!--
Below, we pin the objects `test1` and `test2` to the stack:
-->
<p>Ci-dessous, nous épinglons les objets <code>test1</code> et <code>test2</code> sur la pile :</p>
<!--
```rust
pub fn main() {
    // test1 is safe to move before we initialize it
    let mut test1 = Test::new("test1");
    // Notice how we shadow `test1` to prevent it from being accessed again
    let mut test1 = unsafe { Pin::new_unchecked(&mut test1) };
    Test::init(test1.as_mut());

    let mut test2 = Test::new("test2");
    let mut test2 = unsafe { Pin::new_unchecked(&mut test2) };
    Test::init(test2.as_mut());

    println!("a: {}, b: {}", Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    println!("a: {}, b: {}", Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
# use std::pin::Pin;
# use std::marker::PhantomPinned;
#
# #[derive(Debug)]
# struct Test {
#     a: String,
#     b: *const String,
#     _marker: PhantomPinned,
# }
#
#
# impl Test {
#     fn new(txt: &str) -> Self {
#         Test {
#             a: String::from(txt),
#             b: std::ptr::null(),
#             // This makes our type `!Unpin`
#             _marker: PhantomPinned,
#         }
#     }
#
#     fn init(self: Pin<&mut Self>) {
#         let self_ptr: *const String = &self.a;
#         let this = unsafe { self.get_unchecked_mut() };
#         this.b = self_ptr;
#     }
#
#     fn a(self: Pin<&Self>) -> &str {
#         &self.get_ref().a
#     }
#
#     fn b(self: Pin<&Self>) -> &String {
#         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
#         unsafe { &*(self.b) }
#     }
# }
```
-->
<pre><pre class="playground"><code class="language-rust">pub fn main() {
    // test1 peut être déplacé en sécurité avant que nous l'initialisions :
    let mut test1 = Test::new(&quot;test1&quot;);
    // Notez que nous masquons `test1` pour l'empêcher d'être toujours
    // accessible :
    let mut test1 = unsafe { Pin::new_unchecked(&amp;mut test1) };
    Test::initialiser(test1.as_mut());

    let mut test2 = Test::new(&quot;test2&quot;);
    let mut test2 = unsafe { Pin::new_unchecked(&amp;mut test2) };
    Test::initialiser(test2.as_mut());

    println!(&quot;a: {}, b: {}&quot;, Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    println!(&quot;a: {}, b: {}&quot;, Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marqueur: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(texte: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(texte),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            // Cela rends notre type `!Unpin`
</span><span class="boring">            _marqueur: PhantomPinned,
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn initialiser(self: Pin&lt;&amp;mut Self&gt;) {
</span><span class="boring">        let self_pointeur: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_pointeur;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<!--
Now, if we try to move our data now we get a compilation error:
-->
<p>Maintenant, si nous essayons de déplacer nos données, nous avons désormais une
erreur de compilation :</p>
<!--
```rust, compile_fail
pub fn main() {
    let mut test1 = Test::new("test1");
    let mut test1 = unsafe { Pin::new_unchecked(&mut test1) };
    Test::init(test1.as_mut());

    let mut test2 = Test::new("test2");
    let mut test2 = unsafe { Pin::new_unchecked(&mut test2) };
    Test::init(test2.as_mut());

    println!("a: {}, b: {}", Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    std::mem::swap(test1.get_mut(), test2.get_mut());
    println!("a: {}, b: {}", Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
# use std::pin::Pin;
# use std::marker::PhantomPinned;
#
# #[derive(Debug)]
# struct Test {
#     a: String,
#     b: *const String,
#     _marker: PhantomPinned,
# }
#
#
# impl Test {
#     fn new(txt: &str) -> Self {
#         Test {
#             a: String::from(txt),
#             b: std::ptr::null(),
#             _marker: PhantomPinned, // This makes our type `!Unpin`
#         }
#     }
#
#     fn init(self: Pin<&mut Self>) {
#         let self_ptr: *const String = &self.a;
#         let this = unsafe { self.get_unchecked_mut() };
#         this.b = self_ptr;
#     }
#
#     fn a(self: Pin<&Self>) -> &str {
#         &self.get_ref().a
#     }
#
#     fn b(self: Pin<&Self>) -> &String {
#         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
#         unsafe { &*(self.b) }
#     }
# }
```
-->
<pre><pre class="playground"><code class="language-rust  compile_fail">pub fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    let mut test1 = unsafe { Pin::new_unchecked(&amp;mut test1) };
    Test::initialiser(test1.as_mut());

    let mut test2 = Test::new(&quot;test2&quot;);
    let mut test2 = unsafe { Pin::new_unchecked(&amp;mut test2) };
    Test::initialiser(test2.as_mut());

    println!(&quot;a: {}, b: {}&quot;, Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    std::mem::swap(test1.get_mut(), test2.get_mut());
    println!(&quot;a: {}, b: {}&quot;, Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marqueur: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            _marqueur: PhantomPinned, // Cela rends notre type `!Unpin`
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn initialiser(self: Pin&lt;&amp;mut Self&gt;) {
</span><span class="boring">        let self_pointeur: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_pointeur;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<!--
The type system prevents us from moving the data.
-->
<p>Le système de type nous empêche de déplacer les données.</p>
<!--
> It's important to note that stack pinning will always rely on guarantees
> you give when writing `unsafe`. While we know that the _pointee_ of `&'a mut T`
> is pinned for the lifetime of `'a` we can't know if the data `&'a mut T`
> points to isn't moved after `'a` ends. If it does it will violate the Pin
> contract.
>
> A mistake that is easy to make is forgetting to shadow the original variable
> since you could drop the `Pin` and move the data after `&'a mut T`
> like shown below (which violates the Pin contract):
>
> ```rust
> fn main() {
>    let mut test1 = Test::new("test1");
>    let mut test1_pin = unsafe { Pin::new_unchecked(&mut test1) };
>    Test::init(test1_pin.as_mut());
>
>    drop(test1_pin);
>    println!(r#"test1.b points to "test1": {:?}..."#, test1.b);
>
>    let mut test2 = Test::new("test2");
>    mem::swap(&mut test1, &mut test2);
>    println!("... and now it points nowhere: {:?}", test1.b);
> }
> # use std::pin::Pin;
> # use std::marker::PhantomPinned;
> # use std::mem;
> #
> # #[derive(Debug)]
> # struct Test {
> #     a: String,
> #     b: *const String,
> #     _marker: PhantomPinned,
> # }
> #
> #
> # impl Test {
> #     fn new(txt: &str) -> Self {
> #         Test {
> #             a: String::from(txt),
> #             b: std::ptr::null(),
> #             // This makes our type `!Unpin`
> #             _marker: PhantomPinned,
> #         }
> #     }
> #
> #     fn init<'a>(self: Pin<&'a mut Self>) {
> #         let self_ptr: *const String = &self.a;
> #         let this = unsafe { self.get_unchecked_mut() };
> #         this.b = self_ptr;
> #     }
> #
> #     fn a<'a>(self: Pin<&'a Self>) -> &'a str {
> #         &self.get_ref().a
> #     }
> #
> #     fn b<'a>(self: Pin<&'a Self>) -> &'a String {
> #         assert!(!self.b.is_null(), "Test::b called without Test::init being called first");
> #         unsafe { &*(self.b) }
> #     }
> # }
> ```
-->
<blockquote>
<p>Il est important que vous compreniez que l'épinglage sur la pile s'appuie
toujours sur les garanties que vous écrivez dans votre <code>unsafe</code>. Même si nous
savons que ce sur quoi pointe le <code>&amp;'a mut T</code> est épinglé pour la durée de vie
de <code>'a</code>, nous ne pouvons pas savoir si la donnée sur laquelle pointe
<code>&amp;'a mut T</code> n'est pas déplacée après que <code>'a</code> soit terminé. Si c'est ce qui
se passe, cela violera le contrat du <code>Pin</code>.</p>
<p>Une erreur courante est d'oublier de masquer la variable originale alors que
vous pourriez terminer le <code>Pin</code> et déplacer la donnée après le <code>&amp;'a mut T</code>
comme nous le montrons ci-dessous (ce qui viole le contrat du <code>Pin</code>) :</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
   let mut test1 = Test::new(&quot;test1&quot;);
   let mut test1_pin = unsafe { Pin::new_unchecked(&amp;mut test1) };
   Test::init(test1_pin.as_mut());

   drop(test1_pin);
   println!(r#&quot;test1.b pointe sur &quot;test1&quot;: {:?}...&quot;#, test1.b);

   let mut test2 = Test::new(&quot;test2&quot;);
   mem::swap(&amp;mut test1, &amp;mut test2);
   println!(&quot;... et maintenant il pointe nulle part : {:?}&quot;, test1.b);
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">use std::mem;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marqueur: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            // Cela rends notre type `!Unpin`
</span><span class="boring">            _marqueur: PhantomPinned,
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init&lt;'a&gt;(self: Pin&lt;&amp;'a mut Self&gt;) {
</span><span class="boring">        let self_pointeur: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_pointeur;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a&lt;'a&gt;(self: Pin&lt;&amp;'a Self&gt;) -&gt; &amp;'a str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b&lt;'a&gt;(self: Pin&lt;&amp;'a Self&gt;) -&gt; &amp;'a String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b est appelé sans appeler avant Test::initialiser&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
</blockquote>
<!--
### Pinning to the Heap
-->
<h3 id="epingler-sur-le-tas"><a class="header" href="#epingler-sur-le-tas">Epingler sur le tas</a></h3>
<!--
Pinning an `!Unpin` type to the heap gives our data a stable address so we know
that the data we point to can't move after it's pinned. In contrast to stack
pinning, we know that the data will be pinned for the lifetime of the object.
-->
<p>L'épinglage d'un type <code>!Unpin</code> sur le tas donne une adresse stable à vos
données donc nous savons que la donnée sur laquelle nous pointons ne peut pas
être déplacée après avoir été épinglée. Contrairement à l'épinglage sur la
pile, nous savons que la donnée va être épinglée pendant la durée de vie de
l'objet.</p>
<!--
```rust, edition2018
use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marker: PhantomPinned,
}

impl Test {
    fn new(txt: &str) -> Pin<Box<Self>> {
        let t = Test {
            a: String::from(txt),
            b: std::ptr::null(),
            _marker: PhantomPinned,
        };
        let mut boxed = Box::pin(t);
        let self_ptr: *const String = &boxed.as_ref().a;
        unsafe { boxed.as_mut().get_unchecked_mut().b = self_ptr };

        boxed
    }

    fn a(self: Pin<&Self>) -> &str {
        &self.get_ref().a
    }

    fn b(self: Pin<&Self>) -> &String {
        unsafe { &*(self.b) }
    }
}

pub fn main() {
    let test1 = Test::new("test1");
    let test2 = Test::new("test2");

    println!("a: {}, b: {}",test1.as_ref().a(), test1.as_ref().b());
    println!("a: {}, b: {}",test2.as_ref().a(), test2.as_ref().b());
}
```
-->
<pre><pre class="playground"><code class="language-rust  edition2018">use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marqueur: PhantomPinned,
}

impl Test {
    fn new(texte: &amp;str) -&gt; Pin&lt;Box&lt;Self&gt;&gt; {
        let t = Test {
            a: String::from(texte),
            b: std::ptr::null(),
            _marqueur: PhantomPinned,
        };
        let mut boxed = Box::pin(t);
        let self_pointeur: *const String = &amp;boxed.as_ref().a;
        unsafe { boxed.as_mut().get_unchecked_mut().b = self_pointeur };

        boxed
    }

    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
        &amp;self.get_ref().a
    }

    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
        unsafe { &amp;*(self.b) }
    }
}

pub fn main() {
    let test1 = Test::new(&quot;test1&quot;);
    let test2 = Test::new(&quot;test2&quot;);

    println!(&quot;a: {}, b: {}&quot;,test1.as_ref().a(), test1.as_ref().b());
    println!(&quot;a: {}, b: {}&quot;,test2.as_ref().a(), test2.as_ref().b());
}
</code></pre></pre>
<!--
Some functions require the futures they work with to be `Unpin`. To use a
`Future` or `Stream` that isn't `Unpin` with a function that requires
`Unpin` types, you'll first have to pin the value using either
`Box::pin` (to create a `Pin<Box<T>>`) or the `pin_utils::pin_mut!` macro
(to create a `Pin<&mut T>`). `Pin<Box<Fut>>` and `Pin<&mut Fut>` can both be
used as futures, and both implement `Unpin`.
-->
<p>Certaines fonctions nécessitent que les futures avec lesquelles elles
fonctionnent soient des <code>Unpin</code>. Pour utiliser une <code>Future</code> ou un <code>Stream</code> qui
n'est pas <code>Unpin</code> avec une fonction qui nécessite des types <code>Unpin</code>, vous devez
d'abord épingler la valeur en utilisant soit <code>Box::pin</code> (pour créer un
<code>Pin&lt;Box&lt;T&gt;&gt;</code>) ou la macro <code>pin_utils::pin_mut!</code> (pour créer une
<code>Pin&lt;&amp;mut T&gt;</code>). <code>Pin&lt;Box&lt;Future&gt;&gt;</code> et <code>Pin&lt;&amp;mut Future&gt;</code> peuvent tous deux être
utilisés comme des <code>Future</code>s, et les deux implémentent <code>Unpin</code>.</p>
<!--
For example:
-->
<p>Par exemple :</p>
<!--
```rust,edition2018,ignore
use pin_utils::pin_mut; // `pin_utils` is a handy crate available on crates.io

// A function which takes a `Future` that implements `Unpin`.
fn execute_unpin_future(x: impl Future<Output = ()> + Unpin) { /* ... */ }

let fut = async { /* ... */ };
execute_unpin_future(fut); // Error: `fut` does not implement `Unpin` trait

// Pinning with `Box`:
let fut = async { /* ... */ };
let fut = Box::pin(fut);
execute_unpin_future(fut); // OK

// Pinning with `pin_mut!`:
let fut = async { /* ... */ };
pin_mut!(fut);
execute_unpin_future(fut); // OK
```
-->
<pre><code class="language-rust edition2018 ignore">use pin_utils::pin_mut; // `pin_utils` est une crate bien pratique,
                        // disponible sur crates.io

// Une fonction qui prend en argument une `Future` qui implémente `Unpin`.
fn executer_une_future_unpin(x: impl Future&lt;Output = ()&gt; + Unpin) { /* ... */ }

let future = async { /* ... */ };
executer_une_future_unpin(future); // Erreur : `future` n'implémente pas
                                   // le trait `Unpin`

// Epingler avec `Box`:
let future = async { /* ... */ };
let future = Box::pin(future);
executer_une_future_unpin(future); // OK

// Epingler avec `pin_mut!`:
let future = async { /* ... */ };
pin_mut!(future);
executer_une_future_unpin(future); // OK
</code></pre>
<!--
## Summary
-->
<h2 id="en-résumé"><a class="header" href="#en-résumé">En résumé</a></h2>
<!--
1. If `T: Unpin` (which is the default), then `Pin<'a, T>` is entirely
equivalent to `&'a mut T`. in other words: `Unpin` means it's OK for this type
to be moved even when pinned, so `Pin` will have no effect on such a type.

2. Getting a `&mut T` to a pinned T requires unsafe if `T: !Unpin`.

3. Most standard library types implement `Unpin`. The same goes for most
"normal" types you encounter in Rust. A `Future` generated by async/await is an exception to this rule.

4. You can add a `!Unpin` bound on a type on nightly with a feature flag, or
by adding `std::marker::PhantomPinned` to your type on stable.

5. You can either pin data to the stack or to the heap.

6. Pinning a `!Unpin` object to the stack requires `unsafe`

7. Pinning a `!Unpin` object to the heap does not require `unsafe`. There is a shortcut for doing this using `Box::pin`.

8. For pinned data where `T: !Unpin` you have to maintain the invariant that its memory will not
get invalidated or repurposed _from the moment it gets pinned until when drop_ is called. This is
an important part of the _pin contract_.
-->
<ol>
<li>
<p>Si <code>T: Unpin</code> (ce qu'il est par défaut), alors <code>Pin&lt;'a, T&gt;</code> est strictement
équivalent à <code>&amp;'a mut T</code>. Autrement dit : <code>Unpin</code> signifie que ce type peut
être déplacé sans problème même lorsqu'il est épinglé, donc <code>Pin</code> n'aura pas
d'impact sur ce genre de type.</p>
</li>
<li>
<p>Obtenir un <code>&amp;mut T</code> à partir d'un T épinglé nécessite du code non sécurisé
si <code>T: !Unpin</code>.</p>
</li>
<li>
<p>La plupart des bibliothèques standard implémentent <code>Unpin</code>. C'est la même
chose pour la plupart des types &quot;normaux&quot; que vous utilisez en Rust. Une
<code>Future</code> générée par <code>async</code> et <code>await</code> est une exception à cette généralité.</p>
</li>
<li>
<p>Vous pouvez ajouter un lien <code>!Unpin</code> sur un type avec la version
expérimentale de Rust avec un drapeau de fonctionnalité, ou en ajoutant le
<code>std::marker::PhantomPinned</code> sur votre type avec la version stable.</p>
</li>
<li>
<p>Vous pouvez épingler des données soit sur la pile, soit sur le tas.</p>
</li>
<li>
<p>Epingler un objet <code>!Unpin</code> sur la pile nécessite <code>unsafe</code></p>
</li>
<li>
<p>Epingler un objet <code>!Unpin</code> sur le tas ne nécessite pas <code>unsafe</code>. Il existe
un raccourci pour faire ceci avec <code>Box::pin</code>.</p>
</li>
<li>
<p>Pour les données épinglées où <code>T: !Unpin</code>, vous devez maintenir l'invariant
dont sa mémoire n'est pas invalidée ou réaffectée <em>à partir du moment où elle
est épinglée jusqu'à l'appel à drop</em>. C'est une partie très importante du
<em>contrat d'épinglage</em>.</p>
</li>
</ol>
<!--
["Executing `Future`s and Tasks"]: ../02_execution/01_chapter.md
[the `Future` trait]: ../02_execution/02_future.md
[pin_utils]: https://docs.rs/pin-utils/
-->
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--7"><a class="header" href="#-attention-peinture-fraîche--7">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/8">Pull Request</a>.</p>
</blockquote>
<!--
# The `Stream` Trait
-->
<h1 id="le-trait-stream"><a class="header" href="#le-trait-stream">Le trait <code>Stream</code></a></h1>
<!--
The `Stream` trait is similar to `Future` but can yield multiple values before
completing, similar to the `Iterator` trait from the standard library:
-->
<p>Le trait <code>Stream</code> ressemble à <code>Future</code>, mais peut retourner plusieurs valeurs
avant de se terminer, un peu comme le trait <code>Iterator</code> de la bibliothèque
standard :</p>
<!--
```rust,ignore
trait Stream {
    /// The type of the value yielded by the stream.
    type Item;

    /// Attempt to resolve the next item in the stream.
    /// Returns `Poll::Pending` if not ready, `Poll::Ready(Some(x))` if a value
    /// is ready, and `Poll::Ready(None)` if the stream has completed.
    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>)
        -> Poll<Option<Self::Item>>;
}
```
-->
<pre><code class="language-rust ignore">trait Stream {
    /// Le type de la valeur retournée par le flux.
    type Item;

    /// Tente de résoudre l'élément suivant dans le flux.
    /// Retourne :
    /// `Poll::Pending` s'il n'est pas encore prêt,
    /// `Poll::Ready(Some(x))` si une valeur est prête,
    /// `Poll::Ready(None)` si le flux est terminé.
    fn poll_next(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;Option&lt;Self::Item&gt;&gt;;
}
</code></pre>
<!--
One common example of a `Stream` is the `Receiver` for the channel type from
the `futures` crate. It will yield `Some(val)` every time a value is sent
from the `Sender` end, and will yield `None` once the `Sender` has been
dropped and all pending messages have been received:
-->
<p>Un exemple courant d'un <code>Stream</code> est le <code>Receiver</code> pour le type <code>channel</code> de la
crate <code>futures</code>. Cela va retourner <code>Some(val)</code> à chaque fois qu'une valeur est
envoyée par l'extrémité <code>Sender</code>, et va retourner <code>None</code> une fois que <code>Sender</code>
a été libéré de la mémoire et que tous les messages en cours ont été reçus :</p>
<!--
```rust,edition2018,ignore
async fn send_recv() {
    const BUFFER_SIZE: usize = 10;
    let (mut tx, mut rx) = mpsc::channel::<i32>(BUFFER_SIZE);

    tx.send(1).await.unwrap();
    tx.send(2).await.unwrap();
    drop(tx);

    // `StreamExt::next` is similar to `Iterator::next`, but returns a
    // type that implements `Future<Output = Option<T>>`.
    assert_eq!(Some(1), rx.next().await);
    assert_eq!(Some(2), rx.next().await);
    assert_eq!(None, rx.next().await);
}
```
-->
<pre><code class="language-rust edition2018 ignore">async fn send_recv() {
    const BUFFER_SIZE: usize = 10;
    let (mut tx, mut rx) = mpsc::channel::&lt;i32&gt;(BUFFER_SIZE);

    tx.send(1).await.unwrap();
    tx.send(2).await.unwrap();
    drop(tx);

    // `StreamExt::next` ressemble à `Iterator::next`, mais retourne un type
    // qui implémente `Future&lt;Output = Option&lt;T&gt;&gt;`.
    assert_eq!(Some(1), rx.next().await);
    assert_eq!(Some(2), rx.next().await);
    assert_eq!(None, rx.next().await);
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--8"><a class="header" href="#-attention-peinture-fraîche--8">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/9">Pull Request</a>.</p>
</blockquote>
<!--
# Iteration and Concurrency
-->
<h1 id="litération-et-la-concurrence"><a class="header" href="#litération-et-la-concurrence">L'itération et la concurrence</a></h1>
<!--
Similar to synchronous `Iterator`s, there are many different ways to iterate
over and process the values in a `Stream`. There are combinator-style methods
such as `map`, `filter`, and `fold`, and their early-exit-on-error cousins
`try_map`, `try_filter`, and `try_fold`.
-->
<p>Comme pour les <code>Iterator</code>s synchrones, il existe de nombreuses façons pour
itérer sur les valeurs dans un <code>Stream</code> et pour les traiter. Il existe des
méthodes conçues pour se combiner, comme <code>map</code>, <code>filter</code> et <code>fold</code>, et leurs
cousines conçues pour s'arrêter dès qu'elles rencontrent une erreur, comme
<code>try_map</code>, <code>try_filter</code>, et <code>try_fold</code>.</p>
<!--
Unfortunately, `for` loops are not usable with `Stream`s, but for
imperative-style code, `while let` and the `next`/`try_next` functions can
be used:
-->
<p>Malheureusement, les boucles <code>for</code> ne sont pas utilisables avec les <code>Stream</code>,
mais du code plus impératif peut être utilisé, comme <code>while let</code> et les
fonctions <code>next</code> et <code>try_next</code> :</p>
<!--
```rust,edition2018,ignore
async fn sum_with_next(mut stream: Pin<&mut dyn Stream<Item = i32>>) -> i32 {
    use futures::stream::StreamExt; // for `next`
    let mut sum = 0;
    while let Some(item) = stream.next().await {
        sum += item;
    }
    sum
}

async fn sum_with_try_next(
    mut stream: Pin<&mut dyn Stream<Item = Result<i32, io::Error>>>,
) -> Result<i32, io::Error> {
    use futures::stream::TryStreamExt; // for `try_next`
    let mut sum = 0;
    while let Some(item) = stream.try_next().await? {
        sum += item;
    }
    Ok(sum)
}
```
-->
<pre><code class="language-rust edition2018 ignore">async fn somme_avec_next(mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = i32&gt;&gt;) -&gt; i32 {
    use futures::stream::StreamExt; // pour utiliser `next`
    let mut somme = 0;
    while let Some(valeur) = stream.next().await {
        somme += valeur;
    }
    somme
}

async fn somme_avec_try_next(
    mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = Result&lt;i32, io::Error&gt;&gt;&gt;,
) -&gt; Result&lt;i32, io::Error&gt; {
    use futures::stream::TryStreamExt; // pour utiliser `try_next`
    let mut somme = 0;
    while let Some(valeur) = stream.try_next().await? {
        somme += valeur;
    }
    Ok(somme)
}
</code></pre>
<!--
However, if we're just processing one element at a time, we're potentially
leaving behind opportunity for concurrency, which is, after all, why we're
writing async code in the first place. To process multiple items from a stream
concurrently, use the `for_each_concurrent` and `try_for_each_concurrent`
methods:
-->
<p>Cependant, si nous ne traitions qu'un seul élément à la fois, nous aurions
probablement gaspillé des occasions de concurrence, ce qui, après tout, est
la raison principale pour laquelle nous écrivons du code asynchrone. Pour
traiter en concurrence plusieurs éléments d'un <code>Stream</code>, utilisez les méthodes
<code>for_each_concurrent</code> et <code>try_for_each_concurrent</code> :</p>
<!--
```rust,edition2018,ignore
async fn jump_around(
    mut stream: Pin<&mut dyn Stream<Item = Result<u8, io::Error>>>,
) -> Result<(), io::Error> {
    use futures::stream::TryStreamExt; // for `try_for_each_concurrent`
    const MAX_CONCURRENT_JUMPERS: usize = 100;

    stream.try_for_each_concurrent(MAX_CONCURRENT_JUMPERS, |num| async move {
        jump_n_times(num).await?;
        report_n_jumps(num).await?;
        Ok(())
    }).await?;

    Ok(())
}
```
-->
<pre><code class="language-rust edition2018 ignore">async fn sauter_partout(
    mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = Result&lt;u8, io::Error&gt;&gt;&gt;,
) -&gt; Result&lt;(), io::Error&gt; {
    use futures::stream::TryStreamExt; // pour utiliser `try_for_each_concurrent`
    const SAUTS_CONCURRENTS_MAXI: usize = 100;

    stream.try_for_each_concurrent(SAUTS_CONCURRENTS_MAXI, |nombre| async move {
        saute_x_fois(nombre).await?;
        reporter_x_sauts(nombre).await?;
        Ok(())
    }).await?;

    Ok(())
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--9"><a class="header" href="#-attention-peinture-fraîche--9">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/10">Pull Request</a>.</p>
</blockquote>
<!--
# Executing Multiple Futures at a Time
-->
<h1 id="exécuter-plusieurs-futures-en-même-temps"><a class="header" href="#exécuter-plusieurs-futures-en-même-temps">Exécuter plusieurs futures en même temps</a></h1>
<!--
Up until now, we've mostly executed futures by using `.await`, which blocks
the current task until a particular `Future` completes. However, real
asynchronous applications often need to execute several different
operations concurrently.
-->
<p>Jusqu'à présent, nous avons principalement exécuté les futures en utilisant
<code>.await</code>, ce qui bloque la tâche courante jusqu'à ce qu'une <code>Future</code> soit
terminée. Cependant, les applications asynchrones de la vraie vie ont souvent
besoin d'exécuter plusieurs opérations différentes en concurrence.</p>
<!--
In this chapter, we'll cover some ways to execute multiple asynchronous
operations at the same time:
-->
<p>Dans ce chapitre, nous allons voir différentes manières d'exécuter plusieurs
opérations asynchrones en même temps :</p>
<!--
- `join!`: waits for futures to all complete
- `select!`: waits for one of several futures to complete
- Spawning: creates a top-level task which ambiently runs a future to completion
- `FuturesUnordered`: a group of futures which yields the result of each subfuture
-->
<ul>
<li><code>join!</code> : attends que toutes les futures se terminent</li>
<li><code>select!</code> : attends qu'une des futures se termine</li>
<li>Spawning : crée une tâche de haut-niveau qui exécute de manière globale une
future jusqu'à ce qu'elle se termine</li>
<li><code>FuturesUnordered</code> : un groupe de futures qui retourne le résultat de chaque
sous-futures</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--10"><a class="header" href="#-attention-peinture-fraîche--10">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/11">Pull Request</a>.</p>
</blockquote>
<!--
# `join!`
-->
<h1 id="join"><a class="header" href="#join"><code>join!</code></a></h1>
<!--
The `futures::join` macro makes it possible to wait for multiple different
futures to complete while executing them all concurrently.
-->
<p>La macro <code>futures::join</code> permet d'attendre que plusieurs futures différentes se
terminent pendant qu'elles sont toutes exécutées en concurrence.</p>
<!--
# `join!`
-->
<h2 id="join-1"><a class="header" href="#join-1"><code>join!</code></a></h2>
<!--
When performing multiple asynchronous operations, it's tempting to simply
`.await` them in a series:
-->
<p>Lorsque nous avons besoin de faire plusieurs opérations asynchrones, il peut
être tentant d'utiliser <code>.await</code> en série sur elles :</p>
<!--
```rust,edition2018,ignore
async fn get_book_and_music() -> (Book, Music) {
    let book = get_book().await;
    let music = get_music().await;
    (book, music)
}
```
-->
<pre><code class="language-rust edition2018 ignore">async fn obtenir_livre_et_musique() -&gt; (Livre, Musique) {
    let livre = obtenir_livre().await;
    let musique = obtenir_musique().await;
    (livre, musique)
}
</code></pre>
<!--
However, this will be slower than necessary, since it won't start trying to
`get_music` until after `get_book` has completed. In some other languages,
futures are ambiently run to completion, so two operations can be
run concurrently by first calling each `async fn` to start the futures, and
then awaiting them both:
-->
<p>En revanche, cela peut être plus lent que nécessaire, puisqu'il ne commence
qu'à <code>obtenir_musique</code> avant que <code>obtenir_livre</code> soit terminé. Dans d'autres
langages, les futures sont exécutées normalement jusqu'à leur fin, donc deux
opérations peuvent être exécutées en concurrence en appelant chacune des
<code>async fn</code> pour démarrer les futures, et ensuite attendre la fin des deux :</p>
<!--
```rust,edition2018,ignore
// WRONG -- don't do this
async fn get_book_and_music() -> (Book, Music) {
    let book_future = get_book();
    let music_future = get_music();
    (book_future.await, music_future.await)
}
```
-->
<pre><code class="language-rust edition2018 ignore">// MAUVAISE FAÇON -- ne faites pas cela
async fn obtenir_livre_et_musique() -&gt; (Livre, Musique) {
    let future_livre = obtenir_livre();
    let future_musique = obtenir_musique();
    (future_livre.await, future_musique.await)
}
</code></pre>
<!--
However, Rust futures won't do any work until they're actively `.await`ed.
This means that the two code snippets above will both run
`book_future` and `music_future` in series rather than running them
concurrently. To correctly run the two futures concurrently, use
`futures::join!`:
-->
<p>Malheureusement, les futures en Rust ne font rien tant qu'on n'utilise pas
<code>.await</code> sur elles. Cela signifie que les deux extraits de code ci-dessus vont
exécuter <code>future_livre</code> et <code>future_musique</code> en série au lieu de les exécuter en
concurrence. Pour exécuter correctement les deux futures en concurrence,
utilisons <code>futures::join!</code> :</p>
<!--
```rust,edition2018,ignore
use futures::join;

async fn get_book_and_music() -> (Book, Music) {
    let book_fut = get_book();
    let music_fut = get_music();
    join!(book_fut, music_fut)
}
```
-->
<pre><code class="language-rust edition2018 ignore">use futures::join;

async fn obtenir_livre_et_musique() -&gt; (Livre, Musique) {
    let future_livre = obtenir_livre();
    let future_musique = obtenir_musique();
    join!(future_livre, future_musique)
}
</code></pre>
<!--
The value returned by `join!` is a tuple containing the output of each
`Future` passed in.
-->
<p>La valeur retournée par <code>join!</code> est une tuple contenant le résultat de chacune
des <code>Future</code>s qu'on lui a donné.</p>
<!--
## `try_join!`
-->
<h2 id="try_join"><a class="header" href="#try_join"><code>try_join!</code></a></h2>
<!--
For futures which return `Result`, consider using `try_join!` rather than
`join!`. Since `join!` only completes once all subfutures have completed,
it'll continue processing other futures even after one of its subfutures
has returned an `Err`.
-->
<p>Pour les futures qui retournent <code>Result</code>, il vaut mieux utiliser <code>try_join!</code>
plutôt que <code>join!</code>. Comme <code>join!</code> se termine uniquement lorsque toutes les
sous-futures se soient terminées, il va continuer à calculer les autres futures
même si une de ses sous-futures a retourné une <code>Err</code>.</p>
<!--
Unlike `join!`, `try_join!` will complete immediately if one of the subfutures
returns an error.
-->
<p>Contrairement à <code>join!</code>, <code>try_join!</code> va se terminer tout de suite si une des
sous-futures retourne une erreur.</p>
<!--
```rust,edition2018,ignore
use futures::try_join;

async fn get_book() -> Result<Book, String> { /* ... */ Ok(Book) }
async fn get_music() -> Result<Music, String> { /* ... */ Ok(Music) }

async fn get_book_and_music() -> Result<(Book, Music), String> {
    let book_fut = get_book();
    let music_fut = get_music();
    try_join!(book_fut, music_fut)
}
```
-->
<pre><code class="language-rust edition2018 ignore">use futures::try_join;

async fn obtenir_livre() -&gt; Result&lt;Livre, String&gt; { /* ... */ Ok(Livre) }
async fn obtenir_musique() -&gt; Result&lt;Musique, String&gt; { /* ... */ Ok(Musique) }

async fn obtenir_livre_et_musique() -&gt; Result&lt;(Livre, Musique), String&gt; {
    let future_livre = obtenir_livre();
    let future_musique = obtenir_musique();
    try_join!(future_livre, future_musique)
}
</code></pre>
<!--
Note that the futures passed to `try_join!` must all have the same error type.
Consider using the `.map_err(|e| ...)` and `.err_into()` functions from
`futures::future::TryFutureExt` to consolidate the error types:
-->
<p>Notez que les futures envoyées au <code>try_join!</code> doivent toutes avoir le même type
d'erreur. Vous pouvez utiliser les fonctions <code>.map_err(|e| ...)</code> et
<code>.err_into()</code> de <code>futures::future::TryFutureExt</code> pour regrouper les types
d'erreurs :</p>
<!--
```rust,edition2018,ignore
use futures::{
    future::TryFutureExt,
    try_join,
};

async fn get_book() -> Result<Book, ()> { /* ... */ Ok(Book) }
async fn get_music() -> Result<Music, String> { /* ... */ Ok(Music) }

async fn get_book_and_music() -> Result<(Book, Music), String> {
    let book_fut = get_book().map_err(|()| "Unable to get book".to_string());
    let music_fut = get_music();
    try_join!(book_fut, music_fut)
}
```
-->
<pre><code class="language-rust edition2018 ignore">use futures::{
    future::TryFutureExt,
    try_join,
};

async fn obtenir_livre() -&gt; Result&lt;Livre, ()&gt; { /* ... */ Ok(Livre) }
async fn obtenir_musique() -&gt; Result&lt;Musique, String&gt; { /* ... */ Ok(Musique) }

async fn obtenir_livre_et_musique() -&gt; Result&lt;(Livre, Musique), String&gt; {
    let future_livre = obtenir_livre().map_err(|()| &quot;Impossible d'obtenir le livre&quot;.to_string());
    let future_musique = obtenir_musique();
    try_join!(future_livre, future_musique)
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--11"><a class="header" href="#-attention-peinture-fraîche--11">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/12">Pull Request</a>.</p>
</blockquote>
<!--
# `select!`
-->
<h1 id="select"><a class="header" href="#select"><code>select!</code></a></h1>
<!--
The `futures::select` macro runs multiple futures simultaneously, allowing
the user to respond as soon as any future completes.
-->
<p>La macro <code>futures::select</code> exécute plusieurs futures en même temps, permettant
à son utilisateur de répondre dès qu'une future est terminée.</p>
<!--
```rust,edition2018
use futures::{
    future::FutureExt, // for `.fuse()`
    pin_mut,
    select,
};

async fn task_one() { /* ... */ }
async fn task_two() { /* ... */ }

async fn race_tasks() {
    let t1 = task_one().fuse();
    let t2 = task_two().fuse();

    pin_mut!(t1, t2);

    select! {
        () = t1 => println!("task one completed first"),
        () = t2 => println!("task two completed first"),
    }
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    use futures::{
        future::FutureExt, // pour utiliser `.fuse()`
        pin_mut,
        select,
    };

    async fn premiere_tache() { /* ... */ }
    async fn seconde_tache() { /* ... */ }

    async fn course_de_taches() {
        let t1 = premiere_tache().fuse();
        let t2 = seconde_tache().fuse();

        pin_mut!(t1, t2);

        select! {
            () = t1 =&gt; println!(&quot;la première tâche s'est terminée en premier&quot;),
            () = t2 =&gt; println!(&quot;la seconde tâche s'est terminée en premier&quot;),
        }
    }
<span class="boring">}
</span></code></pre></pre>
<!--
The function above will run both `t1` and `t2` concurrently. When either
`t1` or `t2` finishes, the corresponding handler will call `println!`, and
the function will end without completing the remaining task.
-->
<p>La fonction ci-dessus va exécuter <code>t1</code> et <code>t2</code> en concurrence. Lorsque <code>t1</code> ou
<code>t2</code> se termine, la branche correspondante va appeler <code>println!</code> et la fonction
va se terminer sans terminer la tâche restante.</p>
<!--
The basic syntax for `select` is `<pattern> = <expression> => <code>,`,
repeated for as many futures as you would like to `select` over.
-->
<p>La syntaxe classique pour <code>select</code> est <code>&lt;motif&gt; = &lt;expression&gt; =&gt; &lt;code&gt;,</code>,
répétée par autant de futures que vous voulez gérer avec le <code>select</code>.</p>
<!--
## `default => ...` and `complete => ...`
-->
<h2 id="default---et-complete--"><a class="header" href="#default---et-complete--"><code>default =&gt; ...</code> et <code>complete =&gt; ...</code></a></h2>
<!--
`select` also supports `default` and `complete` branches.
-->
<p><code>select</code> autorise aussi l'utilisation des branches <code>default</code> et <code>complete</code>.</p>
<!--
A `default` branch will run if none of the futures being `select`ed
over are yet complete. A `select` with a `default` branch will
therefore always return immediately, since `default` will be run
if none of the other futures are ready.
-->
<p>La branche <code>default</code> va s'exécuter si aucune des futures dans le <code>select</code> n'est
terminée. Un <code>select</code> avec une branche <code>default</code> toutefois retourner sa valeur
immédiatement, puisque <code>default</code> sera exécuté si aucune des futures n'est
terminée.</p>
<!--
`complete` branches can be used to handle the case where all futures
being `select`ed over have completed and will no longer make progress.
This is often handy when looping over a `select!`.
-->
<p>La branche <code>complete</code> peut être utilisée pour gérer le cas où toutes les
futures présentes dans le <code>select</code> se sont terminées et ne vont pas plus
progresser. C'est parfois utile lorsqu'on boucle sur un <code>select!</code>.</p>
<!--
```rust,edition2018
use futures::{future, select};

async fn count() {
    let mut a_fut = future::ready(4);
    let mut b_fut = future::ready(6);
    let mut total = 0;

    loop {
        select! {
            a = a_fut => total += a,
            b = b_fut => total += b,
            complete => break,
            default => unreachable!(), // never runs (futures are ready, then complete)
        };
    }
    assert_eq!(total, 10);
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    use futures::{future, select};

    async fn compter() {
        let mut future_a = future::ready(4);
        let mut future_b = future::ready(6);
        let mut total = 0;

        loop {
            select! {
                a = future_a =&gt; total += a,
                b = future_b =&gt; total += b,
                complete =&gt; break,
                default =&gt; unreachable!(), // ne sera jamais exécuté (les futures
                                           // sont prêtes, puis ensuite terminées)
            };
        }
        assert_eq!(total, 10);
    }
<span class="boring">}
</span></code></pre></pre>
<!--
## Interaction with `Unpin` and `FusedFuture`
-->
<h2 id="utilisation-avec-unpin-et-fusedfuture"><a class="header" href="#utilisation-avec-unpin-et-fusedfuture">Utilisation avec <code>Unpin</code> et <code>FusedFuture</code></a></h2>
<!--
One thing you may have noticed in the first example above is that we
had to call `.fuse()` on the futures returned by the two `async fn`s,
as well as pinning them with `pin_mut`. Both of these calls are necessary
because the futures used in `select` must implement both the `Unpin`
trait and the `FusedFuture` trait.
-->
<p>Vous avez peut-être remarqué dans le premier exemple ci-dessus que nous avons
dû appeller <code>.fuse()</code> sur les futures retournées par les deux fonctions
asynchrones, ainsi que les épingler avec <code>pin_mut</code>. Chacun de ces appels sont
nécessaires car les futures utilisées dans <code>select</code> doivent implémenter les
traits <code>Unpin</code> et <code>FusedFuture</code>.</p>
<!--
`Unpin` is necessary because the futures used by `select` are not
taken by value, but by mutable reference. By not taking ownership
of the future, uncompleted futures can be used again after the
call to `select`.
-->
<p><code>Unpin</code> est nécessaire car les futures utilisées par <code>select</code> ne sont pas des
valeurs, mais des références mutables. En évitant de prendre possession de la
future, les futures non terminées peuvent toujours être utilisées après l'appel
à <code>select</code>.</p>
<!--
Similarly, the `FusedFuture` trait is required because `select` must
not poll a future after it has completed. `FusedFuture` is implemented
by futures which track whether or not they have completed. This makes
it possible to use `select` in a loop, only polling the futures which
still have yet to complete. This can be seen in the example above,
where `a_fut` or `b_fut` will have completed the second time through
the loop. Because the future returned by `future::ready` implements
`FusedFuture`, it's able to tell `select` not to poll it again.
-->
<p>De la même manière, le trait <code>FusedFuture</code> est nécessaire car <code>select</code> ne doit
pas appeler une future après qu'elle soit complétée. <code>FusedFuture</code> est
implémentée par les futures qui ont besoin de savoir si oui ou non elles se
sont terminées. Cela permet d'utiliser <code>select</code> dans une boucle, pour appeler
uniquement les futures qui n'ont pas encore terminé. Nous pouvons voir cela
dans l'exemple ci-dessus, où <code>future_a</code> ou <code>future_b</code> sont terminés dans le
deuxième tour de boucle. Comme la future retournée par <code>future::ready</code>
implémente <code>FusedFuture</code>, c'est possible d'indiquer au <code>select</code> de ne pas les
appeler à nouveau.</p>
<!--
Note that streams have a corresponding `FusedStream` trait. Streams
which implement this trait or have been wrapped using `.fuse()`
will yield `FusedFuture` futures from their
`.next()` / `.try_next()` combinators.
-->
<p>Remarquez que les <code>Stream</code>s ont un trait <code>FusedStream</code> correspondant. Les
<code>Stream</code>s qui implémentent ce trait ou qui ont été enveloppés en utilisant
<code>.fuse()</code> vont produire des futures <code>FusedFutures</code> à partir de leurs
combinateurs <code>.next()</code> ou <code>try_next()</code>.</p>
<!--
```rust,edition2018
use futures::{
    stream::{Stream, StreamExt, FusedStream},
    select,
};

async fn add_two_streams(
    mut s1: impl Stream<Item = u8> + FusedStream + Unpin,
    mut s2: impl Stream<Item = u8> + FusedStream + Unpin,
) -> u8 {
    let mut total = 0;

    loop {
        let item = select! {
            x = s1.next() => x,
            x = s2.next() => x,
            complete => break,
        };
        if let Some(next_num) = item {
            total += next_num;
        }
    }

    total
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    use futures::{
        select,
        stream::{FusedStream, Stream, StreamExt},
    };

    async fn ajouter_deux_streams(
        mut s1: impl Stream&lt;Item = u8&gt; + FusedStream + Unpin,
        mut s2: impl Stream&lt;Item = u8&gt; + FusedStream + Unpin,
    ) -&gt; u8 {
        let mut total = 0;

        loop {
            let element = select! {
                x = s1.next() =&gt; x,
                x = s2.next() =&gt; x,
                complete =&gt; break,
            };
            if let Some(nombre_suivant) = element {
                total += nombre_suivant;
            }
        }

        total
    }
<span class="boring">}
</span></code></pre></pre>
<!--
## Concurrent tasks in a `select` loop with `Fuse` and `FuturesUnordered`
-->
<h2 id="des-tâches-concurrentes-dans-une-boucle-select-avec-fuse-et-futuresunordered"><a class="header" href="#des-tâches-concurrentes-dans-une-boucle-select-avec-fuse-et-futuresunordered">Des tâches concurrentes dans une boucle <code>select</code> avec <code>Fuse</code> et <code>FuturesUnordered</code></a></h2>
<!--
One somewhat hard-to-discover but handy function is `Fuse::terminated()`,
which allows constructing an empty future which is already terminated,
and can later be filled in with a future that needs to be run.
-->
<p>Une fonction difficile à aborder, mais qui est pratique, est
<code>Fuse::terminated()</code>, ce qui permet de construire une future vide qui est déjà
terminée, et qui peut être rempli plus tard avec une future qui a besoin d'être
exécutée.</p>
<!--
This can be handy when there's a task that needs to be run during a `select`
loop but which is created inside the `select` loop itself.
-->
<p>Cela s'avère utile lorsqu'une tâche nécessite d'être exécuté dans une boucle
<code>select</code> qui est elle-même créée dans la boucle <code>select</code>.</p>
<!--
Note the use of the `.select_next_some()` function. This can be
used with `select` to only run the branch for `Some(_)` values
returned from the stream, ignoring `None`s.
-->
<p>Remarquez l'utilisation de la fonction <code>.select_next_some()</code>. Elle peut être
utilisée avec <code>select</code> pour exécuter uniquement la branche pour les valeurs
<code>Some(_)</code> retournées par le <code>Stream</code>, en ignorant les <code>None</code>s.</p>
<!--
```rust,edition2018
use futures::{
    future::{Fuse, FusedFuture, FutureExt},
    stream::{FusedStream, Stream, StreamExt},
    pin_mut,
    select,
};

async fn get_new_num() -> u8 { /* ... */ 5 }

async fn run_on_new_num(_: u8) { /* ... */ }

async fn run_loop(
    mut interval_timer: impl Stream<Item = ()> + FusedStream + Unpin,
    starting_num: u8,
) {
    let run_on_new_num_fut = run_on_new_num(starting_num).fuse();
    let get_new_num_fut = Fuse::terminated();
    pin_mut!(run_on_new_num_fut, get_new_num_fut);
    loop {
        select! {
            () = interval_timer.select_next_some() => {
                // The timer has elapsed. Start a new `get_new_num_fut`
                // if one was not already running.
                if get_new_num_fut.is_terminated() {
                    get_new_num_fut.set(get_new_num().fuse());
                }
            },
            new_num = get_new_num_fut => {
                // A new number has arrived -- start a new `run_on_new_num_fut`,
                // dropping the old one.
                run_on_new_num_fut.set(run_on_new_num(new_num).fuse());
            },
            // Run the `run_on_new_num_fut`
            () = run_on_new_num_fut => {},
            // panic if everything completed, since the `interval_timer` should
            // keep yielding values indefinitely.
            complete => panic!("`interval_timer` completed unexpectedly"),
        }
    }
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    use futures::{
        future::{Fuse, FusedFuture, FutureExt},
        pin_mut, select,
        stream::{FusedStream, Stream, StreamExt},
    };

    async fn obtenir_nouveau_nombre() -&gt; u8 { /* ... */ 5 }

    async fn executer_avec_nouveau_nombre(_: u8) { /* ... */ }

    async fn executer_boucle(
        mut temporisation: impl Stream&lt;Item = ()&gt; + FusedStream + Unpin,
        nombre_initial: u8,
    ) {
        let executer_avec_nouveau_nombre_future =
            executer_avec_nouveau_nombre(nombre_initial).fuse();
        let obtenir_nouveau_nombre_future = Fuse::terminated();
        pin_mut!(
            executer_avec_nouveau_nombre_future,
            obtenir_nouveau_nombre_future
        );
        loop {
            select! {
                () = temporisation.select_next_some() =&gt; {
                    // La temporisation s'est terminée. Démarre un nouveau
                    // `obtenir_nouveau_nombre_future` s'il n'y en a pas un qui est
                    // déjà en cours d'exécution.
                    if obtenir_nouveau_nombre_future.is_terminated() {
                        obtenir_nouveau_nombre_future.set(obtenir_nouveau_nombre().fuse());
                    }
                },
                new_num = obtenir_nouveau_nombre_future =&gt; {
                    // Un nouveau nombre est arrivé : cela démarrera un nouveau
                    // `executer_avec_nouveau_nombre_future`, ce qui libèrera
                    // l'ancien.
                    executer_avec_nouveau_nombre_future.set(executer_avec_nouveau_nombre(new_num).fuse());
                },
                // Execute le `executer_avec_nouveau_nombre_future`
                () = executer_avec_nouveau_nombre_future =&gt; {},
                // panique si tout est terminé, car la `temporisation` est censé
                // générer des valeurs à l'infini.
                complete =&gt; panic!(&quot;`temporisation` s'est terminé inopinément&quot;),
            }
        }
    }
<span class="boring">}
</span></code></pre></pre>
<!--
When many copies of the same future need to be run simultaneously,
use the `FuturesUnordered` type. The following example is similar
to the one above, but will run each copy of `run_on_new_num_fut`
to completion, rather than aborting them when a new one is created.
It will also print out a value returned by `run_on_new_num_fut`.
-->
<p>Lorsque de nombreuses copies d'une même future a besoin d'être exécuté en même
temps, utilisez le type <code>FuturesUnordered</code>. L'exemple suivant ressemble à celui
ci-dessus, mais va exécuter chaque copie de <code>obtenir_nouveau_nombre_future</code>
jusqu'à ce qu'elles soient terminées, plutôt que de les arrêter lorsqu'une
nouvelle est générée. Cela va aussi afficher la valeur retournée par
<code>obtenir_nouveau_nombre_future</code>.</p>
<!--
```rust,edition2018
use futures::{
    future::{Fuse, FusedFuture, FutureExt},
    stream::{FusedStream, FuturesUnordered, Stream, StreamExt},
    pin_mut,
    select,
};

async fn get_new_num() -> u8 { /* ... */ 5 }

async fn run_on_new_num(_: u8) -> u8 { /* ... */ 5 }

// Runs `run_on_new_num` with the latest number
// retrieved from `get_new_num`.
//
// `get_new_num` is re-run every time a timer elapses,
// immediately cancelling the currently running
// `run_on_new_num` and replacing it with the newly
// returned value.
async fn run_loop(
    mut interval_timer: impl Stream<Item = ()> + FusedStream + Unpin,
    starting_num: u8,
) {
    let mut run_on_new_num_futs = FuturesUnordered::new();
    run_on_new_num_futs.push(run_on_new_num(starting_num));
    let get_new_num_fut = Fuse::terminated();
    pin_mut!(get_new_num_fut);
    loop {
        select! {
            () = interval_timer.select_next_some() => {
                // The timer has elapsed. Start a new `get_new_num_fut`
                // if one was not already running.
                if get_new_num_fut.is_terminated() {
                    get_new_num_fut.set(get_new_num().fuse());
                }
            },
            new_num = get_new_num_fut => {
                // A new number has arrived -- start a new `run_on_new_num_fut`.
                run_on_new_num_futs.push(run_on_new_num(new_num));
            },
            // Run the `run_on_new_num_futs` and check if any have completed
            res = run_on_new_num_futs.select_next_some() => {
                println!("run_on_new_num_fut returned {:?}", res);
            },
            // panic if everything completed, since the `interval_timer` should
            // keep yielding values indefinitely.
            complete => panic!("`interval_timer` completed unexpectedly"),
        }
    }
}

```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    use futures::{
        future::{Fuse, FusedFuture, FutureExt},
        pin_mut, select,
        stream::{FusedStream, FuturesUnordered, Stream, StreamExt},
    };

    async fn obtenir_nouveau_nombre() -&gt; u8 { /* ... */ 5 }

    async fn executer_avec_nouveau_nombre(_: u8) -&gt; u8 { /* ... */ 5 }

    // Exécute `executer_avec_nouveau_nombre` avec le dernier nombre obtenu
    // auprès de `obtenir_nouveau_nombre`.
    //
    // `obtenir_nouveau_nombre` est exécuté à nouveau à chaque fois que la
    // temporisation se termine, ce qui annule immédiatement le
    // `executer_avec_nouveau_nombre` en cours et la remplace avec la nouvelle
    // valeur retournée.
    async fn executer_boucle(
        mut temporisation: impl Stream&lt;Item = ()&gt; + FusedStream + Unpin,
        nombre_initial: u8,
    ) {
        let mut executer_avec_nouveau_nombre_futures = FuturesUnordered::new();
        executer_avec_nouveau_nombre_futures.push(executer_avec_nouveau_nombre(nombre_initial));
        let obtenir_nouveau_nombre_future = Fuse::terminated();
        pin_mut!(obtenir_nouveau_nombre_future);
        loop {
            select! {
                () = temporisation.select_next_some() =&gt; {
                    // La temporisation s'est terminée. Démarre un nouveau
                    // `obtenir_nouveau_nombre_future` s'il n'y en a pas un qui est
                    // déjà en cours d'exécution.
                    if obtenir_nouveau_nombre_future.is_terminated() {
                        obtenir_nouveau_nombre_future.set(obtenir_nouveau_nombre().fuse());
                    }
                },
                new_num = obtenir_nouveau_nombre_future =&gt; {
                    // Un nouveau nombre est arrivé : cela démarrera un nouveau
                    // `executer_avec_nouveau_nombre_future`..
                    executer_avec_nouveau_nombre_futures.push(executer_avec_nouveau_nombre(new_num));
                },
                // Exécute le `executer_avec_nouveau_nombre_futures` et vérifie si certaines ont terminé.
                res = executer_avec_nouveau_nombre_futures.select_next_some() =&gt; {
                    println!(&quot;executer_avec_nouveau_nombre_future a retourné {:?}&quot;, res);
                },
                // panique si tout est terminé, car la `temporisation` est censé
                // générer des valeurs à l'infini.
                complete =&gt; panic!(&quot;`temporisation` s'est terminé inopinément&quot;),
            }
        }
    }

<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--12"><a class="header" href="#-attention-peinture-fraîche--12">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/13">Pull Request</a>.</p>
</blockquote>
<!--
# Workarounds to Know and Love
-->
<h1 id="solutions-de-contournement-à-connaître-et-à-utiliser"><a class="header" href="#solutions-de-contournement-à-connaître-et-à-utiliser">Solutions de contournement à connaître et à utiliser</a></h1>
<!--
Rust's `async` support is still fairly new, and there are a handful of
highly-requested features still under active development, as well
as some subpar diagnostics. This chapter will discuss some common pain
points and explain how to work around them.
-->
<p>La prise en charge de <code>async</code> en Rust est relativement nouvelle, et certaines
fonctionnalités très demandées sont toujours en cours de développement, et
certaines solutions de diagnostic laissent à désirer. Ce chapitre va
présenter certaines situations délicates et expliquer comment les contourner.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--13"><a class="header" href="#-attention-peinture-fraîche--13">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
<p>Vous pouvez contribuer à l'amélioration de cette page sur sa
<a href="https://github.com/Jimskapt/async-book-fr/pull/14">Pull Request</a>.</p>
</blockquote>
<!--
# `?` in `async` Blocks
-->
<h1 id="-dans-les-blocs-async"><a class="header" href="#-dans-les-blocs-async"><code>?</code> dans les blocs <code>async</code></a></h1>
<!--
Just as in `async fn`, it's common to use `?` inside `async` blocks.
However, the return type of `async` blocks isn't explicitly stated.
This can cause the compiler to fail to infer the error type of the
`async` block.
-->
<p>Tout comme dans <code>async fn</code>, il est courant d'utiliser <code>?</code> dans des blocs
<code>async</code>. Cependant, le type de retour des blocs <code>async</code> n'a pas d'état
explicite. Cela peut faire échouer le compilateur à déduire le type d'erreur du
bloc <code>async</code>.</p>
<!--
For example, this code:
-->
<p>Par exemple, ce code ...</p>
<!--
```rust,edition2018
# struct MyError;
# async fn foo() -> Result<(), MyError> { Ok(()) }
# async fn bar() -> Result<(), MyError> { Ok(()) }
let fut = async {
    foo().await?;
    bar().await?;
    Ok(())
};
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">struct MonErreur;
</span><span class="boring">async fn alpha() -&gt; Result&lt;(), MonErreur&gt; { Ok(()) }
</span><span class="boring">async fn beta() -&gt; Result&lt;(), MonErreur&gt; { Ok(()) }
</span>let future = async {
    alpha().await?;
    beta().await?;
    Ok(())
};
<span class="boring">}
</span></code></pre></pre>
<!--
will trigger this error:
-->
<p>... va déclencher cette erreur :</p>
<!--
```
error[E0282]: type annotations needed
 -- > src/main.rs:5:9
  |
4 |     let fut = async {
  |         --- consider giving `fut` a type
5 |         foo().await?;
  |         ^^^^^^^^^^^^ cannot infer type
```
-->
<pre><code>error[E0282]: type annotations needed
 -- &gt; src/main.rs:5:9
  |
4 |     let future = async {
  |         ------ consider giving `fut` a type
5 |         alpha().await?;
  |         ^^^^^^^^^^^^^^ cannot infer type
</code></pre>
<!--
Unfortunately, there's currently no way to "give `fut` a type", nor a way
to explicitly specify the return type of an `async` block.
To work around this, use the "turbofish" operator to supply the success and
error types for the `async` block:
-->
<p>Malheureusement, il n'existe pas pour l'instant de façon de &quot;donner un type à
<code>future</code>&quot;, ni une manière pour préciser explicitement le type de retour d'un
bloc <code>async</code>.
Pour contourner cela, utilisez l'opérateur &quot;turbofish&quot; pour renseigner les
types de succès et d'erreur pour le bloc <code>async</code> :</p>
<!--
```rust,edition2018
# struct MyError;
# async fn foo() -> Result<(), MyError> { Ok(()) }
# async fn bar() -> Result<(), MyError> { Ok(()) }
let fut = async {
    foo().await?;
    bar().await?;
    Ok::<(), MyError>(()) // <- note the explicit type annotation here
};
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">struct MonErreur;
</span><span class="boring">async fn alpha() -&gt; Result&lt;(), MonErreur&gt; { Ok(()) }
</span><span class="boring">async fn beta() -&gt; Result&lt;(), MonErreur&gt; { Ok(()) }
</span>let future = async {
    alpha().await?;
    beta().await?;
    Ok::&lt;(), MonErreur&gt;(()) // &lt;- remarquez l'annotation de type explicite ici
};
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--14"><a class="header" href="#-attention-peinture-fraîche--14">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# `Send` Approximation
-->
<h1 id="lapproximation-de-send"><a class="header" href="#lapproximation-de-send">L'approximation de <code>Send</code></a></h1>
<!--
Some `async fn` state machines are safe to be sent across threads, while
others are not. Whether or not an `async fn` `Future` is `Send` is determined
by whether a non-`Send` type is held across an `.await` point. The compiler
does its best to approximate when values may be held across an `.await`
point, but this analysis is too conservative in a number of places today.
-->
<p>Certaines machines à état de fonctions asynchrones sont sûres pour être
envoyées entre des processus, alors que d'autres ne le sont pas. Le fait que la
<code>Future</code> d'une fonction asynchrone est <code>Send</code> ou non est conditionné par le
fait qu'un type <code>Send</code> soit maintenu par un <code>.await</code>, mais cette approche est
aujourd'hui trop conservatrice sur certains points.</p>
<!--
For example, consider a simple non-`Send` type, perhaps a type
which contains an `Rc`:
-->
<p>Par exemple, imaginez un simple type qui n'est pas <code>Send</code>, comme un type qui
contient un <code>Rc</code> :</p>
<!--
```rust
use std::rc::Rc;

#[derive(Default)]
struct NotSend(Rc<()>);
```
-->
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::rc::Rc;

#[derive(Default)]
struct EstPasSend(Rc&lt;()&gt;);
<span class="boring">}
</span></code></pre></pre>
<!--
Variables of type `NotSend` can briefly appear as temporaries in `async fn`s
even when the resulting `Future` type returned by the `async fn` must be `Send`:
-->
<p>Les variables du type <code>EstPasSend</code> peuvent intervenir brièvement dans des
fonctions asynchrones même si le type résultant de la <code>Future</code> retournée par la
fonction asynchrone doit être <code>Send</code> :</p>
<!--
```rust,edition2018
# use std::rc::Rc;
# #[derive(Default)]
# struct NotSend(Rc<()>);
async fn bar() {}
async fn foo() {
    NotSend::default();
    bar().await;
}

fn require_send(_: impl Send) {}

fn main() {
    require_send(foo());
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct EstPasSend(Rc&lt;()&gt;);
</span>async fn beta() {}
async fn alpha() {
    EstPasSend::default();
    beta().await;
}

fn necessite_send(_: impl Send) {}

fn main() {
    necessite_send(alpha());
}
</code></pre></pre>
<!--
However, if we change `foo` to store `NotSend` in a variable, this example no
longer compiles:
-->
<p>Cependant, si nous changeons <code>alpha</code> pour stocker le <code>EstPasSend</code> dans une
variable, cet exemple ne se compile plus :</p>
<!--
```rust,edition2018
# use std::rc::Rc;
# #[derive(Default)]
# struct NotSend(Rc<()>);
# async fn bar() {}
async fn foo() {
    let x = NotSend::default();
    bar().await;
}
# fn require_send(_: impl Send) {}
# fn main() {
#    require_send(foo());
# }
```
-->
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct EstPasSend(Rc&lt;()&gt;);
</span><span class="boring">async fn beta() {}
</span>async fn alpha() {
    let x = EstPasSend::default();
    beta().await;
}
<span class="boring">fn necessite_send(_: impl Send) {}
</span><span class="boring">fn main() {
</span><span class="boring">   necessite_send(alpha());
</span><span class="boring">}
</span></code></pre></pre>
<!--
```
error[E0277]: `std::rc::Rc<()>` cannot be sent between threads safely
  -- > src/main.rs:15:5
   |
15 |     require_send(foo());
   |     ^^^^^^^^^^^^ `std::rc::Rc<()>` cannot be sent between threads safely
   |
   = help: within `impl std::future::Future`, the trait `std::marker::Send` is not implemented for `std::rc::Rc<()>`
   = note: required because it appears within the type `NotSend`
   = note: required because it appears within the type `{NotSend, impl std::future::Future, ()}`
   = note: required because it appears within the type `[static generator@src/main.rs:7:16: 10:2 {NotSend, impl std::future::Future, ()}]`
   = note: required because it appears within the type `std::future::GenFuture<[static generator@src/main.rs:7:16: 10:2 {NotSend, impl std::future::Future, ()}]>`
   = note: required because it appears within the type `impl std::future::Future`
   = note: required because it appears within the type `impl std::future::Future`
note: required by `require_send`
  -- > src/main.rs:12:1
   |
12 | fn require_send(_: impl Send) {}
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error: aborting due to previous error

For more information about this error, try `rustc --explain E0277`.
```
-->
<pre><code>error[E0277]: `std::rc::Rc&lt;()&gt;` cannot be sent between threads safely
  -- &gt; src/main.rs:15:5
   |
15 |     necessite_send(foo());
   |     ^^^^^^^^^^^^^^ `std::rc::Rc&lt;()&gt;` cannot be sent between threads safely
   |
   = help: within `impl std::future::Future`, the trait `std::marker::Send` is not implemented for `std::rc::Rc&lt;()&gt;`
   = note: required because it appears within the type `EstPasSend`
   = note: required because it appears within the type `{EstPasSend, impl std::future::Future, ()}`
   = note: required because it appears within the type `[static generator@src/main.rs:7:16: 10:2 {EstPasSend, impl std::future::Future, ()}]`
   = note: required because it appears within the type `std::future::GenFuture&lt;[static generator@src/main.rs:7:16: 10:2 {EstPasSend, impl std::future::Future, ()}]&gt;`
   = note: required because it appears within the type `impl std::future::Future`
   = note: required because it appears within the type `impl std::future::Future`
note: required by `necessite_send`
  -- &gt; src/main.rs:12:1
   |
12 | fn necessite_send(_: impl Send) {}
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error: aborting due to previous error

For more information about this error, try `rustc --explain E0277`.
</code></pre>
<!--
This error is correct. If we store `x` into a variable, it won't be dropped
until after the `.await`, at which point the `async fn` may be running on
a different thread. Since `Rc` is not `Send`, allowing it to travel across
threads would be unsound. One simple solution to this would be to `drop`
the `Rc` before the `.await`, but unfortunately that does not work today.
-->
<p>Cette erreur est justifiée. Si nous stockons <code>x</code> dans une variable, il ne sera
pas libéré avant d'arriver après le <code>.await</code>, moment où la fonction asynchrone
s'exécute peut-être sur un processus différent. Comme <code>Rc</code> n'est pas <code>Send</code>,
lui permettre de voyager entre les processus ne serait pas sain. Une solution
simple à cela serait de libérer le <code>Rc</code> avec <code>drop</code> avant le <code>.await</code>, mais
malheureusement cela ne fonctionne pas aujourd'hui.</p>
<!--
In order to successfully work around this issue, you may have to introduce
a block scope encapsulating any non-`Send` variables. This makes it easier
for the compiler to tell that these variables do not live across an
`.await` point.
-->
<p>Pour contourner ce problème, vous pouvez créer une portée de bloc qui englobe
chacune des variables qui ne sont pas <code>Send</code>. Cela permet de dire facilement au
compilateur que ces variables ne vivent plus en dehors de l'utilisation du
<code>.await</code>.</p>
<!--
```rust,edition2018
# use std::rc::Rc;
# #[derive(Default)]
# struct NotSend(Rc<()>);
# async fn bar() {}
async fn foo() {
    {
        let x = NotSend::default();
    }
    bar().await;
}
# fn require_send(_: impl Send) {}
# fn main() {
#    require_send(foo());
# }
```
-->
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct EstPasSend(Rc&lt;()&gt;);
</span><span class="boring">async fn beta() {}
</span>async fn alpha() {
    {
        let x = EstPasSend::default();
    }
    beta().await;
}
<span class="boring">fn necessite_send(_: impl Send) {}
</span><span class="boring">fn main() {
</span><span class="boring">   necessite_send(alpha());
</span><span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--15"><a class="header" href="#-attention-peinture-fraîche--15">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# Recursion
-->
<h1 id="la-récursivité"><a class="header" href="#la-récursivité">La récursivité</a></h1>
<!--
Internally, `async fn` creates a state machine type containing each
sub-`Future` being `.await`ed. This makes recursive `async fn`s a little
tricky, since the resulting state machine type has to contain itself:
-->
<p>En interne, une fonction asynchrone génère une machine à états qui contient
chaque sous-future qui sont attendus avec <code>await</code>. Cela rend la récursivité des
fonctions asynchrones un peu compliqué, car la machine à état doit se contenir
elle-même :</p>
<!--
```rust,edition2018
# async fn step_one() { /* ... */ }
# async fn step_two() { /* ... */ }
# struct StepOne;
# struct StepTwo;
// This function:
async fn foo() {
    step_one().await;
    step_two().await;
}
// generates a type like this:
enum Foo {
    First(StepOne),
    Second(StepTwo),
}

// So this function:
async fn recursive() {
    recursive().await;
    recursive().await;
}

// generates a type like this:
enum Recursive {
    First(Recursive),
    Second(Recursive),
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">async fn etape_une() { /* ... */ }
</span><span class="boring">async fn etape_deux() { /* ... */ }
</span><span class="boring">struct EtapeUne;
</span><span class="boring">struct EtapeDeux;
</span>// Cette fonction ...
async fn alpha() {
    etape_une().await;
    etape_deux().await;
}
// ... génère un type comme celui-ci :
enum Alpha {
    Premiere(EtapeUne),
    Seconde(EtapeDeux),
}

// Donc cette fonction ...
async fn recursif() {
    recursif().await;
    recursif().await;
}

// ... génère un type comme celui-ci :
enum Recursif {
    Premiere(Recursif),
    Seconde(Recursif),
}
<span class="boring">}
</span></code></pre></pre>
<!--
This won't work—we've created an infinitely-sized type!
The compiler will complain:
-->
<p>Cela ne fonctionne pas, nous avons créé un type de taille infinie !
Le compilateur va se plaindre :</p>
<!--
```
error[E0733]: recursion in an `async fn` requires boxing
 -- > src/lib.rs:1:22
  |
1 | async fn recursive() {
  |                      ^ an `async fn` cannot invoke itself directly
  |
  = note: a recursive `async fn` must be rewritten to return a boxed future.
```
-->
<pre><code>error[E0733]: recursion in an `async fn` requires boxing
 -- &gt; src/lib.rs:1:22
  |
1 | async fn recursif() {
  |                     ^ an `async fn` cannot invoke itself directly
  |
  = note: a recursive `async fn` must be rewritten to return a boxed future.
</code></pre>
<!--
In order to allow this, we have to introduce an indirection using `Box`.
Unfortunately, compiler limitations mean that just wrapping the calls to
`recursive()` in `Box::pin` isn't enough. To make this work, we have
to make `recursive` into a non-`async` function which returns a `.boxed()`
`async` block:
-->
<p>Pour nous permettre cela, nous devons faire une dérivation en utilisant
<code>Box</code>. Malheureusement, les limitations du compilateur font en sorte
qu'envelopper les appels à <code>recursif()</code> dans une <code>Box::pin</code> n'est pas
suffisant. Pour que cela fonctionne, nous devons transformer <code>recursif</code> en
fonction synchrone pour retourner un bloc <code>async</code> qui est dans une <code>Box</code> :</p>
<!--
```rust,edition2018
use futures::future::{BoxFuture, FutureExt};

fn recursive() -> BoxFuture<'static, ()> {
    async move {
        recursive().await;
        recursive().await;
    }.boxed()
}
```
-->
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::future::{BoxFuture, FutureExt};

fn recursif() -&gt; BoxFuture&lt;'static, ()&gt; {
    async move {
        recursif().await;
        recursif().await;
    }.boxed()
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--16"><a class="header" href="#-attention-peinture-fraîche--16">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# `async` in Traits
-->
<h1 id="async-dans-les-traits"><a class="header" href="#async-dans-les-traits"><code>async</code> dans les traits</a></h1>
<!--
Currently, `async fn` cannot be used in traits. The reasons for this are
somewhat complex, but there are plans to remove this restriction in the
future.
-->
<p>Actuellement, les fonctions asynchrones ne peuvent pas être utilisées dans les
traits. Les raisons à cela sont un peu complexes, mais il a des solutions en
préparation pour lever cette restriction à l'avenir.</p>
<!--
In the meantime, however, this can be worked around using the
[async-trait crate from crates.io](https://github.com/dtolnay/async-trait).
-->
<p>Cependant, cette restriction peut être contournée en utilisant la <a href="https://github.com/dtolnay/async-trait">crate
async-trait à partir de crates.io</a>.</p>
<!--
Note that using these trait methods will result in a heap allocation
per-function-call. This is not a significant cost for the vast majority
of applications, but should be considered when deciding whether to use
this functionality in the public API of a low-level function that is expected
to be called millions of times a second.
-->
<p>Notez toutefois que l'utilisation de ces méthodes de trait vont provoquer des
allocations sur le tas à chaque appel de fonction. Cela n'a pas d'impact
significatif sur la grande majorité des applications, mais cela doit être pris
en compte lorsqu'on décide d'utiliser cette fonctionnalité dans l'API publique
d'une fonction bas-niveau qui peut être appelé des millions de fois par
seconde.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--17"><a class="header" href="#-attention-peinture-fraîche--17">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# The Async Ecosystem
Rust currently provides only the bare essentials for writing async code.
Importantly, executors, tasks, reactors, combinators, and low-level I/O futures and traits
are not yet provided in the standard library. In the meantime,
community-provided async ecosystems fill in these gaps.
-->
<h1 id="lécosystème-asynchrone"><a class="header" href="#lécosystème-asynchrone">L'écosystème asynchrone</a></h1>
<p>Actuellement, Rust ne fournit que l'essentiel pour écrire du code asynchrone.
En particulier, les exécuteurs, les tâches, les réacteurs, les combinateurs, et
les futures et les traits de bas-niveau d'entrée/sortie ne sont pas encore
fournis par la bibliothèque standard. Mais en attendant, les écosystèmes
asynchrones fournis par la communauté répondent à ce besoin.</p>
<!--
The Async Foundations Team is interested in extending examples in the Async Book to cover multiple runtimes.
If you're interested in contributing to this project, please reach out to us on
[Zulip](https://rust-lang.zulipchat.com/#narrow/stream/201246-wg-async-foundations.2Fbook).
-->
<p>L'équipe en charge des fondations de l'asynchrone est intéressée par le
développement dans le livre sur l'asynchrone pour couvrir plusieurs
environnements d'exécution. Si vous êtes intéressé pour contribuer à ce projet,
veuillez vous rendre sur
<a href="https://rust-lang.zulipchat.com/#narrow/stream/201246-wg-async-foundations.2Fbook">Zulip</a>.</p>
<!--
## Async Runtimes
Async runtimes are libraries used for executing async applications.
Runtimes usually bundle together a *reactor* with one or more *executors*.
Reactors provide subscription mechanisms for external events, like async I/O, interprocess communication, and timers.
In an async runtime, subscribers are typically futures representing low-level I/O operations.
Executors handle the scheduling and execution of tasks.
They keep track of running and suspended tasks, poll futures to completion, and wake tasks when they can make progress.
The word "executor" is frequently used interchangeably with "runtime".
Here, we use the word "ecosystem" to describe a runtime bundled with compatible traits and features.
-->
<h2 id="les-environnements-dexécution-asynchrone"><a class="header" href="#les-environnements-dexécution-asynchrone">Les environnements d'exécution asynchrone</a></h2>
<p>Les environnements d'exécution asynchrones sont des bibliothèques utilisées
pour exécuter des applications asynchrones.
Les environnements d'exécution embarquent généralement ensemble un <em>réacteur</em>
avec un ou plusieurs <em>exécuteurs</em>.
Les réacteurs fournissent des mécanismes d'abonnement pour les évènements
externes, comme les entrées/sorties asynchrones, la communication entre les
processus, et les temporisations.
Dans un environnement d'exécution asynchrone, les abonnés sont typiquement des
futures qui représentent les opérations d'entrées/sorties de bas-niveau.
Les exécuteurs gèrent la planification et l'exécution des tâches.
Ils assurent le suivi les tâches en cours d'exécution et celles qui sont
suspendues, l'appel des futures jusqu'à ce qu'elles terminent, et réaniment les
tâches lorsqu'elles peuvent progresser.
Le mot &quot;exécuteur&quot; est souvent permuté avec &quot;l'environnement d'exécution&quot;.
Ici, nous utilisons le mot &quot;écosystème&quot; pour décrire un environnement
d'exécution accompagné des traits et fonctionnalités compatibles.</p>
<!--
## Community-Provided Async Crates
-->
<h2 id="les-crates-asynchrones-fournies-par-la-communauté"><a class="header" href="#les-crates-asynchrones-fournies-par-la-communauté">Les crates asynchrones fournies par la communauté</a></h2>
<!--
### The Futures Crate
The [`futures` crate](https://docs.rs/futures/) contains traits and functions useful for writing async code.
This includes the `Stream`, `Sink`, `AsyncRead`, and `AsyncWrite` traits, and utilities such as combinators.
These utilities and traits may eventually become part of the standard library.
-->
<h3 id="la-crate-futures"><a class="header" href="#la-crate-futures">La crate <code>Futures</code></a></h3>
<p>La <a href="https://docs.rs/futures/">crate <code>futures</code></a> contient les traits et les
fonctions utiles pour écrire du code asynchrone. Cela comprend les traits
<code>Stream</code>, <code>Sink</code>, <code>AsyncRead</code>, et <code>AsyncWrite</code>, et des utilitaires comme les
combinateurs. Ces utilitaires et ces traits pourraient éventuellement faire
partie un jour de la bibliothèque standard.</p>
<!--
`futures` has its own executor, but not its own reactor, so it does not support execution of async I/O or timer futures.
For this reason, it's not considered a full runtime.
A common choice is to use utilities from `futures` with an executor from another crate.
-->
<p>Les <code>futures</code> ont leur propre exécuteur, mais pas son propre réacteur, donc
cela ne prend pas en charge l'exécution d'entrées/sorties asynchrones ou de
futures de temporisation. C'est pour cette raison que ce n'est pas considéré
comme un environnement d'exécution complet.
Il est courant d'employer les utilitaires de <code>futures</code> avec un exécuteur d'une
autre crate.</p>
<!--
### Popular Async Runtimes
There is no asynchronous runtime in the standard library, and none are officially recommended.
The following crates provide popular runtimes.
- [Tokio](https://docs.rs/tokio/): A popular async ecosystem with HTTP, gRPC, and tracing frameworks.
- [async-std](https://docs.rs/async-std/): A crate that provides asynchronous counterparts to standard library components.
- [smol](https://docs.rs/smol/): A small, simplified async runtime.
Provides the `Async` trait that can be used to wrap structs like `UnixStream` or `TcpListener`.
- [fuchsia-async](https://fuchsia.googlesource.com/fuchsia/+/master/src/lib/fuchsia-async/):
An executor for use in the Fuchsia OS.
-->
<h3 id="les-environnements-dexécution-asynchrones-populaires"><a class="header" href="#les-environnements-dexécution-asynchrones-populaires">Les environnements d'exécution asynchrones populaires</a></h3>
<p>Il n'y a pas d'environnement d'exécution asynchrone dans la bibliothèque
standard, et aucune n'est officiellement recommandée.
Les crates suivantes offrent des environnement d'exécution populaires.</p>
<ul>
<li><a href="https://docs.rs/tokio/">Tokio</a> : un écosystème asynchrone populaire pour des
cadriciels travaillant avec HTTP, gRPC et du traçage.</li>
<li><a href="https://docs.rs/async-std/">async-std</a> : une crate qui fournit des
équivalents asynchrones aux composants de la bibliothèque standard.</li>
<li><a href="https://docs.rs/smol/">smol</a> : un environnement d'exécution asynchrone,
minimisé et simplifié.</li>
</ul>
<!--
## Determining Ecosystem Compatibility
Not all async applications, frameworks, and libraries are compatible with each other, or with every OS or platform.
Most async code can be used with any ecosystem, but some frameworks and libraries require the use of a specific ecosystem.
Ecosystem constraints are not always documented, but there are several rules of thumb to determine
whether a library, trait, or function depends on a specific ecosystem.
-->
<h2 id="la-compatibilité-des-écosystèmes"><a class="header" href="#la-compatibilité-des-écosystèmes">La compatibilité des écosystèmes</a></h2>
<p>Toutes les applications, cadriciels, et bibliothèques asynchrones ne sont pas
compatibles entre elles, ou avec tous les systèmes d'exploitation ou
plateformes. La plupart du code asynchrone peut être utilisé avec n'importe
quel écosystème, mais certains cadriciels et bibliothèques nécessitent
l'utilisation d'un écosystème précis. Les contraintes d'un écosystème ne sont
pas toujours documentées, mais quelques méthodes empiriques pour déterminer si
une bibliothèque, un trait, ou une fonction dépends d'un écosystème précis.</p>
<!--
Any async code that interacts with async I/O, timers, interprocess communication, or tasks
generally depends on a specific async executor or reactor.
All other async code, such as async expressions, combinators, synchronization types, and streams
are usually ecosystem independent, provided that any nested futures are also ecosystem independent.
Before beginning a project, it's recommended to research relevant async frameworks and libraries to ensure
compatibility with your chosen runtime and with each other.
-->
<p>Tout code asynchrone qui interagit avec des entrées/sorties, temporisations,
communication inter-processus, ou des tâches asynchrones dépend généralement
d'un exécuteur ou réacteur asynchrone.
Tous les autres codes asynchrones, comme les expressions, combinateurs, types
de sychronisation, et les <code>Stream</code> asynchrones sont généralement indépendants
des écosystèmes, à condition que toutes les futures imbriquées sont aussi
indépendantes de tout écosystème.
Avant de commencer un projet, il est recommandé de rechercher les cadriciels
et bibliothèques asynchrones que vous aurez besoin pour vous assurer la
compatibilité entre eux et avec l'environnement d'exécution que vous avez
choisi.</p>
<!--
Notably, `Tokio` uses the `mio` reactor and defines its own versions of async I/O traits,
including `AsyncRead` and `AsyncWrite`.
On its own, it's not compatible with `async-std` and `smol`,
which rely on the [`async-executor` crate](https://docs.rs/async-executor), and the `AsyncRead` and `AsyncWrite`
traits defined in `futures`.
-->
<p>En particulier, <code>Tokio</code> utilise le réacteur <code>mio</code> et définit ses propres
versions des traits d'entrées/sorties asynchrones, y compris <code>AsyncRead</code> et
<code>AsyncWrite</code>. Seul, il n'est pas compatible avec <code>async-std</code> et <code>smol</code>, qui
reposent sur <a href="https://docs.rs/async-executor">la crate <code>async-executor</code></a>, et
les traits <code>AsyncRead</code> et <code>AsyncWrite</code> sont définis dans <code>futures</code>.</p>
<!--
Conflicting runtime requirements can sometimes be resolved by compatibility layers
that allow you to call code written for one runtime within another.
For example, the [`async_compat` crate](https://docs.rs/async_compat) provides a compatibility layer between
`Tokio` and other runtimes.
-->
<p>Les pré-requis d'environnement d'exécution en conflit peuvent parfois être
résolus avec des couches de compatibilité qui vous permettent d'appeler du code
écrit pour un environnement d'exécution dans un autre.
Par exemple, <a href="https://docs.rs/async_compat">la crate <code>async_compat</code></a> fournit
une couche de compatibilité entre <code>Tokio</code> et les autres environnements
d'exécution.</p>
<!--
Libraries exposing async APIs should not depend on a specific executor or reactor,
unless they need to spawn tasks or define their own async I/O or timer futures.
Ideally, only binaries should be responsible for scheduling and running tasks.
-->
<p>Les bibliothèques qui exposent des APIs asynchrones ne devraient pas dépendre
d'un exécuteur ou d'un réacteur en particulier, à moins qu'ils aient besoin de
créer des tâches ou de définir leurs propres entrées/sorties asynchrones ou des
futures de temporisation. Dans l'idéal, seuls les binaires devraient être
responsables de la planification et de l'exécution des tâches.</p>
<!--
## Single Threaded vs Multi-Threaded Executors
Async executors can be single-threaded or multi-threaded.
For example, the `async-executor` crate has both a single-threaded `LocalExecutor` and a multi-threaded `Executor`.
-->
<h2 id="les-exécuteurs-mono-processus-versus-multi-processus"><a class="header" href="#les-exécuteurs-mono-processus-versus-multi-processus">Les exécuteurs mono-processus versus multi-processus</a></h2>
<p>Les exécuteurs asynchrones peuvent être mono-processus ou multi-processus.
Par exemple, la crate <code>async-executor</code> a deux <code>LocalExecutor</code> mono-processus et
un <code>Executor</code> multi-processus.</p>
<!--
A multi-threaded executor makes progress on several tasks simultaneously.
It can speed up the execution greatly for workloads with many tasks,
but synchronizing data between tasks is usually more expensive.
It is recommended to measure performance for your application
when you are choosing between a single- and a multi-threaded runtime.
-->
<p>Les exécuteurs multi-processus permettent de faire progresser plusieurs tâches
en simultané. Cela peut accélérer considérablement l'exécution pour les charges
de travail avec beaucoup de tâches, mais la synchronisation des données entre
les tâches est habituellement moins rentable. Il est recommandé de mesurer les
performances de votre application lorsque vous choisissez entre un
environnement d'exécution mono-processus et multi-processus.</p>
<!--
Tasks can either be run on the thread that created them or on a separate thread.
Async runtimes often provide functionality for spawning tasks onto separate threads.
Even if tasks are executed on separate threads, they should still be non-blocking.
In order to schedule tasks on a multi-threaded executor, they must also be `Send`.
Some runtimes provide functions for spawning non-`Send` tasks,
which ensures every task is executed on the thread that spawned it.
They may also provide functions for spawning blocking tasks onto dedicated threads,
which is useful for running blocking synchronous code from other libraries.
-->
<p>Les tâches peuvent être exécutées soit sur le processus qui les a créés, ou sur
processus séparé. Les environnements d'exécution asynchrones fournissent
souvent des fonctionnalités pour créer des tâches sur des processus séparés.
Même si les tâches sont exécutées sur des processus séparés, ils ne doivent
toujours pas être bloquants. Pour pouvoir planifier l'exécution des tâches sur
un exécuteur multi-processus, elles doivent être aussi être <code>Send</code>. Certains
environnements d'exécution fournissent des fonctions pour créer des tâches qui
ne sont pas <code>Send</code>, ce qui permet de s'assurer que les tâches sont exécutées
sur le processus qui les ont créés.
Ils peuvent également fournir des fonctions pour créer des tâches bloquantes
sur des processus dédiés, ce qui est pratique pour exécuter du code synchrone
bloquant des autres bibliothèques.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--18"><a class="header" href="#-attention-peinture-fraîche--18">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# Final Project: Building a Concurrent Web Server with Async Rust
In this chapter, we'll use asynchronous Rust to modify the Rust book's 
[single-threaded web server](https://doc.rust-lang.org/book/ch20-01-single-threaded.html) 
to serve requests concurrently.
## Recap
Here's what the code looked like at the end of the lesson.
-->
<h1 id="projet-final--construire-un-serveur-web-concurrent-avec-le-rust-asynchrone"><a class="header" href="#projet-final--construire-un-serveur-web-concurrent-avec-le-rust-asynchrone">Projet final : construire un serveur web concurrent avec le Rust asynchrone</a></h1>
<p>Dans ce chapitre, nous allons utiliser le Rust asynchrone pour modifier le
<a href="https://jimskapt.github.io/rust-book-fr/ch20-00-final-project-a-web-server.html">serveur web mono-processus</a>
du livre sur Rust, afin qu'il serve les requêtes de manière concurrente.</p>
<h2 id="résumé"><a class="header" href="#résumé">Résumé</a></h2>
<p>Voici ce à quoi ressemblera le code à la fin de cette leçon.</p>
<!--
`src/main.rs`:
```rust
use std::fs;
use std::io::prelude::*;
use std::net::TcpListener;
use std::net::TcpStream;

fn main() {
    // Listen for incoming TCP connections on localhost port 7878
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();

    // Block forever, handling each request that arrives at this IP address
    for stream in listener.incoming() {
        let stream = stream.unwrap();

        handle_connection(stream);
    }
}

fn handle_connection(mut stream: TcpStream) {
    // Read the first 1024 bytes of data from the stream
    let mut buffer = [0; 1024];
    stream.read(&mut buffer).unwrap();

    let get = b"GET / HTTP/1.1\r\n";

    // Respond with greetings or a 404,
    // depending on the data in the request
    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };
    let contents = fs::read_to_string(filename).unwrap();

    // Write response back to the stream,
    // and flush the stream to ensure the response is sent back to the client
    let response = format!("{status_line}{contents}");
    stream.write_all(response.as_bytes()).unwrap();
    stream.flush().unwrap();
}
```
-->
<p><code>src/main.rs</code> :</p>
<pre><pre class="playground"><code class="language-rust">use std::fs;
use std::io::prelude::*;
use std::net::TcpListener;
use std::net::TcpStream;

fn main() {
    // Ecoute les connexions TCP entrantes sur localhost, port 7878.
    let ecouteur = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();

    // Bloque pour toujours, gérant chaque requête qui arrive
    // sur cette adresse IP.
    for flux in ecouteur.incoming() {
        let flux = flux.unwrap();

        gestion_connexion(flux);
    }
}

fn gestion_connexion(mut flux: TcpStream) {
    // Lit les 1024 premiers octets de données présents dans le flux
    let mut tampon = [0; 1024];
    flux.read(&amp;mut tampon).unwrap();

    let get = b&quot;GET / HTTP/1.1\r\n&quot;;

    // Répond avec l'accueil ou une erreur 404,
    // en fonction des données présentes dans la requête
    let (ligne_statut, nom_fichier) = if tampon.starts_with(get) {
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else {
        (&quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&quot;, &quot;404.html&quot;)
    };
    let contenu = fs::read_to_string(nom_fichier).unwrap();

    // Ecrit la réponse dans le flux, et purge le flux pour s'assurer
    // que la réponse est bien renvoyée au client
    let reponse = format!(&quot;{ligne_statut}{contenu}&quot;);
    flux.write_all(reponse.as_bytes()).unwrap();
    flux.flush().unwrap();
}
</code></pre></pre>
<!--
`hello.html`:
```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Hello!</title>
  </head>
  <body>
    <h1 id="hello"><a class="header" href="#hello">Hello!</a></h1>
    <p>Hi from Rust</p>
  </body>
</html>
```
-->
<p><code>hello.html</code> :</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;title&gt;Salutations !&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Salut !&lt;/h1&gt;
    &lt;p&gt;Bonjour de la part de Rust&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<!--
`404.html`:
```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Hello!</title>
  </head>
  <body>
    <h1 id="oops"><a class="header" href="#oops">Oops!</a></h1>
    <p>Sorry, I don't know what you're asking for.</p>
  </body>
</html>
```
-->
<p><code>404.html</code> :</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;title&gt;Salutations !&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Oups !&lt;/h1&gt;
    &lt;p&gt;Désolé, je ne connaît pas ce que vous demandez.&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<!--
If you run the server with `cargo run` and visit `127.0.0.1:7878` in your browser,
you'll be greeted with a friendly message from Ferris!
-->
<p>Si vous exécutez le serveur avec <code>cargo run</code> et visitez <code>127.0.0.1:7878</code> dans
votre navigateur, vous allez être accueilli par un message chaleureux de
Ferris !</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--19"><a class="header" href="#-attention-peinture-fraîche--19">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# Running Asynchronous Code
An HTTP server should be able to serve multiple clients concurrently;
that is, it should not wait for previous requests to complete before handling the current request.
The book
[solves this problem](https://doc.rust-lang.org/book/ch20-02-multithreaded.html#turning-our-single-threaded-server-into-a-multithreaded-server)
by creating a thread pool where each connection is handled on its own thread.
Here, instead of improving throughput by adding threads, we'll achieve the same effect using asynchronous code.
-->
<h1 id="exécuter-du-code-asynchrone"><a class="header" href="#exécuter-du-code-asynchrone">Exécuter du code asynchrone</a></h1>
<p>Un serveur HTTP doit être capable de servir plusieurs clients en concurrence,
et par conséquent, il ne doit pas attendre que les requêtes précédentes soient
terminées pour s'occuper de la requête en cours.
Le livre Rust <a href="https://jimskapt.github.io/rust-book-fr/ch20-02-multithreaded.html#transformer-notre-serveur-monot%C3%A2che-en-serveur-multit%C3%A2ches">résout ce
problème</a>
en créant un groupe de tâches où chaque connexion est gérée sur son propre
processus. Nous allons obtenir le même effet en utilisant du code asynchrone,
au lieu d'améliorer le débit en ajoutant des processus.</p>
<!--
Let's modify `handle_connection` to return a future by declaring it an `async fn`:
```rust,ignore
async fn handle_connection(mut stream: TcpStream) {
    //<-- snip -- >
}
```
-->
<p>Modifions le <code>gestion_connexion</code> pour retourner une future en la déclarant
comme étant une fonction asynchrone :</p>
<pre><code class="language-rust ignore">async fn gestion_connexion(mut flux: TcpStream) {
    //&lt;-- partie masquée ici --&gt;
}
</code></pre>
<!--
Adding `async` to the function declaration changes its return type
from the unit type `()` to a type that implements `Future<Output=()>`.
-->
<p>L'ajout de <code>async</code> à la déclaration de la fonction change son type de retour de
<code>()</code> à un type qui implémente <code>Future&lt;Output=()&gt;</code>.</p>
<!--
If we try to compile this, the compiler warns us that it will not work:
```console
$ cargo check
    Checking async-rust v0.1.0 (file:///projects/async-rust)
warning: unused implementer of `std::future::Future` that must be used
  -- > src/main.rs:12:9
   |
12 |         handle_connection(stream);
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: `#[warn(unused_must_use)]` on by default
   = note: futures do nothing unless you `.await` or poll them
```
-->
<p>Si nous essayons de compiler cela, le compilateur va nous avertir que cela ne
fonctionnera pas :</p>
<pre><code class="language-console">$ cargo check
    Checking async-rust v0.1.0 (file:///projects/async-rust)
warning: unused implementer of `std::future::Future` that must be used
  -- &gt; src/main.rs:12:9
   |
12 |         gestion_connexion(flux);
   |         ^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: `#[warn(unused_must_use)]` on by default
   = note: futures do nothing unless you `.await` or poll them
</code></pre>
<!--
Because we haven't `await`ed or `poll`ed the result of `handle_connection`,
it'll never run. If you run the server and visit `127.0.0.1:7878` in a browser,
you'll see that the connection is refused; our server is not handling requests.
-->
<p>Comme nous n'avons pas utilisé <code>await</code> ou <code>poll</code> sur le résultat de
<code>gestion_connexion</code>, cela ne va jamais s'exécuter. Si vous lancez le serveur et
visitez <code>127.0.0.1:7878</code> dans un navigateur web, vous constaterez que la
connexion est refusée, notre serveur ne prend pas en charge les requêtes.</p>
<!--
We can't `await` or `poll` futures within synchronous code by itself.
We'll need an asynchronous runtime to handle scheduling and running futures to completion.
Please consult the [section on choosing a runtime](../08_ecosystem/00_chapter.md)
for more information on asynchronous runtimes, executors, and reactors.
Any of the runtimes listed will work for this project, but for these examples,
we've chosen to use the `async-std` crate.
-->
<p>Nous ne pouvons pas utiliser <code>await</code> ou <code>poll</code> sur des futures dans du code
synchrone tout seul.
Nous allons avoir besoin d'un environnement d'exécution asynchrone pour gérer
la planification et l'exécution des futures jusqu'à ce qu'elles se terminent.
Vous pouvez consulter la <a href="09_example/../08_ecosystem/00_chapter.html">section pour choisir un environnement
d'exécution</a> pour plus d'information sur les
environnements d'exécution, exécuteurs et réacteurs asynchrones.
Tous les environnements d'exécution listés vont fonctionner pour ce projet,
mais pour ces exemples, nous avons choisi d'utiliser la crate <code>async-std</code>.</p>
<!--
## Adding an Async Runtime
The following example will demonstrate refactoring synchronous code to use an async runtime; here, `async-std`.
The `#[async_std::main]` attribute from `async-std` allows us to write an asynchronous main function.
To use it, enable the `attributes` feature of `async-std` in `Cargo.toml`:
```toml
[dependencies.async-std]
version = "1.6"
features = ["attributes"]
```
-->
<h2 id="ajouter-un-environnement-dexécution-asynchrone"><a class="header" href="#ajouter-un-environnement-dexécution-asynchrone">Ajouter un environnement d'exécution asynchrone</a></h2>
<p>L'exemple suivant va monter le remaniement du code synchrone pour utiliser un
environnement d'exécution asynchrone, dans ce cas <code>async-std</code>.
L'attribut <code>#[async_std::main]</code> de <code>async-std</code> nous permet d'écrire une
fonction <code>main</code> asynchrone.
Pour l'utiliser, il faut activer la fonctionnalité <code>attributes</code> de <code>async-std</code>
dans <code>Cargo.toml</code> :</p>
<pre><code class="language-toml">[dependencies.async-std]
version = &quot;1.6&quot;
features = [&quot;attributes&quot;]
</code></pre>
<!--
As a first step, we'll switch to an asynchronous main function,
and `await` the future returned by the async version of `handle_connection`.
Then, we'll test how the server responds.
Here's what that would look like:
```rust
#[async_std::main]
async fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    for stream in listener.incoming() {
        let stream = stream.unwrap();
        // Warning: This is not concurrent!
        handle_connection(stream).await;
    }
}
```
Now, let's test to see if our server can handle connections concurrently.
Simply making `handle_connection` asynchronous doesn't mean that the server
can handle multiple connections at the same time, and we'll soon see why.
-->
<p>Pour commencer, nous allons changer pour une fonction <code>main</code> asynchrone, et
utiliser <code>await</code> sur la future retournée par la version asynchrone de
<code>gestion_connexion</code>. Ensuite, nous testerons comment le serveur répond. Voici à
quoi cela ressemblerait :</p>
<pre><pre class="playground"><code class="language-rust">#[async_std::main]
async fn main() {
    let ecouteur = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();
    for flux in ecouteur.incoming() {
        let flux = flux.unwrap();
        // Attention : cela n'est pas concurrent !
        gestion_connexion(flux).await;
    }
}
</code></pre></pre>
<p>Maintenant, testons pour voir si notre serveur peut gérer les connexions en
concurrence. Transformer simplement <code>gestion_connexion</code> en asynchrone ne
signifie pas que le serveur puisse gérer plusieurs connexions en même temps, et
nous allons bientôt voir pourquoi.</p>
<!--
To illustrate this, let's simulate a slow request.
When a client makes a request to `127.0.0.1:7878/sleep`,
our server will sleep for 5 seconds:
-->
<p>Pour illustrer cela, simulons une réponse lente.
Lorsqu'un client fait une requête vers <code>127.0.0.1:7878/pause</code>, notre serveur va
attendre 5 secondes :</p>
<!--
```rust,ignore
use async_std::task;

async fn handle_connection(mut stream: TcpStream) {
    let mut buffer = [0; 1024];
    stream.read(&mut buffer).unwrap();

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        task::sleep(Duration::from_secs(5)).await;
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };
    let contents = fs::read_to_string(filename).unwrap();

    let response = format!("{status_line}{contents}");
    stream.write(response.as_bytes()).unwrap();
    stream.flush().unwrap();
}
```
This is very similar to the 
[simulation of a slow request](https://doc.rust-lang.org/book/ch20-02-multithreaded.html#simulating-a-slow-request-in-the-current-server-implementation)
from the Book, but with one important difference:
we're using the non-blocking function `async_std::task::sleep` instead of the blocking function `std::thread::sleep`.
It's important to remember that even if a piece of code is run within an `async fn` and `await`ed, it may still block.
To test whether our server handles connections concurrently, we'll need to ensure that `handle_connection` is non-blocking.
-->
<pre><code class="language-rust ignore">use async_std::task;

async fn gestion_connexion(mut flux: TcpStream) {
    let mut tampon = [0; 1024];
    flux.read(&amp;mut tampon).unwrap();

    let get = b&quot;GET / HTTP/1.1\r\n&quot;;
    let pause = b&quot;GET /pause HTTP/1.1\r\n&quot;;

    let (ligne_statut, nom_fichier) = if tampon.starts_with(get) {
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else if tampon.starts_with(pause) {
        task::sleep(Duration::from_secs(5)).await;
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else {
        (&quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&quot;, &quot;404.html&quot;)
    };
    let contenu = fs::read_to_string(nom_fichier).unwrap();

    let reponse = format!(&quot;{ligne_statut}{contenu}&quot;);
    flux.write(reponse.as_bytes()).unwrap();
    flux.flush().unwrap();
}
</code></pre>
<p>C'est très ressemblant à la <a href="https://jimskapt.github.io/rust-book-fr/ch20-02-multithreaded.html#simuler-une-longue-requ%C3%AAte-%C3%A0-traiter-avec-limpl%C3%A9mentation-actuelle-du-serveur">simulation d'une requête
lente</a>
dans le livre Rust, mais avec une différence importante :
nous utilisons la fonction non bloquante <code>async_std::task::sleep</code> au lieu de la
fonction bloquante <code>std::thread::sleep</code>.
Il est important de se rappeler que même si un code est exécuté dans une
fonction asynchrone et qu'on utilise <code>await</code> sur elle, elle peut toujours
bloquer.
Pour tester si notre serveur puisse gérer les connexions en concurrence, nous
avons besoin de nous assurer que <code>gestion_connexion</code> n'est pas bloquante.</p>
<!--
If you run the server, you'll see that a request to `127.0.0.1:7878/sleep`
will block any other incoming requests for 5 seconds!
This is because there are no other concurrent tasks that can make progress
while we are `await`ing the result of `handle_connection`.
In the next section, we'll see how to use async code to handle connections concurrently.
-->
<p>Si vous exécutez le serveur, vous constaterez qu'une requête vers
<code>127.0.0.1:7878/pause</code> devrait bloquer toutes les autres requêtes entrantes
pendant 5 secondes !
C'est parce qu'il n'y a pas d'autres tâches concurrentes qui peuvent progresser
pendant que nous utilisons <code>await</code> sur le résultat de <code>gestion_connexion</code>.
Dans la prochaine section, nous allons voir comment utiliser du code asynchrone
pour gérer en concurrence les connexions.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--20"><a class="header" href="#-attention-peinture-fraîche--20">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# Handling Connections Concurrently
The problem with our code so far is that `listener.incoming()` is a blocking iterator.
The executor can't run other futures while `listener` waits on incoming connections,
and we can't handle a new connection until we're done with the previous one.
-->
<h1 id="gérer-les-connexions-en-concurrence"><a class="header" href="#gérer-les-connexions-en-concurrence">Gérer les connexions en concurrence</a></h1>
<p>Le problème avec notre code précédent est que <code>ecouteur.incoming()</code> est un
itérateur bloquant. L'exécuteur ne peut pas exécuter d'autres futures pendant
que <code>ecouteur</code> attends les connexions entrantes, et nous ne pouvons pas gérer
une nouvelle connexion jusqu'à ce que nous ayons terminé avec la précédente.</p>
<!--
In order to fix this, we'll transform `listener.incoming()` from a blocking Iterator
to a non-blocking Stream. Streams are similar to Iterators, but can be consumed asynchronously.
For more information, see the [chapter on Streams](../05_streams/01_chapter.md).
-->
<p>Pour corriger cela, nous allons transformer l'itérateur bloquant
<code>ecouteur.incoming()</code> en <code>Stream</code> non bloquant. Les <code>Stream</code>s ressemblent aux
itérateurs, mais peuvent être consommés de manière asynchrone. Pour plus
d'informations, vous pouvez consulter <a href="09_example/../05_streams/01_chapter.html">le chapitre sur les
<code>Stream</code>s</a>.</p>
<!--
Let's replace our blocking `std::net::TcpListener` with the non-blocking `async_std::net::TcpListener`,
and update our connection handler to accept an `async_std::net::TcpStream`:
```rust,ignore
use async_std::prelude::*;

async fn handle_connection(mut stream: TcpStream) {
    let mut buffer = [0; 1024];
    stream.read(&mut buffer).await.unwrap();

    //<-- snip -- >
    stream.write(response.as_bytes()).await.unwrap();
    stream.flush().await.unwrap();
}
```
-->
<p>Remplaçons notre <code>std::net::TcpListener</code> bloquant par le
<code>async_std::net::TcpListener</code> non bloquant, et mettons à jour notre gestion de
connexion pour accepter un <code>async_std::net::TcpStream</code> :</p>
<pre><code class="language-rust ignore">use async_std::prelude::*;

async fn gestion_connexion(mut flux: TcpStream) {
    let mut tampon = [0; 1024];
    flux.read(&amp;mut tampon).await.unwrap();

    //&lt;-- partie masquée ici --&gt;
    flux.write(reponse.as_bytes()).await.unwrap();
    flux.flush().await.unwrap();
}
</code></pre>
<!--
The asynchronous version of `TcpListener` implements the `Stream` trait for `listener.incoming()`,
a change which provides two benefits.
The first is that `listener.incoming()` no longer blocks the executor.
The executor can now yield to other pending futures 
while there are no incoming TCP connections to be processed.
-->
<p>La version asynchrone de <code>TcpListener</code> implémente le trait <code>Stream</code> sur
<code>ecouteur.incoming()</code>, ce qui apporte deux avantages.
Le premier est que <code>ecouteur.incoming()</code> ne bloque plus l'exécuteur.
L'exécuteur peut maintenant transférer l'exécution à d'autres futures en
attente lorsqu'il n'y a plus de connexions TCP entrantes à traiter.</p>
<!--
The second benefit is that elements from the Stream can optionally be processed concurrently,
using a Stream's `for_each_concurrent` method.
Here, we'll take advantage of this method to handle each incoming request concurrently.
We'll need to import the `Stream` trait from the `futures` crate, so our Cargo.toml now looks like this:
```diff
+[dependencies]
+futures = "0.3"

 [dependencies.async-std]
 version = "1.6"
 features = ["attributes"]
```
-->
<p>Le second bienfait est que les éléments du <code>Stream</code> peuvent optionnellement
être traités en concurrence, en utilisant la méthode <code>for_each_concurrent</code> des
<code>Stream</code>s.
Ici, nous allons profiter de cette méthode pour traiter chaque requête entrante
de manière concurrente.
Nous avons besoin d'importer le trait <code>Stream</code> de la crate <code>futures</code>, donc
notre Cargo.toml ressemble maintenant à ceci :</p>
<pre><code class="language-diff">+[dependencies]
+futures = &quot;0.3&quot;

 [dependencies.async-std]
 version = &quot;1.6&quot;
 features = [&quot;attributes&quot;]
</code></pre>
<!--
Now, we can handle each connection concurrently by passing `handle_connection` in through a closure function.
The closure function takes ownership of each `TcpStream`, and is run as soon as a new `TcpStream` becomes available.
As long as `handle_connection` does not block, a slow request will no longer prevent other requests from completing.
```rust,ignore
use async_std::net::TcpListener;
use async_std::net::TcpStream;
use futures::stream::StreamExt;

#[async_std::main]
async fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").await.unwrap();
    listener
        .incoming()
        .for_each_concurrent(/* limit */ None, |tcpstream| async move {
            let tcpstream = tcpstream.unwrap();
            handle_connection(tcpstream).await;
        })
        .await;
}
```
# Serving Requests in Parallel
Our example so far has largely presented concurrency (using async code)
as an alternative to parallelism (using threads).
However, async code and threads are not mutually exclusive.
In our example, `for_each_concurrent` processes each connection concurrently, but on the same thread.
The `async-std` crate allows us to spawn tasks onto separate threads as well.
Because `handle_connection` is both `Send` and non-blocking, it's safe to use with `async_std::task::spawn`.
Here's what that would look like:
```rust
use async_std::task::spawn;

#[async_std::main]
async fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").await.unwrap();
    listener
        .incoming()
        .for_each_concurrent(/* limit */ None, |stream| async move {
            let stream = stream.unwrap();
            spawn(handle_connection(stream));
        })
        .await;
}
```
Now we are using both concurrency and parallelism to handle multiple requests at the same time!
See the [section on multithreaded executors](../08_ecosystem/00_chapter.md#single-threading-vs-multithreading)
for more information.
-->
<p>Maintenant, nous pouvons traiter chaque connexion en concurrence en passant
<code>gestion_connexion</code> dans une fermeture. La fermeture prend possession de chaque
<code>TcpStream</code>, et est exécuté dès qu'un nouveau <code>TcpStream</code> est disponible. Tant
que <code>gestion_connexion</code> ne bloque pas, une réponse lente ne va plus empêcher
les autres requêtes de se compléter.</p>
<pre><code class="language-rust ignore">use async_std::net::TcpListener;
use async_std::net::TcpStream;
use futures::stream::StreamExt;

#[async_std::main]
async fn main() {
    let ecouteur = TcpListener::bind(&quot;127.0.0.1:7878&quot;).await.unwrap();
    ecouteur
        .incoming()
        .for_each_concurrent(/* limite */ None, |flux_tcp| async move {
            let flux_tcp = flux_tcp.unwrap();
            gestion_connexion(flux_tcp).await;
        })
        .await;
}
</code></pre>
<h1 id="servir-les-requêtes-en-parallèle"><a class="header" href="#servir-les-requêtes-en-parallèle">Servir les requêtes en parallèle</a></h1>
<p>Notre exemple jusqu'à présent a largement présenté la concurrence (en utilisant
du code asynchrone) comme étant une alternative au parallélisme (en utilisant
des processus).
Cependant, le code asynchrone et les processus ne s'excluent pas mutuellement.
Dans notre exemple, <code>for_each_concurrent</code> traite chaque connexion en
concurrence, mais sur le même processus.
La crate <code>async-std</code> nous permet également de créer des tâches sur des
processus séparés.
Comme <code>gestion_connexion</code> est à la fois <code>Send</code> et non bloquant, il est sûr à
utiliser avec <code>async_std::task::spawn</code>.
Voici à quoi cela devrait ressembler :</p>
<pre><pre class="playground"><code class="language-rust">use async_std::task::spawn;

#[async_std::main]
async fn main() {
    let ecouteur = TcpListener::bind(&quot;127.0.0.1:7878&quot;).await.unwrap();
    ecouteur
        .incoming()
        .for_each_concurrent(/* limite */ None, |flux| async move {
            let flux = flux.unwrap();
            spawn(gestion_connexion(flux));
        })
        .await;
}
</code></pre></pre>
<p>Maintenant nous utilisons à la fois la concurrence et le parallélisme pour
traiter plusieurs requêtes en même temps ! Lisez la <a href="09_example/../08_ecosystem/00_chapter.html">section sur les exécuteurs
multi-processus</a> pour en savoir plus.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<h1 id="-attention-peinture-fraîche--21"><a class="header" href="#-attention-peinture-fraîche--21">🚧 Attention, peinture fraîche !</a></h1>
<p>Cette page a été traduite par une seule personne et n'a pas été relue et
vérifiée par quelqu'un d'autre ! Les informations peuvent par exemple être
erronées, être formulées maladroitement, ou contenir d'autres types de fautes.</p>
</blockquote>
<!--
# Testing the TCP Server
Let's move on to testing our `handle_connection` function.
-->
<h1 id="test-du-serveur-tcp"><a class="header" href="#test-du-serveur-tcp">Test du serveur TCP</a></h1>
<p>Passons désormais au test de notre fonction <code>gestion_connexion</code>.</p>
<!--
First, we need a `TcpStream` to work with.
In an end-to-end or integration test, we might want to make a real TCP connection
to test our code.
One strategy for doing this is to start a listener on `localhost` port 0.
Port 0 isn't a valid UNIX port, but it'll work for testing.
The operating system will pick an open TCP port for us.
-->
<p>D'abord, nous avons besoin d'un <code>TcpStream</code> avec lequel travailler.
Dans un test d'intégration ou de bout-à-bout, nous serions tentés de faire une
vraie connexion TCP pour tester notre code.
Une des stratégies pour faire cela est de démarrer un écouteur sur le port 0 de
<code>localhost</code>.
Le port 0 n'est pas un port UNIX valide, mais il fonctionne pour faire des
tests.
Le système d'exploitation va obtenir un port TCP ouvert pour nous.</p>
<!--
Instead, in this example we'll write a unit test for the connection handler,
to check that the correct responses are returned for the respective inputs.
To keep our unit test isolated and deterministic, we'll replace the `TcpStream` with a mock.
-->
<p>Dans cet exemple, nous allons plutôt écrire un test unitaire pour le
gestionnaire de connexion, pour vérifier que les réponses correctes soient
retournées à leurs entrées respectives.
Pour faire en sorte que notre test unitaire soit isolé et déterminé, nous
allons remplacer le <code>TcpStream</code> par un mock.</p>
<!--
First, we'll change the signature of `handle_connection` to make it easier to test.
`handle_connection` doesn't actually require an `async_std::net::TcpStream`;
it requires any struct that implements `async_std::io::Read`, `async_std::io::Write`, and `marker::Unpin`.
Changing the type signature to reflect this allows us to pass a mock for testing.
```rust,ignore
use std::marker::Unpin;
use async_std::io::{Read, Write};

async fn handle_connection(mut stream: impl Read + Write + Unpin) {
```
-->
<p>Pour commencer, nous allons changer la signature de <code>gestion_connexion</code> pour
faciliter ses tests.
En fait, <code>gestion_connexion</code> ne nécessite pas de <code>async_std::net::TcpStream</code>,
il a juste besoin d'une structure qui implémente <code>async_std::io::Read</code>,
<code>async_std::io::Write</code>, et <code>marker::Unpin</code>.
Changeons la signature du type dans ce sens nous permet de lui passer un mock
pour la tester.</p>
<pre><code class="language-rust ignore">use std::marker::Unpin;
use async_std::io::{Read, Write};

async fn gestion_connexion(mut stream: impl Read + Write + Unpin) {
</code></pre>
<!--
Next, let's build a mock `TcpStream` that implements these traits.
First, let's implement the `Read` trait, with one method, `poll_read`.
Our mock `TcpStream` will contain some data that is copied into the read buffer,
and we'll return `Poll::Ready` to signify that the read is complete.
```rust,ignore
    use super::*;
    use futures::io::Error;
    use futures::task::{Context, Poll};

    use std::cmp::min;
    use std::pin::Pin;

    struct MockTcpStream {
        read_data: Vec<u8>,
        write_data: Vec<u8>,
    }

    impl Read for MockTcpStream {
        fn poll_read(
            self: Pin<&mut Self>,
            _: &mut Context,
            buf: &mut [u8],
        ) -> Poll<Result<usize, Error>> {
            let size: usize = min(self.read_data.len(), buf.len());
            buf[..size].copy_from_slice(&self.read_data[..size]);
            Poll::Ready(Ok(size))
        }
    }
```
-->
<p>Ensuite, créons un mock de <code>TcpStream</code> qui implémente ces traits.
Implémentons d'abord le trait <code>Read</code>, qui a une méthode, <code>poll_read</code>.
Notre mock de <code>TcpStream</code> va contenir certaines données qui sont copiées dans
le tampon de lecture, et nous allons retourner <code>Poll::Ready</code> pour signaler que
la lecture est terminée.</p>
<pre><code class="language-rust ignore">    use super::*;
    use futures::io::Error;
    use futures::task::{Context, Poll};

    use std::cmp::min;
    use std::pin::Pin;

    struct MockTcpStream {
        donnees_lecture: Vec&lt;u8&gt;,
        donnees_ecriture: Vec&lt;u8&gt;,
    }

    impl Read for MockTcpStream {
        fn poll_read(
            self: Pin&lt;&amp;mut Self&gt;,
            _: &amp;mut Context,
            tampon: &amp;mut [u8],
        ) -&gt; Poll&lt;Result&lt;usize, Error&gt;&gt; {
            let taille: usize = min(self.donnees_lecture.len(), tampon.len());
            tampon[..taille].copy_from_slice(&amp;self.donnees_lecture[..taille]);
            Poll::Ready(Ok(taille))
        }
    }
</code></pre>
<!--
Our implementation of `Write` is very similar,
although we'll need to write three methods: `poll_write`, `poll_flush`, and `poll_close`.
`poll_write` will copy any input data into the mock `TcpStream`, and return `Poll::Ready` when complete.
No work needs to be done to flush or close the mock `TcpStream`, so `poll_flush` and `poll_close`
can just return `Poll::Ready`.
```rust,ignore
    impl Write for MockTcpStream {
        fn poll_write(
            mut self: Pin<&mut Self>,
            _: &mut Context,
            buf: &[u8],
        ) -> Poll<Result<usize, Error>> {
            self.write_data = Vec::from(buf);

            Poll::Ready(Ok(buf.len()))
        }

        fn poll_flush(self: Pin<&mut Self>, _: &mut Context) -> Poll<Result<(), Error>> {
            Poll::Ready(Ok(()))
        }

        fn poll_close(self: Pin<&mut Self>, _: &mut Context) -> Poll<Result<(), Error>> {
            Poll::Ready(Ok(()))
        }
    }
```
-->
<p>Notre implémentation de <code>Write</code> y ressemble beaucoup, même si nous avons besoin
d'écrire trois méthodes : <code>poll_write</code>, <code>poll_flush</code>, et <code>poll_close</code>.
<code>poll_write</code> va copier toutes les données d'entrée dans le mock de <code>TcpStream</code>,
et retourne <code>Poll::Ready</code> lorsqu'elle sera terminée.
Il n'y a pas besoin de purger et fermer le mock de <code>TcpStream</code>, donc
<code>poll_flush</code> et <code>poll_close</code> peuvent simplement retourner <code>Poll::Ready</code>.</p>
<pre><code class="language-rust ignore">    impl Write for MockTcpStream {
        fn poll_write(
            mut self: Pin&lt;&amp;mut Self&gt;,
            _: &amp;mut Context,
            tampon: &amp;[u8],
        ) -&gt; Poll&lt;Result&lt;usize, Error&gt;&gt; {
            self.donnees_ecriture = Vec::from(tampon);

            Poll::Ready(Ok(tampon.len()))
        }

        fn poll_flush(self: Pin&lt;&amp;mut Self&gt;, _: &amp;mut Context) -&gt; Poll&lt;Result&lt;(), Error&gt;&gt; {
            Poll::Ready(Ok(()))
        }

        fn poll_close(self: Pin&lt;&amp;mut Self&gt;, _: &amp;mut Context) -&gt; Poll&lt;Result&lt;(), Error&gt;&gt; {
            Poll::Ready(Ok(()))
        }
    }
</code></pre>
<!--
Lastly, our mock will need to implement `Unpin`, signifying that its location in memory can safely be moved.
For more information on pinning and the `Unpin` trait, see the [section on pinning](../04_pinning/01_chapter.md).
```rust,ignore
    use std::marker::Unpin;
    impl Unpin for MockTcpStream {}
```
-->
<p>Enfin, notre mock a besoin d'implémenter <code>Unpin</code>, ce qui veut dire que sa
position dans la mémoire peut être déplacée en toute sécurité. Pour plus
d'informations sur l'épinglage et le trait <code>Unpin</code>, rendez-vous à la <a href="09_example/../04_pinning/01_chapter.html">section
sur l'épinglage</a>.</p>
<pre><code class="language-rust ignore">    use std::marker::Unpin;
    impl Unpin for MockTcpStream {}
</code></pre>
<!--
Now we're ready to test the `handle_connection` function.
After setting up the `MockTcpStream` containing some initial data,
we can run `handle_connection` using the attribute `#[async_std::test]`, similarly to how we used `#[async_std::main]`.
To ensure that `handle_connection` works as intended, we'll check that the correct data
was written to the `MockTcpStream` based on its initial contents.
```rust,ignore
    use std::fs;

    #[async_std::test]
    async fn test_handle_connection() {
        let input_bytes = b"GET / HTTP/1.1\r\n";
        let mut contents = vec![0u8; 1024];
        contents[..input_bytes.len()].clone_from_slice(input_bytes);
        let mut stream = MockTcpStream {
            read_data: contents,
            write_data: Vec::new(),
        };

        handle_connection(&mut stream).await;
        let mut buf = [0u8; 1024];
        stream.read(&mut buf).await.unwrap();

        let expected_contents = fs::read_to_string("hello.html").unwrap();
        let expected_response = format!("HTTP/1.1 200 OK\r\n\r\n{}", expected_contents);
        assert!(stream.write_data.starts_with(expected_response.as_bytes()));
    }
```
-->
<p>Maintenant nous sommes prêts à tester la fonction <code>gestion_connexion</code>.
Après avoir réglé le <code>MockTcpStream</code> pour contenir les données initiales, nous
pouvons exécuter <code>gestion_connexion</code> en utilisant l'attribut
<code>#[async_std::test]</code>, de la même manière que nous avons utilisé
<code>#[async_std::main]</code>.
Pour nous assurer que <code>gestion_connexion</code> fonctionne comme attendu, nous
allons vérifier que les données ont été correctement écrites dans le
<code>MockTcpStream</code> en fonction de son contenu initial.</p>
<pre><code class="language-rust ignore">    use std::fs;

    #[async_std::test]
    async fn test_gestion_connexion() {
        let octets_entree = b&quot;GET / HTTP/1.1\r\n&quot;;
        let mut contenu = vec![0u8; 1024];
        contenu[..octets_entree.len()].clone_from_slice(octets_entree);
        let mut flux = MockTcpStream {
            donnees_lecture: contenu,
            donnees_ecriture: Vec::new(),
        };

        gestion_connexion(&amp;mut flux).await;
        let mut tampon = [0u8; 1024];
        flux.read(&amp;mut tampon).await.unwrap();

        let contenu_attendu = fs::read_to_string(&quot;hello.html&quot;).unwrap();
        let reponse_attendue = format!(&quot;HTTP/1.1 200 OK\r\n\r\n{}&quot;, contenu_attendu);
        assert!(flux.donnees_ecriture.starts_with(reponse_attendue.as_bytes()));
    }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!--
# Appendix : Translations of the Book
-->
<h1 id="annexe--traductions-du-livre"><a class="header" href="#annexe--traductions-du-livre">Annexe : traductions du livre</a></h1>
<!--
For resources in languages other than English.
-->
<p>Pour plus d'informations dans d'autres langues que le Français.</p>
<ul>
<li><a href="https://rust-lang.github.io/async-book/">Anglais</a></li>
<li><a href="https://doc.rust-lang.ru/async-book/">Русский</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="traduction-des-termes"><a class="header" href="#traduction-des-termes">Traduction des termes</a></h1>
<p>Voici les principaux termes techniques qui ont été traduits de l'anglais vers le
français.</p>
<table><thead><tr><th>Anglais</th><th>Français</th><th>Remarques</th></tr></thead><tbody>
<tr><td>actor model</td><td>modèle d'acteur</td><td>-</td></tr>
<tr><td>borrow</td><td>emprunter</td><td>-</td></tr>
<tr><td>buffer</td><td>tampon</td><td>-</td></tr>
<tr><td>bug</td><td>bogue</td><td>-</td></tr>
<tr><td>callback</td><td>fonction de rappel</td><td>-</td></tr>
<tr><td>cheaper synchronization</td><td>synchronisation allégée</td><td>-</td></tr>
<tr><td>closure</td><td>fermeture</td><td>-</td></tr>
<tr><td>combinator</td><td>combinateur</td><td>-</td></tr>
<tr><td>concurrent</td><td>concurrent</td><td>-</td></tr>
<tr><td>coroutine</td><td>coroutine</td><td>-</td></tr>
<tr><td>CPU</td><td>processeur</td><td>-</td></tr>
<tr><td>crate</td><td>crate</td><td>-</td></tr>
<tr><td>deadlock</td><td>interblocage</td><td>-</td></tr>
<tr><td>driver</td><td>pilote</td><td>-</td></tr>
<tr><td>drop</td><td>libérer</td><td>-</td></tr>
<tr><td>dynamic dispatch</td><td>répartition dynamique</td><td>-</td></tr>
<tr><td>flow controle</td><td>contrôle de flux</td><td>-</td></tr>
<tr><td>framework</td><td>cadriciel</td><td>-</td></tr>
<tr><td>future</td><td>future</td><td>-</td></tr>
<tr><td>GUI application</td><td>application avec interface graphique</td><td>-</td></tr>
<tr><td>heap</td><td>tas</td><td>-</td></tr>
<tr><td>IO</td><td>entrée/sortie</td><td>-</td></tr>
<tr><td>lazy</td><td>passif</td><td>-</td></tr>
<tr><td>library</td><td>bibliothèque</td><td>-</td></tr>
<tr><td>lifetime</td><td>durée de vie</td><td>-</td></tr>
<tr><td>lock</td><td>verrou</td><td>-</td></tr>
<tr><td>low-level</td><td>bas-niveau</td><td>-</td></tr>
<tr><td>mock</td><td>mock</td><td>-</td></tr>
<tr><td>mutable</td><td>mutable</td><td>-</td></tr>
<tr><td>nightly Rust</td><td>version expérimentale de Rust</td><td>-</td></tr>
<tr><td>OS</td><td>Système d'Exploitation</td><td>Operating System</td></tr>
<tr><td>(take) ownership</td><td>(prendre) possession</td><td>-</td></tr>
<tr><td>pin</td><td>épingler</td><td>-</td></tr>
<tr><td>pinning</td><td>épinglage</td><td>-</td></tr>
<tr><td>reactor</td><td>réacteur</td><td>-</td></tr>
<tr><td>refactoring</td><td>remaniement</td><td>-</td></tr>
<tr><td>retry logic</td><td>logique de relance</td><td>-</td></tr>
<tr><td>runtime</td><td>environnement d'exécution</td><td>-</td></tr>
<tr><td>scope</td><td>portée</td><td>pour la durée de vie</td></tr>
<tr><td>shadow</td><td>masquer</td><td>remplacer une variable par une autre de même nom</td></tr>
<tr><td>snip</td><td>partie masquée ici</td><td>dans un encart</td></tr>
<tr><td>stack</td><td>pile</td><td>-</td></tr>
<tr><td>state machine</td><td>machine à états</td><td>-</td></tr>
<tr><td>static</td><td>statique</td><td>-</td></tr>
<tr><td>subscriber</td><td>abonné</td><td>-</td></tr>
<tr><td>task</td><td>tâche</td><td>-</td></tr>
<tr><td>thread</td><td>processus</td><td>-</td></tr>
<tr><td>thread pool</td><td>groupe de processus</td><td>-</td></tr>
<tr><td>trait</td><td>trait</td><td>-</td></tr>
<tr><td>tuple</td><td>tuple</td><td>-</td></tr>
<tr><td>unit test</td><td>test unitaire</td><td>-</td></tr>
<tr><td>unsafe</td><td>non sécurisé</td><td>-</td></tr>
<tr><td>valid</td><td>en vigueur</td><td>pour la durée de vie</td></tr>
<tr><td>yield control</td><td>transférer le contrôle</td><td>-</td></tr>
</tbody></table>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
